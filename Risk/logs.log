2024-06-10 12:36:14,328:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 12:36:14,328:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 12:36:14,328:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 12:36:14,328:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-10 12:36:35,386:INFO:PyCaret ClassificationExperiment
2024-06-10 12:36:35,386:INFO:Logging name: clf-default-name
2024-06-10 12:36:35,386:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-10 12:36:35,386:INFO:version 3.3.2
2024-06-10 12:36:35,386:INFO:Initializing setup()
2024-06-10 12:36:35,388:INFO:self.USI: dede
2024-06-10 12:36:35,388:INFO:self._variable_keys: {'_available_plots', 'pipeline', 'X', 'gpu_param', 'idx', 'X_test', 'gpu_n_jobs_param', 'fold_shuffle_param', 'exp_name_log', 'X_train', 'seed', 'USI', 'y_test', 'y_train', 'n_jobs_param', 'exp_id', 'target_param', 'html_param', 'y', 'fold_groups_param', 'is_multiclass', 'data', 'memory', '_ml_usecase', 'log_plots_param', 'fix_imbalance', 'logging_param', 'fold_generator'}
2024-06-10 12:36:35,388:INFO:Checking environment
2024-06-10 12:36:35,388:INFO:python_version: 3.9.13
2024-06-10 12:36:35,388:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2024-06-10 12:36:35,389:INFO:machine: AMD64
2024-06-10 12:36:35,389:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-10 12:36:35,389:INFO:Memory: svmem(total=16843341824, available=6360477696, percent=62.2, used=10482864128, free=6360477696)
2024-06-10 12:36:35,389:INFO:Physical Core: 4
2024-06-10 12:36:35,389:INFO:Logical Core: 8
2024-06-10 12:36:35,389:INFO:Checking libraries
2024-06-10 12:36:35,389:INFO:System:
2024-06-10 12:36:35,389:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2024-06-10 12:36:35,390:INFO:executable: c:\ProgramData\Anaconda3\python.exe
2024-06-10 12:36:35,390:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-10 12:36:35,390:INFO:PyCaret required dependencies:
2024-06-10 12:36:35,790:INFO:                 pip: 22.2.2
2024-06-10 12:36:35,790:INFO:          setuptools: 63.4.1
2024-06-10 12:36:35,790:INFO:             pycaret: 3.3.2
2024-06-10 12:36:35,790:INFO:             IPython: 7.31.1
2024-06-10 12:36:35,790:INFO:          ipywidgets: 7.6.5
2024-06-10 12:36:35,790:INFO:                tqdm: 4.64.1
2024-06-10 12:36:35,790:INFO:               numpy: 1.21.5
2024-06-10 12:36:35,790:INFO:              pandas: 1.4.4
2024-06-10 12:36:35,790:INFO:              jinja2: 2.11.3
2024-06-10 12:36:35,790:INFO:               scipy: 1.9.1
2024-06-10 12:36:35,790:INFO:              joblib: 1.1.0
2024-06-10 12:36:35,790:INFO:             sklearn: 1.0.2
2024-06-10 12:36:35,790:INFO:                pyod: 2.0.0
2024-06-10 12:36:35,790:INFO:            imblearn: 0.12.3
2024-06-10 12:36:35,790:INFO:   category_encoders: 2.6.3
2024-06-10 12:36:35,794:INFO:            lightgbm: 4.3.0
2024-06-10 12:36:35,794:INFO:               numba: 0.55.1
2024-06-10 12:36:35,794:INFO:            requests: 2.28.1
2024-06-10 12:36:35,794:INFO:          matplotlib: 3.5.2
2024-06-10 12:36:35,794:INFO:          scikitplot: 0.3.7
2024-06-10 12:36:35,794:INFO:         yellowbrick: 1.5
2024-06-10 12:36:35,794:INFO:              plotly: 5.9.0
2024-06-10 12:36:35,794:INFO:    plotly-resampler: Not installed
2024-06-10 12:36:35,794:INFO:             kaleido: 0.2.1
2024-06-10 12:36:35,794:INFO:           schemdraw: 0.15
2024-06-10 12:36:35,794:INFO:         statsmodels: 0.13.2
2024-06-10 12:36:35,795:INFO:              sktime: 0.26.0
2024-06-10 12:36:35,795:INFO:               tbats: 1.1.3
2024-06-10 12:36:35,795:INFO:            pmdarima: 2.0.4
2024-06-10 12:36:35,795:INFO:              psutil: 5.9.0
2024-06-10 12:36:35,795:INFO:          markupsafe: 2.0.1
2024-06-10 12:36:35,795:INFO:             pickle5: Not installed
2024-06-10 12:36:35,795:INFO:         cloudpickle: 2.0.0
2024-06-10 12:36:35,795:INFO:         deprecation: 2.1.0
2024-06-10 12:36:35,795:INFO:              xxhash: 3.4.1
2024-06-10 12:36:35,795:INFO:           wurlitzer: Not installed
2024-06-10 12:36:35,795:INFO:PyCaret optional dependencies:
2024-06-10 12:36:35,825:INFO:                shap: Not installed
2024-06-10 12:36:35,825:INFO:           interpret: Not installed
2024-06-10 12:36:35,825:INFO:                umap: 0.5.6
2024-06-10 12:36:35,825:INFO:     ydata_profiling: 4.2.0
2024-06-10 12:36:35,825:INFO:  explainerdashboard: Not installed
2024-06-10 12:36:35,825:INFO:             autoviz: Not installed
2024-06-10 12:36:35,825:INFO:           fairlearn: Not installed
2024-06-10 12:36:35,825:INFO:          deepchecks: Not installed
2024-06-10 12:36:35,825:INFO:             xgboost: Not installed
2024-06-10 12:36:35,825:INFO:            catboost: Not installed
2024-06-10 12:36:35,825:INFO:              kmodes: Not installed
2024-06-10 12:36:35,825:INFO:             mlxtend: Not installed
2024-06-10 12:36:35,825:INFO:       statsforecast: Not installed
2024-06-10 12:36:35,826:INFO:        tune_sklearn: Not installed
2024-06-10 12:36:35,826:INFO:                 ray: Not installed
2024-06-10 12:36:35,826:INFO:            hyperopt: Not installed
2024-06-10 12:36:35,826:INFO:              optuna: Not installed
2024-06-10 12:36:35,826:INFO:               skopt: Not installed
2024-06-10 12:36:35,826:INFO:              mlflow: Not installed
2024-06-10 12:36:35,826:INFO:              gradio: Not installed
2024-06-10 12:36:35,826:INFO:             fastapi: Not installed
2024-06-10 12:36:35,826:INFO:             uvicorn: Not installed
2024-06-10 12:36:35,826:INFO:              m2cgen: Not installed
2024-06-10 12:36:35,826:INFO:           evidently: Not installed
2024-06-10 12:36:35,826:INFO:               fugue: Not installed
2024-06-10 12:36:35,826:INFO:           streamlit: Not installed
2024-06-10 12:36:35,826:INFO:             prophet: Not installed
2024-06-10 12:36:35,826:INFO:None
2024-06-10 12:36:35,826:INFO:Set up data.
2024-06-10 12:36:35,835:INFO:Set up folding strategy.
2024-06-10 12:36:35,835:INFO:Set up train/test split.
2024-06-10 12:36:35,846:INFO:Set up index.
2024-06-10 12:36:35,846:INFO:Assigning column types.
2024-06-10 12:36:35,850:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-10 12:36:35,917:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-10 12:36:35,917:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 12:36:35,977:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 12:36:35,977:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 12:36:36,045:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-10 12:36:36,048:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 12:36:36,098:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 12:36:36,098:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 12:36:36,100:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-10 12:36:36,156:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 12:36:36,187:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 12:36:36,187:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 12:36:36,246:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-10 12:36:36,284:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 12:36:36,284:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 12:36:36,288:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-10 12:36:36,388:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 12:36:36,388:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 12:36:36,495:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 12:36:36,495:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 12:36:36,505:INFO:Finished creating preprocessing pipeline.
2024-06-10 12:36:36,507:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\aabir\AppData\Local\Temp\joblib),
         steps=[('placeholder', None)], verbose=False)
2024-06-10 12:36:36,507:INFO:Creating final display dataframe.
2024-06-10 12:36:36,563:INFO:Setup _display_container:                    Description     Value
0                   Session id       740
1                       Target   Outcome
2                  Target type    Binary
3          Original data shape  (768, 9)
4       Transformed data shape  (768, 9)
5  Transformed train set shape  (537, 9)
6   Transformed test set shape  (231, 9)
7             Numeric features         8
2024-06-10 12:36:36,722:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 12:36:36,722:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 12:36:37,044:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 12:36:37,044:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-10 12:36:37,044:INFO:setup() successfully completed in 1.66s...............
2024-06-10 12:36:39,761:INFO:Initializing compare_models()
2024-06-10 12:36:39,761:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AF7743760>, include=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=5, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000029AF7743760>, 'include': None, 'exclude': ['lightgbm', 'xgboost', 'dummy', 'svm', 'ridge', 'knn', 'dt', 'nb', 'qda'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 5, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['lightgbm', 'xgboost', 'dummy', 'svm', 'ridge', 'knn', 'dt', 'nb', 'qda'])
2024-06-10 12:36:39,762:INFO:Checking exceptions
2024-06-10 12:36:39,769:INFO:Preparing display monitor
2024-06-10 12:36:39,830:INFO:Initializing Logistic Regression
2024-06-10 12:36:39,830:INFO:Total runtime is 0.0 minutes
2024-06-10 12:36:39,840:INFO:SubProcess create_model() called ==================================
2024-06-10 12:36:39,840:INFO:Initializing create_model()
2024-06-10 12:36:39,840:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AF7743760>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029AF58B0130>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 12:36:39,840:INFO:Checking exceptions
2024-06-10 12:36:39,840:INFO:Importing libraries
2024-06-10 12:36:39,840:INFO:Copying training dataset
2024-06-10 12:36:39,847:INFO:Defining folds
2024-06-10 12:36:39,847:INFO:Declaring metric variables
2024-06-10 12:36:39,854:INFO:Importing untrained model
2024-06-10 12:36:39,861:INFO:Logistic Regression Imported successfully
2024-06-10 12:36:39,878:INFO:Starting cross validation
2024-06-10 12:36:39,878:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 12:36:49,172:INFO:Calculating mean and std
2024-06-10 12:36:49,178:INFO:Creating metrics dataframe
2024-06-10 12:36:49,182:INFO:Uploading results into container
2024-06-10 12:36:49,182:INFO:Uploading model into container now
2024-06-10 12:36:49,182:INFO:_master_model_container: 1
2024-06-10 12:36:49,182:INFO:_display_container: 2
2024-06-10 12:36:49,182:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=740, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-06-10 12:36:49,182:INFO:create_model() successfully completed......................................
2024-06-10 12:36:49,430:INFO:SubProcess create_model() end ==================================
2024-06-10 12:36:49,430:INFO:Creating metrics dataframe
2024-06-10 12:36:49,444:INFO:Initializing Random Forest Classifier
2024-06-10 12:36:49,452:INFO:Total runtime is 0.16037965615590413 minutes
2024-06-10 12:36:49,458:INFO:SubProcess create_model() called ==================================
2024-06-10 12:36:49,458:INFO:Initializing create_model()
2024-06-10 12:36:49,458:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AF7743760>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029AF58B0130>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 12:36:49,458:INFO:Checking exceptions
2024-06-10 12:36:49,458:INFO:Importing libraries
2024-06-10 12:36:49,458:INFO:Copying training dataset
2024-06-10 12:36:49,472:INFO:Defining folds
2024-06-10 12:36:49,472:INFO:Declaring metric variables
2024-06-10 12:36:49,480:INFO:Importing untrained model
2024-06-10 12:36:49,493:INFO:Random Forest Classifier Imported successfully
2024-06-10 12:36:49,508:INFO:Starting cross validation
2024-06-10 12:36:49,511:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 12:36:50,393:INFO:Calculating mean and std
2024-06-10 12:36:50,395:INFO:Creating metrics dataframe
2024-06-10 12:36:50,406:INFO:Uploading results into container
2024-06-10 12:36:50,406:INFO:Uploading model into container now
2024-06-10 12:36:50,411:INFO:_master_model_container: 2
2024-06-10 12:36:50,411:INFO:_display_container: 2
2024-06-10 12:36:50,413:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=740, verbose=0,
                       warm_start=False)
2024-06-10 12:36:50,413:INFO:create_model() successfully completed......................................
2024-06-10 12:36:50,582:INFO:SubProcess create_model() end ==================================
2024-06-10 12:36:50,583:INFO:Creating metrics dataframe
2024-06-10 12:36:50,595:INFO:Initializing Ada Boost Classifier
2024-06-10 12:36:50,595:INFO:Total runtime is 0.17942094405492146 minutes
2024-06-10 12:36:50,629:INFO:SubProcess create_model() called ==================================
2024-06-10 12:36:50,630:INFO:Initializing create_model()
2024-06-10 12:36:50,630:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AF7743760>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029AF58B0130>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 12:36:50,630:INFO:Checking exceptions
2024-06-10 12:36:50,630:INFO:Importing libraries
2024-06-10 12:36:50,630:INFO:Copying training dataset
2024-06-10 12:36:50,650:INFO:Defining folds
2024-06-10 12:36:50,651:INFO:Declaring metric variables
2024-06-10 12:36:50,657:INFO:Importing untrained model
2024-06-10 12:36:50,677:INFO:Ada Boost Classifier Imported successfully
2024-06-10 12:36:50,690:INFO:Starting cross validation
2024-06-10 12:36:50,690:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 12:36:50,724:WARNING:C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-06-10 12:36:50,729:WARNING:C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-06-10 12:36:50,733:WARNING:C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-06-10 12:36:50,737:WARNING:C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-06-10 12:36:50,737:WARNING:C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-06-10 12:36:50,741:WARNING:C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-06-10 12:36:50,741:WARNING:C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-06-10 12:36:50,748:WARNING:C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-06-10 12:36:50,981:WARNING:C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-06-10 12:36:50,983:WARNING:C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-06-10 12:36:51,132:INFO:Calculating mean and std
2024-06-10 12:36:51,133:INFO:Creating metrics dataframe
2024-06-10 12:36:51,139:INFO:Uploading results into container
2024-06-10 12:36:51,139:INFO:Uploading model into container now
2024-06-10 12:36:51,145:INFO:_master_model_container: 3
2024-06-10 12:36:51,145:INFO:_display_container: 2
2024-06-10 12:36:51,146:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=740)
2024-06-10 12:36:51,146:INFO:create_model() successfully completed......................................
2024-06-10 12:36:51,366:INFO:SubProcess create_model() end ==================================
2024-06-10 12:36:51,366:INFO:Creating metrics dataframe
2024-06-10 12:36:51,379:INFO:Initializing Gradient Boosting Classifier
2024-06-10 12:36:51,384:INFO:Total runtime is 0.19257117509841917 minutes
2024-06-10 12:36:51,390:INFO:SubProcess create_model() called ==================================
2024-06-10 12:36:51,390:INFO:Initializing create_model()
2024-06-10 12:36:51,390:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AF7743760>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029AF58B0130>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 12:36:51,390:INFO:Checking exceptions
2024-06-10 12:36:51,390:INFO:Importing libraries
2024-06-10 12:36:51,390:INFO:Copying training dataset
2024-06-10 12:36:51,400:INFO:Defining folds
2024-06-10 12:36:51,400:INFO:Declaring metric variables
2024-06-10 12:36:51,408:INFO:Importing untrained model
2024-06-10 12:36:51,417:INFO:Gradient Boosting Classifier Imported successfully
2024-06-10 12:36:51,433:INFO:Starting cross validation
2024-06-10 12:36:51,434:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 12:36:52,081:INFO:Calculating mean and std
2024-06-10 12:36:52,083:INFO:Creating metrics dataframe
2024-06-10 12:36:52,093:INFO:Uploading results into container
2024-06-10 12:36:52,095:INFO:Uploading model into container now
2024-06-10 12:36:52,095:INFO:_master_model_container: 4
2024-06-10 12:36:52,095:INFO:_display_container: 2
2024-06-10 12:36:52,095:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=740, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-06-10 12:36:52,095:INFO:create_model() successfully completed......................................
2024-06-10 12:36:52,294:INFO:SubProcess create_model() end ==================================
2024-06-10 12:36:52,296:INFO:Creating metrics dataframe
2024-06-10 12:36:52,316:INFO:Initializing Linear Discriminant Analysis
2024-06-10 12:36:52,317:INFO:Total runtime is 0.20812700192133585 minutes
2024-06-10 12:36:52,325:INFO:SubProcess create_model() called ==================================
2024-06-10 12:36:52,325:INFO:Initializing create_model()
2024-06-10 12:36:52,325:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AF7743760>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029AF58B0130>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 12:36:52,325:INFO:Checking exceptions
2024-06-10 12:36:52,325:INFO:Importing libraries
2024-06-10 12:36:52,325:INFO:Copying training dataset
2024-06-10 12:36:52,336:INFO:Defining folds
2024-06-10 12:36:52,336:INFO:Declaring metric variables
2024-06-10 12:36:52,345:INFO:Importing untrained model
2024-06-10 12:36:52,351:INFO:Linear Discriminant Analysis Imported successfully
2024-06-10 12:36:52,369:INFO:Starting cross validation
2024-06-10 12:36:52,370:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 12:36:52,568:INFO:Calculating mean and std
2024-06-10 12:36:52,568:INFO:Creating metrics dataframe
2024-06-10 12:36:52,574:INFO:Uploading results into container
2024-06-10 12:36:52,574:INFO:Uploading model into container now
2024-06-10 12:36:52,574:INFO:_master_model_container: 5
2024-06-10 12:36:52,574:INFO:_display_container: 2
2024-06-10 12:36:52,574:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-06-10 12:36:52,574:INFO:create_model() successfully completed......................................
2024-06-10 12:36:52,772:INFO:SubProcess create_model() end ==================================
2024-06-10 12:36:52,772:INFO:Creating metrics dataframe
2024-06-10 12:36:52,794:INFO:Initializing Extra Trees Classifier
2024-06-10 12:36:52,794:INFO:Total runtime is 0.21607494354248047 minutes
2024-06-10 12:36:52,802:INFO:SubProcess create_model() called ==================================
2024-06-10 12:36:52,802:INFO:Initializing create_model()
2024-06-10 12:36:52,802:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AF7743760>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029AF58B0130>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 12:36:52,802:INFO:Checking exceptions
2024-06-10 12:36:52,802:INFO:Importing libraries
2024-06-10 12:36:52,802:INFO:Copying training dataset
2024-06-10 12:36:52,812:INFO:Defining folds
2024-06-10 12:36:52,813:INFO:Declaring metric variables
2024-06-10 12:36:52,816:INFO:Importing untrained model
2024-06-10 12:36:52,824:INFO:Extra Trees Classifier Imported successfully
2024-06-10 12:36:52,836:INFO:Starting cross validation
2024-06-10 12:36:52,839:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 12:36:53,524:INFO:Calculating mean and std
2024-06-10 12:36:53,524:INFO:Creating metrics dataframe
2024-06-10 12:36:53,528:INFO:Uploading results into container
2024-06-10 12:36:53,528:INFO:Uploading model into container now
2024-06-10 12:36:53,528:INFO:_master_model_container: 6
2024-06-10 12:36:53,528:INFO:_display_container: 2
2024-06-10 12:36:53,528:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=740, verbose=0,
                     warm_start=False)
2024-06-10 12:36:53,528:INFO:create_model() successfully completed......................................
2024-06-10 12:36:53,706:INFO:SubProcess create_model() end ==================================
2024-06-10 12:36:53,706:INFO:Creating metrics dataframe
2024-06-10 12:36:53,738:INFO:Initializing create_model()
2024-06-10 12:36:53,740:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AF7743760>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=740, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 12:36:53,740:INFO:Checking exceptions
2024-06-10 12:36:53,743:INFO:Importing libraries
2024-06-10 12:36:53,743:INFO:Copying training dataset
2024-06-10 12:36:53,747:INFO:Defining folds
2024-06-10 12:36:53,747:INFO:Declaring metric variables
2024-06-10 12:36:53,747:INFO:Importing untrained model
2024-06-10 12:36:53,748:INFO:Declaring custom model
2024-06-10 12:36:53,750:INFO:Logistic Regression Imported successfully
2024-06-10 12:36:53,750:INFO:Cross validation set to False
2024-06-10 12:36:53,750:INFO:Fitting Model
2024-06-10 12:36:53,796:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=740, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-06-10 12:36:53,796:INFO:create_model() successfully completed......................................
2024-06-10 12:36:54,003:INFO:Initializing create_model()
2024-06-10 12:36:54,006:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AF7743760>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 12:36:54,006:INFO:Checking exceptions
2024-06-10 12:36:54,007:INFO:Importing libraries
2024-06-10 12:36:54,007:INFO:Copying training dataset
2024-06-10 12:36:54,013:INFO:Defining folds
2024-06-10 12:36:54,014:INFO:Declaring metric variables
2024-06-10 12:36:54,014:INFO:Importing untrained model
2024-06-10 12:36:54,014:INFO:Declaring custom model
2024-06-10 12:36:54,014:INFO:Linear Discriminant Analysis Imported successfully
2024-06-10 12:36:54,014:INFO:Cross validation set to False
2024-06-10 12:36:54,014:INFO:Fitting Model
2024-06-10 12:36:54,058:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-06-10 12:36:54,060:INFO:create_model() successfully completed......................................
2024-06-10 12:36:54,242:INFO:Initializing create_model()
2024-06-10 12:36:54,250:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AF7743760>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=740, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 12:36:54,250:INFO:Checking exceptions
2024-06-10 12:36:54,252:INFO:Importing libraries
2024-06-10 12:36:54,252:INFO:Copying training dataset
2024-06-10 12:36:54,253:INFO:Defining folds
2024-06-10 12:36:54,253:INFO:Declaring metric variables
2024-06-10 12:36:54,253:INFO:Importing untrained model
2024-06-10 12:36:54,253:INFO:Declaring custom model
2024-06-10 12:36:54,253:INFO:Random Forest Classifier Imported successfully
2024-06-10 12:36:54,258:INFO:Cross validation set to False
2024-06-10 12:36:54,258:INFO:Fitting Model
2024-06-10 12:36:54,638:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=740, verbose=0,
                       warm_start=False)
2024-06-10 12:36:54,639:INFO:create_model() successfully completed......................................
2024-06-10 12:36:54,811:INFO:Initializing create_model()
2024-06-10 12:36:54,811:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AF7743760>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=740, verbose=0,
                     warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 12:36:54,811:INFO:Checking exceptions
2024-06-10 12:36:54,816:INFO:Importing libraries
2024-06-10 12:36:54,817:INFO:Copying training dataset
2024-06-10 12:36:54,822:INFO:Defining folds
2024-06-10 12:36:54,822:INFO:Declaring metric variables
2024-06-10 12:36:54,822:INFO:Importing untrained model
2024-06-10 12:36:54,822:INFO:Declaring custom model
2024-06-10 12:36:54,822:INFO:Extra Trees Classifier Imported successfully
2024-06-10 12:36:54,822:INFO:Cross validation set to False
2024-06-10 12:36:54,822:INFO:Fitting Model
2024-06-10 12:36:55,150:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=740, verbose=0,
                     warm_start=False)
2024-06-10 12:36:55,150:INFO:create_model() successfully completed......................................
2024-06-10 12:36:55,373:INFO:Initializing create_model()
2024-06-10 12:36:55,373:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AF7743760>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=740, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 12:36:55,373:INFO:Checking exceptions
2024-06-10 12:36:55,373:INFO:Importing libraries
2024-06-10 12:36:55,373:INFO:Copying training dataset
2024-06-10 12:36:55,384:INFO:Defining folds
2024-06-10 12:36:55,384:INFO:Declaring metric variables
2024-06-10 12:36:55,384:INFO:Importing untrained model
2024-06-10 12:36:55,384:INFO:Declaring custom model
2024-06-10 12:36:55,384:INFO:Gradient Boosting Classifier Imported successfully
2024-06-10 12:36:55,384:INFO:Cross validation set to False
2024-06-10 12:36:55,384:INFO:Fitting Model
2024-06-10 12:36:55,577:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=740, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-06-10 12:36:55,577:INFO:create_model() successfully completed......................................
2024-06-10 12:36:55,762:INFO:_master_model_container: 6
2024-06-10 12:36:55,762:INFO:_display_container: 2
2024-06-10 12:36:55,767:INFO:[LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=740, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=740, verbose=0,
                       warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=740, verbose=0,
                     warm_start=False), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=740, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)]
2024-06-10 12:36:55,767:INFO:compare_models() successfully completed......................................
2024-06-10 12:37:00,862:INFO:Initializing create_model()
2024-06-10 12:37:00,862:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AF7743760>, estimator=catboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 12:37:00,864:INFO:Checking exceptions
2024-06-10 12:37:21,591:INFO:Initializing create_model()
2024-06-10 12:37:21,594:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AF7743760>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 12:37:21,594:INFO:Checking exceptions
2024-06-10 12:37:21,673:INFO:Importing libraries
2024-06-10 12:37:21,674:INFO:Copying training dataset
2024-06-10 12:37:21,677:INFO:Defining folds
2024-06-10 12:37:21,677:INFO:Declaring metric variables
2024-06-10 12:37:21,683:INFO:Importing untrained model
2024-06-10 12:37:21,693:INFO:Random Forest Classifier Imported successfully
2024-06-10 12:37:21,710:INFO:Starting cross validation
2024-06-10 12:37:21,710:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 12:37:22,680:INFO:Calculating mean and std
2024-06-10 12:37:22,683:INFO:Creating metrics dataframe
2024-06-10 12:37:22,695:INFO:Finalizing model
2024-06-10 12:37:23,008:INFO:Uploading results into container
2024-06-10 12:37:23,013:INFO:Uploading model into container now
2024-06-10 12:37:23,041:INFO:_master_model_container: 7
2024-06-10 12:37:23,050:INFO:_display_container: 3
2024-06-10 12:37:23,055:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=740, verbose=0,
                       warm_start=False)
2024-06-10 12:37:23,055:INFO:create_model() successfully completed......................................
2024-06-10 12:37:23,336:INFO:Initializing create_model()
2024-06-10 12:37:23,336:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AF7743760>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 12:37:23,336:INFO:Checking exceptions
2024-06-10 12:37:23,410:INFO:Importing libraries
2024-06-10 12:37:23,410:INFO:Copying training dataset
2024-06-10 12:37:23,424:INFO:Defining folds
2024-06-10 12:37:23,424:INFO:Declaring metric variables
2024-06-10 12:37:23,430:INFO:Importing untrained model
2024-06-10 12:37:23,443:INFO:Logistic Regression Imported successfully
2024-06-10 12:37:23,459:INFO:Starting cross validation
2024-06-10 12:37:23,460:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 12:37:23,650:INFO:Calculating mean and std
2024-06-10 12:37:23,650:INFO:Creating metrics dataframe
2024-06-10 12:37:23,660:INFO:Finalizing model
2024-06-10 12:37:23,701:INFO:Uploading results into container
2024-06-10 12:37:23,701:INFO:Uploading model into container now
2024-06-10 12:37:23,727:INFO:_master_model_container: 8
2024-06-10 12:37:23,727:INFO:_display_container: 4
2024-06-10 12:37:23,727:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=740, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-06-10 12:37:23,727:INFO:create_model() successfully completed......................................
2024-06-10 12:37:24,029:INFO:Initializing create_model()
2024-06-10 12:37:24,029:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AF7743760>, estimator=lda, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 12:37:24,029:INFO:Checking exceptions
2024-06-10 12:37:24,118:INFO:Importing libraries
2024-06-10 12:37:24,118:INFO:Copying training dataset
2024-06-10 12:37:24,125:INFO:Defining folds
2024-06-10 12:37:24,127:INFO:Declaring metric variables
2024-06-10 12:37:24,133:INFO:Importing untrained model
2024-06-10 12:37:24,146:INFO:Linear Discriminant Analysis Imported successfully
2024-06-10 12:37:24,171:INFO:Starting cross validation
2024-06-10 12:37:24,172:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 12:37:24,472:INFO:Calculating mean and std
2024-06-10 12:37:24,479:INFO:Creating metrics dataframe
2024-06-10 12:37:24,521:INFO:Finalizing model
2024-06-10 12:37:24,540:INFO:Uploading results into container
2024-06-10 12:37:24,544:INFO:Uploading model into container now
2024-06-10 12:37:24,564:INFO:_master_model_container: 9
2024-06-10 12:37:24,565:INFO:_display_container: 5
2024-06-10 12:37:24,565:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-06-10 12:37:24,566:INFO:create_model() successfully completed......................................
2024-06-10 12:37:24,906:INFO:Initializing create_model()
2024-06-10 12:37:24,907:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AF7743760>, estimator=gbc, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 12:37:24,907:INFO:Checking exceptions
2024-06-10 12:37:24,975:INFO:Importing libraries
2024-06-10 12:37:24,975:INFO:Copying training dataset
2024-06-10 12:37:24,994:INFO:Defining folds
2024-06-10 12:37:24,994:INFO:Declaring metric variables
2024-06-10 12:37:25,009:INFO:Importing untrained model
2024-06-10 12:37:25,022:INFO:Gradient Boosting Classifier Imported successfully
2024-06-10 12:37:25,047:INFO:Starting cross validation
2024-06-10 12:37:25,052:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 12:37:26,170:INFO:Calculating mean and std
2024-06-10 12:37:26,184:INFO:Creating metrics dataframe
2024-06-10 12:37:26,200:INFO:Finalizing model
2024-06-10 12:37:26,583:INFO:Uploading results into container
2024-06-10 12:37:26,583:INFO:Uploading model into container now
2024-06-10 12:37:26,609:INFO:_master_model_container: 10
2024-06-10 12:37:26,610:INFO:_display_container: 6
2024-06-10 12:37:26,610:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=740, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-06-10 12:37:26,610:INFO:create_model() successfully completed......................................
2024-06-10 12:37:33,449:INFO:Initializing interpret_model()
2024-06-10 12:37:33,449:INFO:interpret_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=740, verbose=0,
                       warm_start=False), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AF7743760>)
2024-06-10 12:37:33,455:INFO:Checking exceptions
2024-06-10 12:37:33,455:ERROR:
'shap' is a soft dependency and not included in the pycaret installation. Please run: `pip install shap` to install.
Alternately, you can install this by running `pip install pycaret[analysis]`
NoneType: None
2024-06-10 12:38:47,809:INFO:Initializing tune_model()
2024-06-10 12:38:47,809:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=740, verbose=0,
                       warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AF7743760>)
2024-06-10 12:38:47,810:INFO:Checking exceptions
2024-06-10 12:38:47,893:INFO:Copying training dataset
2024-06-10 12:38:47,902:INFO:Checking base model
2024-06-10 12:38:47,902:INFO:Base model : Random Forest Classifier
2024-06-10 12:38:47,918:INFO:Declaring metric variables
2024-06-10 12:38:47,928:INFO:Defining Hyperparameters
2024-06-10 12:38:48,188:INFO:Tuning with n_jobs=-1
2024-06-10 12:38:48,188:INFO:Initializing RandomizedSearchCV
2024-06-10 12:38:59,486:INFO:best_params: {'actual_estimator__n_estimators': 220, 'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.005, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 4, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': {}, 'actual_estimator__bootstrap': True}
2024-06-10 12:38:59,486:INFO:Hyperparameter search completed
2024-06-10 12:38:59,486:INFO:SubProcess create_model() called ==================================
2024-06-10 12:38:59,493:INFO:Initializing create_model()
2024-06-10 12:38:59,497:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AF7743760>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=740, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029AF4CDD370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 220, 'min_samples_split': 9, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.005, 'max_features': 'sqrt', 'max_depth': 4, 'criterion': 'gini', 'class_weight': {}, 'bootstrap': True})
2024-06-10 12:38:59,497:INFO:Checking exceptions
2024-06-10 12:38:59,498:INFO:Importing libraries
2024-06-10 12:38:59,498:INFO:Copying training dataset
2024-06-10 12:38:59,509:INFO:Defining folds
2024-06-10 12:38:59,509:INFO:Declaring metric variables
2024-06-10 12:38:59,522:INFO:Importing untrained model
2024-06-10 12:38:59,526:INFO:Declaring custom model
2024-06-10 12:38:59,537:INFO:Random Forest Classifier Imported successfully
2024-06-10 12:38:59,548:INFO:Starting cross validation
2024-06-10 12:38:59,557:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 12:39:01,191:INFO:Calculating mean and std
2024-06-10 12:39:01,194:INFO:Creating metrics dataframe
2024-06-10 12:39:01,204:INFO:Finalizing model
2024-06-10 12:39:02,231:INFO:Uploading results into container
2024-06-10 12:39:02,233:INFO:Uploading model into container now
2024-06-10 12:39:02,234:INFO:_master_model_container: 11
2024-06-10 12:39:02,234:INFO:_display_container: 7
2024-06-10 12:39:02,236:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=4, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.005, min_samples_leaf=5,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=220, n_jobs=-1,
                       oob_score=False, random_state=740, verbose=0,
                       warm_start=False)
2024-06-10 12:39:02,237:INFO:create_model() successfully completed......................................
2024-06-10 12:39:02,485:INFO:SubProcess create_model() end ==================================
2024-06-10 12:39:02,485:INFO:choose_better activated
2024-06-10 12:39:02,497:INFO:SubProcess create_model() called ==================================
2024-06-10 12:39:02,497:INFO:Initializing create_model()
2024-06-10 12:39:02,500:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AF7743760>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=740, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 12:39:02,500:INFO:Checking exceptions
2024-06-10 12:39:02,503:INFO:Importing libraries
2024-06-10 12:39:02,504:INFO:Copying training dataset
2024-06-10 12:39:02,515:INFO:Defining folds
2024-06-10 12:39:02,515:INFO:Declaring metric variables
2024-06-10 12:39:02,515:INFO:Importing untrained model
2024-06-10 12:39:02,515:INFO:Declaring custom model
2024-06-10 12:39:02,519:INFO:Random Forest Classifier Imported successfully
2024-06-10 12:39:02,520:INFO:Starting cross validation
2024-06-10 12:39:02,520:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 12:39:03,351:INFO:Calculating mean and std
2024-06-10 12:39:03,351:INFO:Creating metrics dataframe
2024-06-10 12:39:03,351:INFO:Finalizing model
2024-06-10 12:39:03,777:INFO:Uploading results into container
2024-06-10 12:39:03,777:INFO:Uploading model into container now
2024-06-10 12:39:03,780:INFO:_master_model_container: 12
2024-06-10 12:39:03,780:INFO:_display_container: 8
2024-06-10 12:39:03,780:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=740, verbose=0,
                       warm_start=False)
2024-06-10 12:39:03,781:INFO:create_model() successfully completed......................................
2024-06-10 12:39:03,973:INFO:SubProcess create_model() end ==================================
2024-06-10 12:39:03,978:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=740, verbose=0,
                       warm_start=False) result for AUC is 0.8044
2024-06-10 12:39:03,978:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=4, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.005, min_samples_leaf=5,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=220, n_jobs=-1,
                       oob_score=False, random_state=740, verbose=0,
                       warm_start=False) result for AUC is 0.8179
2024-06-10 12:39:03,978:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=4, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.005, min_samples_leaf=5,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=220, n_jobs=-1,
                       oob_score=False, random_state=740, verbose=0,
                       warm_start=False) is best model
2024-06-10 12:39:03,978:INFO:choose_better completed
2024-06-10 12:39:03,993:INFO:_master_model_container: 12
2024-06-10 12:39:03,993:INFO:_display_container: 7
2024-06-10 12:39:03,993:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=4, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.005, min_samples_leaf=5,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=220, n_jobs=-1,
                       oob_score=False, random_state=740, verbose=0,
                       warm_start=False)
2024-06-10 12:39:03,993:INFO:tune_model() successfully completed......................................
2024-06-10 12:39:04,201:INFO:Initializing tune_model()
2024-06-10 12:39:04,201:INFO:tune_model(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=740, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AF7743760>)
2024-06-10 12:39:04,201:INFO:Checking exceptions
2024-06-10 12:39:04,273:INFO:Copying training dataset
2024-06-10 12:39:04,286:INFO:Checking base model
2024-06-10 12:39:04,286:INFO:Base model : Logistic Regression
2024-06-10 12:39:04,299:INFO:Declaring metric variables
2024-06-10 12:39:04,308:INFO:Defining Hyperparameters
2024-06-10 12:39:04,581:INFO:Tuning with n_jobs=-1
2024-06-10 12:39:04,581:INFO:Initializing RandomizedSearchCV
2024-06-10 12:39:05,522:INFO:best_params: {'actual_estimator__class_weight': {}, 'actual_estimator__C': 2.673}
2024-06-10 12:39:05,522:INFO:Hyperparameter search completed
2024-06-10 12:39:05,522:INFO:SubProcess create_model() called ==================================
2024-06-10 12:39:05,522:INFO:Initializing create_model()
2024-06-10 12:39:05,522:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AF7743760>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=740, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029AEBE37F70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'class_weight': {}, 'C': 2.673})
2024-06-10 12:39:05,522:INFO:Checking exceptions
2024-06-10 12:39:05,522:INFO:Importing libraries
2024-06-10 12:39:05,522:INFO:Copying training dataset
2024-06-10 12:39:05,533:INFO:Defining folds
2024-06-10 12:39:05,533:INFO:Declaring metric variables
2024-06-10 12:39:05,534:INFO:Importing untrained model
2024-06-10 12:39:05,539:INFO:Declaring custom model
2024-06-10 12:39:05,544:INFO:Logistic Regression Imported successfully
2024-06-10 12:39:05,549:INFO:Starting cross validation
2024-06-10 12:39:05,557:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 12:39:05,733:INFO:Calculating mean and std
2024-06-10 12:39:05,734:INFO:Creating metrics dataframe
2024-06-10 12:39:05,743:INFO:Finalizing model
2024-06-10 12:39:05,808:INFO:Uploading results into container
2024-06-10 12:39:05,808:INFO:Uploading model into container now
2024-06-10 12:39:05,808:INFO:_master_model_container: 13
2024-06-10 12:39:05,808:INFO:_display_container: 8
2024-06-10 12:39:05,808:INFO:LogisticRegression(C=2.673, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=740, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-06-10 12:39:05,808:INFO:create_model() successfully completed......................................
2024-06-10 12:39:06,065:INFO:SubProcess create_model() end ==================================
2024-06-10 12:39:06,065:INFO:choose_better activated
2024-06-10 12:39:06,115:INFO:SubProcess create_model() called ==================================
2024-06-10 12:39:06,120:INFO:Initializing create_model()
2024-06-10 12:39:06,120:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AF7743760>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=740, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 12:39:06,121:INFO:Checking exceptions
2024-06-10 12:39:06,125:INFO:Importing libraries
2024-06-10 12:39:06,125:INFO:Copying training dataset
2024-06-10 12:39:06,132:INFO:Defining folds
2024-06-10 12:39:06,132:INFO:Declaring metric variables
2024-06-10 12:39:06,132:INFO:Importing untrained model
2024-06-10 12:39:06,134:INFO:Declaring custom model
2024-06-10 12:39:06,135:INFO:Logistic Regression Imported successfully
2024-06-10 12:39:06,151:INFO:Starting cross validation
2024-06-10 12:39:06,151:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 12:39:06,320:INFO:Calculating mean and std
2024-06-10 12:39:06,320:INFO:Creating metrics dataframe
2024-06-10 12:39:06,320:INFO:Finalizing model
2024-06-10 12:39:06,340:INFO:Uploading results into container
2024-06-10 12:39:06,340:INFO:Uploading model into container now
2024-06-10 12:39:06,340:INFO:_master_model_container: 14
2024-06-10 12:39:06,340:INFO:_display_container: 9
2024-06-10 12:39:06,340:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=740, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-06-10 12:39:06,340:INFO:create_model() successfully completed......................................
2024-06-10 12:39:06,577:INFO:SubProcess create_model() end ==================================
2024-06-10 12:39:06,577:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=740, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.8256
2024-06-10 12:39:06,577:INFO:LogisticRegression(C=2.673, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=740, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.8262
2024-06-10 12:39:06,577:INFO:LogisticRegression(C=2.673, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=740, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2024-06-10 12:39:06,577:INFO:choose_better completed
2024-06-10 12:39:06,603:INFO:_master_model_container: 14
2024-06-10 12:39:06,603:INFO:_display_container: 8
2024-06-10 12:39:06,603:INFO:LogisticRegression(C=2.673, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=740, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-06-10 12:39:06,603:INFO:tune_model() successfully completed......................................
2024-06-10 12:39:06,829:INFO:Initializing tune_model()
2024-06-10 12:39:06,829:INFO:tune_model(estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AF7743760>)
2024-06-10 12:39:06,829:INFO:Checking exceptions
2024-06-10 12:39:06,872:INFO:Copying training dataset
2024-06-10 12:39:06,880:INFO:Checking base model
2024-06-10 12:39:06,880:INFO:Base model : Linear Discriminant Analysis
2024-06-10 12:39:06,890:INFO:Declaring metric variables
2024-06-10 12:39:06,892:INFO:Defining Hyperparameters
2024-06-10 12:39:07,130:INFO:Tuning with n_jobs=-1
2024-06-10 12:39:07,130:INFO:Initializing RandomizedSearchCV
2024-06-10 12:39:07,503:INFO:best_params: {'actual_estimator__solver': 'eigen', 'actual_estimator__shrinkage': 'auto'}
2024-06-10 12:39:07,503:INFO:Hyperparameter search completed
2024-06-10 12:39:07,503:INFO:SubProcess create_model() called ==================================
2024-06-10 12:39:07,503:INFO:Initializing create_model()
2024-06-10 12:39:07,503:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AF7743760>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029AF516EE20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'solver': 'eigen', 'shrinkage': 'auto'})
2024-06-10 12:39:07,503:INFO:Checking exceptions
2024-06-10 12:39:07,503:INFO:Importing libraries
2024-06-10 12:39:07,503:INFO:Copying training dataset
2024-06-10 12:39:07,503:INFO:Defining folds
2024-06-10 12:39:07,503:INFO:Declaring metric variables
2024-06-10 12:39:07,513:INFO:Importing untrained model
2024-06-10 12:39:07,513:INFO:Declaring custom model
2024-06-10 12:39:07,513:INFO:Linear Discriminant Analysis Imported successfully
2024-06-10 12:39:07,531:INFO:Starting cross validation
2024-06-10 12:39:07,531:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 12:39:07,634:INFO:Calculating mean and std
2024-06-10 12:39:07,634:INFO:Creating metrics dataframe
2024-06-10 12:39:07,636:INFO:Finalizing model
2024-06-10 12:39:07,658:INFO:Uploading results into container
2024-06-10 12:39:07,665:INFO:Uploading model into container now
2024-06-10 12:39:07,666:INFO:_master_model_container: 15
2024-06-10 12:39:07,666:INFO:_display_container: 9
2024-06-10 12:39:07,668:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage='auto', solver='eigen',
                           store_covariance=False, tol=0.0001)
2024-06-10 12:39:07,668:INFO:create_model() successfully completed......................................
2024-06-10 12:39:07,854:INFO:SubProcess create_model() end ==================================
2024-06-10 12:39:07,854:INFO:choose_better activated
2024-06-10 12:39:07,854:INFO:SubProcess create_model() called ==================================
2024-06-10 12:39:07,854:INFO:Initializing create_model()
2024-06-10 12:39:07,860:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AF7743760>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 12:39:07,860:INFO:Checking exceptions
2024-06-10 12:39:07,864:INFO:Importing libraries
2024-06-10 12:39:07,864:INFO:Copying training dataset
2024-06-10 12:39:07,864:INFO:Defining folds
2024-06-10 12:39:07,864:INFO:Declaring metric variables
2024-06-10 12:39:07,864:INFO:Importing untrained model
2024-06-10 12:39:07,864:INFO:Declaring custom model
2024-06-10 12:39:07,864:INFO:Linear Discriminant Analysis Imported successfully
2024-06-10 12:39:07,864:INFO:Starting cross validation
2024-06-10 12:39:07,864:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 12:39:07,971:INFO:Calculating mean and std
2024-06-10 12:39:07,971:INFO:Creating metrics dataframe
2024-06-10 12:39:07,971:INFO:Finalizing model
2024-06-10 12:39:07,981:INFO:Uploading results into container
2024-06-10 12:39:07,981:INFO:Uploading model into container now
2024-06-10 12:39:07,981:INFO:_master_model_container: 16
2024-06-10 12:39:07,981:INFO:_display_container: 10
2024-06-10 12:39:07,981:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-06-10 12:39:07,981:INFO:create_model() successfully completed......................................
2024-06-10 12:39:08,174:INFO:SubProcess create_model() end ==================================
2024-06-10 12:39:08,174:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001) result for AUC is 0.8245
2024-06-10 12:39:08,174:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage='auto', solver='eigen',
                           store_covariance=False, tol=0.0001) result for AUC is 0.8245
2024-06-10 12:39:08,174:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001) is best model
2024-06-10 12:39:08,174:INFO:choose_better completed
2024-06-10 12:39:08,174:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-06-10 12:39:08,194:INFO:_master_model_container: 16
2024-06-10 12:39:08,194:INFO:_display_container: 9
2024-06-10 12:39:08,194:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-06-10 12:39:08,196:INFO:tune_model() successfully completed......................................
2024-06-10 12:39:08,389:INFO:Initializing tune_model()
2024-06-10 12:39:08,389:INFO:tune_model(estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=740, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AF7743760>)
2024-06-10 12:39:08,389:INFO:Checking exceptions
2024-06-10 12:39:08,439:INFO:Copying training dataset
2024-06-10 12:39:08,448:INFO:Checking base model
2024-06-10 12:39:08,448:INFO:Base model : Gradient Boosting Classifier
2024-06-10 12:39:08,451:INFO:Declaring metric variables
2024-06-10 12:39:08,464:INFO:Defining Hyperparameters
2024-06-10 12:39:08,750:INFO:Tuning with n_jobs=-1
2024-06-10 12:39:08,752:INFO:Initializing RandomizedSearchCV
2024-06-10 12:39:19,144:INFO:best_params: {'actual_estimator__subsample': 0.8, 'actual_estimator__n_estimators': 280, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.01, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 11, 'actual_estimator__learning_rate': 0.01}
2024-06-10 12:39:19,149:INFO:Hyperparameter search completed
2024-06-10 12:39:19,150:INFO:SubProcess create_model() called ==================================
2024-06-10 12:39:19,152:INFO:Initializing create_model()
2024-06-10 12:39:19,153:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AF7743760>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=740, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029AEBE37F70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.8, 'n_estimators': 280, 'min_samples_split': 5, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.01, 'max_features': 'sqrt', 'max_depth': 11, 'learning_rate': 0.01})
2024-06-10 12:39:19,153:INFO:Checking exceptions
2024-06-10 12:39:19,153:INFO:Importing libraries
2024-06-10 12:39:19,153:INFO:Copying training dataset
2024-06-10 12:39:19,159:INFO:Defining folds
2024-06-10 12:39:19,161:INFO:Declaring metric variables
2024-06-10 12:39:19,165:INFO:Importing untrained model
2024-06-10 12:39:19,165:INFO:Declaring custom model
2024-06-10 12:39:19,178:INFO:Gradient Boosting Classifier Imported successfully
2024-06-10 12:39:19,191:INFO:Starting cross validation
2024-06-10 12:39:19,191:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 12:39:22,566:INFO:Calculating mean and std
2024-06-10 12:39:22,566:INFO:Creating metrics dataframe
2024-06-10 12:39:22,577:INFO:Finalizing model
2024-06-10 12:39:23,664:INFO:Uploading results into container
2024-06-10 12:39:23,664:INFO:Uploading model into container now
2024-06-10 12:39:23,664:INFO:_master_model_container: 17
2024-06-10 12:39:23,664:INFO:_display_container: 10
2024-06-10 12:39:23,664:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='log_loss', max_depth=11,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.01, min_samples_leaf=4,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=280, n_iter_no_change=None,
                           random_state=740, subsample=0.8, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-06-10 12:39:23,664:INFO:create_model() successfully completed......................................
2024-06-10 12:39:23,941:INFO:SubProcess create_model() end ==================================
2024-06-10 12:39:23,941:INFO:choose_better activated
2024-06-10 12:39:23,948:INFO:SubProcess create_model() called ==================================
2024-06-10 12:39:23,948:INFO:Initializing create_model()
2024-06-10 12:39:23,948:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AF7743760>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=740, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 12:39:23,948:INFO:Checking exceptions
2024-06-10 12:39:23,954:INFO:Importing libraries
2024-06-10 12:39:23,954:INFO:Copying training dataset
2024-06-10 12:39:23,958:INFO:Defining folds
2024-06-10 12:39:23,958:INFO:Declaring metric variables
2024-06-10 12:39:23,958:INFO:Importing untrained model
2024-06-10 12:39:23,958:INFO:Declaring custom model
2024-06-10 12:39:23,959:INFO:Gradient Boosting Classifier Imported successfully
2024-06-10 12:39:23,959:INFO:Starting cross validation
2024-06-10 12:39:23,959:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 12:39:24,511:INFO:Calculating mean and std
2024-06-10 12:39:24,511:INFO:Creating metrics dataframe
2024-06-10 12:39:24,515:INFO:Finalizing model
2024-06-10 12:39:24,703:INFO:Uploading results into container
2024-06-10 12:39:24,703:INFO:Uploading model into container now
2024-06-10 12:39:24,703:INFO:_master_model_container: 18
2024-06-10 12:39:24,703:INFO:_display_container: 11
2024-06-10 12:39:24,703:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=740, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-06-10 12:39:24,703:INFO:create_model() successfully completed......................................
2024-06-10 12:39:24,879:INFO:SubProcess create_model() end ==================================
2024-06-10 12:39:24,879:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=740, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for AUC is 0.7942
2024-06-10 12:39:24,880:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='log_loss', max_depth=11,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.01, min_samples_leaf=4,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=280, n_iter_no_change=None,
                           random_state=740, subsample=0.8, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for AUC is 0.8096
2024-06-10 12:39:24,881:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='log_loss', max_depth=11,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.01, min_samples_leaf=4,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=280, n_iter_no_change=None,
                           random_state=740, subsample=0.8, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2024-06-10 12:39:24,881:INFO:choose_better completed
2024-06-10 12:39:24,892:INFO:_master_model_container: 18
2024-06-10 12:39:24,892:INFO:_display_container: 10
2024-06-10 12:39:24,892:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='log_loss', max_depth=11,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.01, min_samples_leaf=4,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=280, n_iter_no_change=None,
                           random_state=740, subsample=0.8, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-06-10 12:39:24,892:INFO:tune_model() successfully completed......................................
2024-06-10 12:39:51,906:INFO:Initializing stack_models()
2024-06-10 12:39:51,906:INFO:stack_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AF7743760>, estimator_list=[LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=740, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=740, verbose=0,
                       warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=740, verbose=0,
                     warm_start=False), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=740, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)], meta_model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=740, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), meta_model_fold=5, fold=None, round=4, method=auto, restack=False, choose_better=False, optimize=AUC, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2024-06-10 12:39:51,906:INFO:Checking exceptions
2024-06-10 12:39:51,915:INFO:Defining meta model
2024-06-10 12:39:52,025:INFO:Getting model names
2024-06-10 12:39:52,029:INFO:[('Logistic Regression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=740, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)), ('Linear Discriminant Analysis', LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)), ('Random Forest Classifier', RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=740, verbose=0,
                       warm_start=False)), ('Extra Trees Classifier', ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=740, verbose=0,
                     warm_start=False)), ('Gradient Boosting Classifier', GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=740, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False))]
2024-06-10 12:39:52,038:INFO:SubProcess create_model() called ==================================
2024-06-10 12:39:52,056:INFO:Initializing create_model()
2024-06-10 12:39:52,056:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AF7743760>, estimator=StackingClassifier(cv=5,
                   estimators=[('Logistic Regression',
                                LogisticRegression(C=1.0, class_weight=None,
                                                   dual=False,
                                                   fit_intercept=True,
                                                   intercept_scaling=1,
                                                   l1_ratio=None, max_iter=1000,
                                                   multi_class='auto',
                                                   n_jobs=None, penalty='l2',
                                                   random_state=740,
                                                   solver='lbfgs', tol=0.0001,
                                                   verbose=0,
                                                   warm_start=False)),
                               ('Linear Discriminant Analysis',
                                LinearDiscriminantAnalysi...
                                                           validation_fraction=0.1,
                                                           verbose=0,
                                                           warm_start=False))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=740,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=False, stack_method='auto',
                   verbose=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029AF58E2130>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 12:39:52,056:INFO:Checking exceptions
2024-06-10 12:39:52,056:INFO:Importing libraries
2024-06-10 12:39:52,056:INFO:Copying training dataset
2024-06-10 12:39:52,076:INFO:Defining folds
2024-06-10 12:39:52,079:INFO:Declaring metric variables
2024-06-10 12:39:52,088:INFO:Importing untrained model
2024-06-10 12:39:52,093:INFO:Declaring custom model
2024-06-10 12:39:52,113:INFO:Stacking Classifier Imported successfully
2024-06-10 12:39:52,130:INFO:Starting cross validation
2024-06-10 12:39:52,130:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 12:40:03,210:INFO:Calculating mean and std
2024-06-10 12:40:03,214:INFO:Creating metrics dataframe
2024-06-10 12:40:03,230:INFO:Finalizing model
2024-06-10 12:40:04,780:INFO:Uploading results into container
2024-06-10 12:40:04,784:INFO:Uploading model into container now
2024-06-10 12:40:04,784:INFO:_master_model_container: 19
2024-06-10 12:40:04,784:INFO:_display_container: 11
2024-06-10 12:40:04,802:INFO:StackingClassifier(cv=5,
                   estimators=[('Logistic Regression',
                                LogisticRegression(C=1.0, class_weight=None,
                                                   dual=False,
                                                   fit_intercept=True,
                                                   intercept_scaling=1,
                                                   l1_ratio=None, max_iter=1000,
                                                   multi_class='auto',
                                                   n_jobs=None, penalty='l2',
                                                   random_state=740,
                                                   solver='lbfgs', tol=0.0001,
                                                   verbose=0,
                                                   warm_start=False)),
                               ('Linear Discriminant Analysis',
                                LinearDiscriminantAnalysi...
                                                           validation_fraction=0.1,
                                                           verbose=0,
                                                           warm_start=False))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=740,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=False, stack_method='auto',
                   verbose=0)
2024-06-10 12:40:04,802:INFO:create_model() successfully completed......................................
2024-06-10 12:40:05,047:INFO:SubProcess create_model() end ==================================
2024-06-10 12:40:05,066:INFO:_master_model_container: 19
2024-06-10 12:40:05,066:INFO:_display_container: 11
2024-06-10 12:40:05,081:INFO:StackingClassifier(cv=5,
                   estimators=[('Logistic Regression',
                                LogisticRegression(C=1.0, class_weight=None,
                                                   dual=False,
                                                   fit_intercept=True,
                                                   intercept_scaling=1,
                                                   l1_ratio=None, max_iter=1000,
                                                   multi_class='auto',
                                                   n_jobs=None, penalty='l2',
                                                   random_state=740,
                                                   solver='lbfgs', tol=0.0001,
                                                   verbose=0,
                                                   warm_start=False)),
                               ('Linear Discriminant Analysis',
                                LinearDiscriminantAnalysi...
                                                           validation_fraction=0.1,
                                                           verbose=0,
                                                           warm_start=False))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=740,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=False, stack_method='auto',
                   verbose=0)
2024-06-10 12:40:05,081:INFO:stack_models() successfully completed......................................
2024-06-10 12:40:08,361:INFO:Initializing plot_model()
2024-06-10 12:40:08,361:INFO:plot_model(plot=boundary, fold=None, verbose=True, display=None, display_format=None, estimator=StackingClassifier(cv=5,
                   estimators=[('Logistic Regression',
                                LogisticRegression(C=1.0, class_weight=None,
                                                   dual=False,
                                                   fit_intercept=True,
                                                   intercept_scaling=1,
                                                   l1_ratio=None, max_iter=1000,
                                                   multi_class='auto',
                                                   n_jobs=None, penalty='l2',
                                                   random_state=740,
                                                   solver='lbfgs', tol=0.0001,
                                                   verbose=0,
                                                   warm_start=False)),
                               ('Linear Discriminant Analysis',
                                LinearDiscriminantAnalysi...
                                                           validation_fraction=0.1,
                                                           verbose=0,
                                                           warm_start=False))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=740,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=False, stack_method='auto',
                   verbose=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AF7743760>, system=True)
2024-06-10 12:40:08,361:INFO:Checking exceptions
2024-06-10 12:40:08,369:INFO:Preloading libraries
2024-06-10 12:40:08,422:INFO:Copying training dataset
2024-06-10 12:40:08,422:INFO:Plot type: boundary
2024-06-10 12:40:08,469:INFO:Fitting StandardScaler()
2024-06-10 12:40:08,481:INFO:Fitting PCA()
2024-06-10 12:40:08,536:INFO:Fitting Model
2024-06-10 12:40:12,085:INFO:Visual Rendered Successfully
2024-06-10 12:40:12,351:INFO:plot_model() successfully completed......................................
2024-06-10 12:40:14,150:INFO:Initializing plot_model()
2024-06-10 12:40:14,150:INFO:plot_model(plot=auc, fold=None, verbose=True, display=None, display_format=None, estimator=StackingClassifier(cv=5,
                   estimators=[('Logistic Regression',
                                LogisticRegression(C=1.0, class_weight=None,
                                                   dual=False,
                                                   fit_intercept=True,
                                                   intercept_scaling=1,
                                                   l1_ratio=None, max_iter=1000,
                                                   multi_class='auto',
                                                   n_jobs=None, penalty='l2',
                                                   random_state=740,
                                                   solver='lbfgs', tol=0.0001,
                                                   verbose=0,
                                                   warm_start=False)),
                               ('Linear Discriminant Analysis',
                                LinearDiscriminantAnalysi...
                                                           validation_fraction=0.1,
                                                           verbose=0,
                                                           warm_start=False))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=740,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=False, stack_method='auto',
                   verbose=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AF7743760>, system=True)
2024-06-10 12:40:14,150:INFO:Checking exceptions
2024-06-10 12:40:14,157:INFO:Preloading libraries
2024-06-10 12:40:14,211:INFO:Copying training dataset
2024-06-10 12:40:14,211:INFO:Plot type: auc
2024-06-10 12:40:14,295:INFO:Fitting Model
2024-06-10 12:40:14,299:INFO:Scoring test/hold-out set
2024-06-10 12:40:15,318:INFO:Visual Rendered Successfully
2024-06-10 12:40:15,637:INFO:plot_model() successfully completed......................................
2024-06-10 12:40:18,802:INFO:Initializing blend_models()
2024-06-10 12:40:18,802:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AF7743760>, estimator_list=[LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=740, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=740, verbose=0,
                       warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=740, verbose=0,
                     warm_start=False), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=740, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)], fold=None, round=4, choose_better=False, optimize=AUC, method=soft, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2024-06-10 12:40:18,802:INFO:Checking exceptions
2024-06-10 12:40:18,890:INFO:Importing libraries
2024-06-10 12:40:18,893:INFO:Copying training dataset
2024-06-10 12:40:18,907:INFO:Getting model names
2024-06-10 12:40:18,920:INFO:SubProcess create_model() called ==================================
2024-06-10 12:40:18,936:INFO:Initializing create_model()
2024-06-10 12:40:18,936:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AF7743760>, estimator=VotingClassifier(estimators=[('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=740,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covar...
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=740,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029AF15E4DF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 12:40:18,936:INFO:Checking exceptions
2024-06-10 12:40:18,936:INFO:Importing libraries
2024-06-10 12:40:18,936:INFO:Copying training dataset
2024-06-10 12:40:18,950:INFO:Defining folds
2024-06-10 12:40:18,950:INFO:Declaring metric variables
2024-06-10 12:40:18,962:INFO:Importing untrained model
2024-06-10 12:40:18,962:INFO:Declaring custom model
2024-06-10 12:40:18,979:INFO:Voting Classifier Imported successfully
2024-06-10 12:40:19,001:INFO:Starting cross validation
2024-06-10 12:40:19,001:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 12:40:21,312:INFO:Calculating mean and std
2024-06-10 12:40:21,314:INFO:Creating metrics dataframe
2024-06-10 12:40:21,324:INFO:Finalizing model
2024-06-10 12:40:21,673:INFO:Uploading results into container
2024-06-10 12:40:21,681:INFO:Uploading model into container now
2024-06-10 12:40:21,681:INFO:_master_model_container: 20
2024-06-10 12:40:21,681:INFO:_display_container: 12
2024-06-10 12:40:21,698:INFO:VotingClassifier(estimators=[('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=740,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covar...
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=740,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2024-06-10 12:40:21,701:INFO:create_model() successfully completed......................................
2024-06-10 12:40:21,998:INFO:SubProcess create_model() end ==================================
2024-06-10 12:40:22,032:INFO:_master_model_container: 20
2024-06-10 12:40:22,032:INFO:_display_container: 12
2024-06-10 12:40:22,056:INFO:VotingClassifier(estimators=[('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=740,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covar...
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=740,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2024-06-10 12:40:22,057:INFO:blend_models() successfully completed......................................
2024-06-10 12:40:22,406:INFO:Initializing plot_model()
2024-06-10 12:40:22,411:INFO:plot_model(plot=boundary, fold=None, verbose=True, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=740,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covar...
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=740,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AF7743760>, system=True)
2024-06-10 12:40:22,411:INFO:Checking exceptions
2024-06-10 12:40:22,427:INFO:Preloading libraries
2024-06-10 12:40:22,520:INFO:Copying training dataset
2024-06-10 12:40:22,520:INFO:Plot type: boundary
2024-06-10 12:40:22,556:INFO:Fitting StandardScaler()
2024-06-10 12:40:22,568:INFO:Fitting PCA()
2024-06-10 12:40:22,598:INFO:Fitting Model
2024-06-10 12:40:25,081:INFO:Visual Rendered Successfully
2024-06-10 12:40:25,324:INFO:plot_model() successfully completed......................................
2024-06-10 12:40:25,354:INFO:Initializing plot_model()
2024-06-10 12:40:25,354:INFO:plot_model(plot=auc, fold=None, verbose=True, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=740,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covar...
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=740,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AF7743760>, system=True)
2024-06-10 12:40:25,354:INFO:Checking exceptions
2024-06-10 12:40:25,358:INFO:Preloading libraries
2024-06-10 12:40:25,395:INFO:Copying training dataset
2024-06-10 12:40:25,395:INFO:Plot type: auc
2024-06-10 12:40:25,435:INFO:Fitting Model
2024-06-10 12:40:25,435:INFO:Scoring test/hold-out set
2024-06-10 12:40:26,125:INFO:Visual Rendered Successfully
2024-06-10 12:40:26,319:INFO:plot_model() successfully completed......................................
2024-06-10 12:40:27,183:INFO:Initializing blend_models()
2024-06-10 12:40:27,183:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AF7743760>, estimator_list=[LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=740, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=740, verbose=0,
                       warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=740, verbose=0,
                     warm_start=False), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=740, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)], fold=None, round=4, choose_better=False, optimize=AUC, method=hard, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2024-06-10 12:40:27,183:INFO:Checking exceptions
2024-06-10 12:40:27,320:INFO:Importing libraries
2024-06-10 12:40:27,320:INFO:Copying training dataset
2024-06-10 12:40:27,328:INFO:Getting model names
2024-06-10 12:40:27,346:INFO:SubProcess create_model() called ==================================
2024-06-10 12:40:27,354:INFO:Initializing create_model()
2024-06-10 12:40:27,357:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AF7743760>, estimator=VotingClassifier(estimators=[('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=740,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covar...
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=740,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029AF9A37400>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 12:40:27,357:INFO:Checking exceptions
2024-06-10 12:40:27,357:INFO:Importing libraries
2024-06-10 12:40:27,357:INFO:Copying training dataset
2024-06-10 12:40:27,369:INFO:Defining folds
2024-06-10 12:40:27,369:INFO:Declaring metric variables
2024-06-10 12:40:27,385:INFO:Importing untrained model
2024-06-10 12:40:27,385:INFO:Declaring custom model
2024-06-10 12:40:27,401:INFO:Voting Classifier Imported successfully
2024-06-10 12:40:27,426:INFO:Starting cross validation
2024-06-10 12:40:27,426:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 12:40:28,668:WARNING:C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2024-06-10 12:40:28,668:WARNING:C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2024-06-10 12:40:28,683:WARNING:C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2024-06-10 12:40:28,742:WARNING:C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2024-06-10 12:40:28,757:WARNING:C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2024-06-10 12:40:28,778:WARNING:C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2024-06-10 12:40:28,778:WARNING:C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2024-06-10 12:40:28,778:WARNING:C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2024-06-10 12:40:29,380:WARNING:C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2024-06-10 12:40:29,412:WARNING:C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2024-06-10 12:40:29,442:INFO:Calculating mean and std
2024-06-10 12:40:29,442:INFO:Creating metrics dataframe
2024-06-10 12:40:29,462:INFO:Finalizing model
2024-06-10 12:40:29,821:INFO:Uploading results into container
2024-06-10 12:40:29,821:INFO:Uploading model into container now
2024-06-10 12:40:29,824:INFO:_master_model_container: 21
2024-06-10 12:40:29,824:INFO:_display_container: 13
2024-06-10 12:40:29,850:INFO:VotingClassifier(estimators=[('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=740,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covar...
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=740,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None)
2024-06-10 12:40:29,850:INFO:create_model() successfully completed......................................
2024-06-10 12:40:30,110:INFO:SubProcess create_model() end ==================================
2024-06-10 12:40:30,132:INFO:_master_model_container: 21
2024-06-10 12:40:30,132:INFO:_display_container: 13
2024-06-10 12:40:30,141:INFO:VotingClassifier(estimators=[('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=740,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covar...
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=740,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None)
2024-06-10 12:40:30,141:INFO:blend_models() successfully completed......................................
2024-06-10 12:40:43,618:INFO:Initializing plot_model()
2024-06-10 12:40:43,618:INFO:plot_model(plot=boundary, fold=None, verbose=True, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=740,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covar...
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=740,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AF7743760>, system=True)
2024-06-10 12:40:43,618:INFO:Checking exceptions
2024-06-10 12:40:43,628:INFO:Preloading libraries
2024-06-10 12:40:43,660:INFO:Copying training dataset
2024-06-10 12:40:43,660:INFO:Plot type: boundary
2024-06-10 12:40:43,691:INFO:Fitting StandardScaler()
2024-06-10 12:40:43,705:INFO:Fitting PCA()
2024-06-10 12:40:43,734:INFO:Fitting Model
2024-06-10 12:40:46,790:INFO:Visual Rendered Successfully
2024-06-10 12:40:47,053:INFO:plot_model() successfully completed......................................
2024-06-10 12:40:51,566:INFO:Initializing calibrate_model()
2024-06-10 12:40:51,568:INFO:calibrate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AF7743760>, estimator=VotingClassifier(estimators=[('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=740,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covar...
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=740,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), method=sigmoid, calibrate_fold=5, fold=None, round=4, fit_kwargs=None, groups=None, verbose=True, return_train_score=False)
2024-06-10 12:40:51,568:INFO:Checking exceptions
2024-06-10 12:40:51,569:INFO:Preloading libraries
2024-06-10 12:40:51,569:INFO:Preparing display monitor
2024-06-10 12:40:51,638:INFO:Getting model name
2024-06-10 12:40:51,638:INFO:Base model : Voting Classifier
2024-06-10 12:40:51,661:INFO:Importing untrained CalibratedClassifierCV
2024-06-10 12:40:51,661:INFO:SubProcess create_model() called ==================================
2024-06-10 12:40:51,687:INFO:Initializing create_model()
2024-06-10 12:40:51,687:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AF7743760>, estimator=CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=VotingClassifier(estimators=[('Logistic '
                                                               'Regression',
                                                               LogisticRegression(C=1.0,
                                                                                  class_weight=None,
                                                                                  dual=False,
                                                                                  fit_intercept=True,
                                                                                  intercept_scaling=1,
                                                                                  l1_ratio=None,
                                                                                  max_iter=1000,
                                                                                  multi_class='auto',
                                                                                  n_jobs=None,
                                                                                  penalty='l2',
                                                                                  random_state=740,
                                                                                  solver='lbfgs',
                                                                                  tol=0.0001,
                                                                                  verbose=0,
                                                                                  warm_start=False)),
                                                              ('Linear...
                                                                                          max_leaf_nodes=None,
                                                                                          min_impurity_decrease=0.0,
                                                                                          min_samples_leaf=1,
                                                                                          min_samples_split=2,
                                                                                          min_weight_fraction_leaf=0.0,
                                                                                          n_estimators=100,
                                                                                          n_iter_no_change=None,
                                                                                          random_state=740,
                                                                                          subsample=1.0,
                                                                                          tol=0.0001,
                                                                                          validation_fraction=0.1,
                                                                                          verbose=0,
                                                                                          warm_start=False))],
                                                  flatten_transform=True,
                                                  n_jobs=-1, verbose=False,
                                                  voting='soft', weights=None),
                       method='sigmoid', n_jobs=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029A833F4D00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 12:40:51,690:INFO:Checking exceptions
2024-06-10 12:40:51,690:INFO:Importing libraries
2024-06-10 12:40:51,690:INFO:Copying training dataset
2024-06-10 12:40:51,697:INFO:Defining folds
2024-06-10 12:40:51,697:INFO:Declaring metric variables
2024-06-10 12:40:51,709:INFO:Importing untrained model
2024-06-10 12:40:51,709:INFO:Declaring custom model
2024-06-10 12:40:51,725:INFO:Voting Classifier Imported successfully
2024-06-10 12:40:51,734:INFO:Starting cross validation
2024-06-10 12:40:51,734:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-10 12:41:04,534:INFO:Calculating mean and std
2024-06-10 12:41:04,539:INFO:Creating metrics dataframe
2024-06-10 12:41:04,551:INFO:Finalizing model
2024-06-10 12:41:07,035:INFO:Uploading results into container
2024-06-10 12:41:07,040:INFO:Uploading model into container now
2024-06-10 12:41:07,040:INFO:_master_model_container: 22
2024-06-10 12:41:07,040:INFO:_display_container: 14
2024-06-10 12:41:07,082:INFO:CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=VotingClassifier(estimators=[('Logistic '
                                                               'Regression',
                                                               LogisticRegression(C=1.0,
                                                                                  class_weight=None,
                                                                                  dual=False,
                                                                                  fit_intercept=True,
                                                                                  intercept_scaling=1,
                                                                                  l1_ratio=None,
                                                                                  max_iter=1000,
                                                                                  multi_class='auto',
                                                                                  n_jobs=None,
                                                                                  penalty='l2',
                                                                                  random_state=740,
                                                                                  solver='lbfgs',
                                                                                  tol=0.0001,
                                                                                  verbose=0,
                                                                                  warm_start=False)),
                                                              ('Linear...
                                                                                          max_leaf_nodes=None,
                                                                                          min_impurity_decrease=0.0,
                                                                                          min_samples_leaf=1,
                                                                                          min_samples_split=2,
                                                                                          min_weight_fraction_leaf=0.0,
                                                                                          n_estimators=100,
                                                                                          n_iter_no_change=None,
                                                                                          random_state=740,
                                                                                          subsample=1.0,
                                                                                          tol=0.0001,
                                                                                          validation_fraction=0.1,
                                                                                          verbose=0,
                                                                                          warm_start=False))],
                                                  flatten_transform=True,
                                                  n_jobs=-1, verbose=False,
                                                  voting='soft', weights=None),
                       method='sigmoid', n_jobs=None)
2024-06-10 12:41:07,082:INFO:create_model() successfully completed......................................
2024-06-10 12:41:07,279:INFO:SubProcess create_model() end ==================================
2024-06-10 12:41:07,300:INFO:_master_model_container: 22
2024-06-10 12:41:07,300:INFO:_display_container: 14
2024-06-10 12:41:07,321:INFO:CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=VotingClassifier(estimators=[('Logistic '
                                                               'Regression',
                                                               LogisticRegression(C=1.0,
                                                                                  class_weight=None,
                                                                                  dual=False,
                                                                                  fit_intercept=True,
                                                                                  intercept_scaling=1,
                                                                                  l1_ratio=None,
                                                                                  max_iter=1000,
                                                                                  multi_class='auto',
                                                                                  n_jobs=None,
                                                                                  penalty='l2',
                                                                                  random_state=740,
                                                                                  solver='lbfgs',
                                                                                  tol=0.0001,
                                                                                  verbose=0,
                                                                                  warm_start=False)),
                                                              ('Linear...
                                                                                          max_leaf_nodes=None,
                                                                                          min_impurity_decrease=0.0,
                                                                                          min_samples_leaf=1,
                                                                                          min_samples_split=2,
                                                                                          min_weight_fraction_leaf=0.0,
                                                                                          n_estimators=100,
                                                                                          n_iter_no_change=None,
                                                                                          random_state=740,
                                                                                          subsample=1.0,
                                                                                          tol=0.0001,
                                                                                          validation_fraction=0.1,
                                                                                          verbose=0,
                                                                                          warm_start=False))],
                                                  flatten_transform=True,
                                                  n_jobs=-1, verbose=False,
                                                  voting='soft', weights=None),
                       method='sigmoid', n_jobs=None)
2024-06-10 12:41:07,321:INFO:calibrate_model() successfully completed......................................
2024-06-10 12:41:09,770:INFO:Initializing finalize_model()
2024-06-10 12:41:09,770:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AF7743760>, estimator=CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=VotingClassifier(estimators=[('Logistic '
                                                               'Regression',
                                                               LogisticRegression(C=1.0,
                                                                                  class_weight=None,
                                                                                  dual=False,
                                                                                  fit_intercept=True,
                                                                                  intercept_scaling=1,
                                                                                  l1_ratio=None,
                                                                                  max_iter=1000,
                                                                                  multi_class='auto',
                                                                                  n_jobs=None,
                                                                                  penalty='l2',
                                                                                  random_state=740,
                                                                                  solver='lbfgs',
                                                                                  tol=0.0001,
                                                                                  verbose=0,
                                                                                  warm_start=False)),
                                                              ('Linear...
                                                                                          max_leaf_nodes=None,
                                                                                          min_impurity_decrease=0.0,
                                                                                          min_samples_leaf=1,
                                                                                          min_samples_split=2,
                                                                                          min_weight_fraction_leaf=0.0,
                                                                                          n_estimators=100,
                                                                                          n_iter_no_change=None,
                                                                                          random_state=740,
                                                                                          subsample=1.0,
                                                                                          tol=0.0001,
                                                                                          validation_fraction=0.1,
                                                                                          verbose=0,
                                                                                          warm_start=False))],
                                                  flatten_transform=True,
                                                  n_jobs=-1, verbose=False,
                                                  voting='soft', weights=None),
                       method='sigmoid', n_jobs=None), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-06-10 12:41:09,795:INFO:Finalizing CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=VotingClassifier(estimators=[('Logistic '
                                                               'Regression',
                                                               LogisticRegression(C=1.0,
                                                                                  class_weight=None,
                                                                                  dual=False,
                                                                                  fit_intercept=True,
                                                                                  intercept_scaling=1,
                                                                                  l1_ratio=None,
                                                                                  max_iter=1000,
                                                                                  multi_class='auto',
                                                                                  n_jobs=None,
                                                                                  penalty='l2',
                                                                                  random_state=740,
                                                                                  solver='lbfgs',
                                                                                  tol=0.0001,
                                                                                  verbose=0,
                                                                                  warm_start=False)),
                                                              ('Linear...
                                                                                          max_leaf_nodes=None,
                                                                                          min_impurity_decrease=0.0,
                                                                                          min_samples_leaf=1,
                                                                                          min_samples_split=2,
                                                                                          min_weight_fraction_leaf=0.0,
                                                                                          n_estimators=100,
                                                                                          n_iter_no_change=None,
                                                                                          random_state=740,
                                                                                          subsample=1.0,
                                                                                          tol=0.0001,
                                                                                          validation_fraction=0.1,
                                                                                          verbose=0,
                                                                                          warm_start=False))],
                                                  flatten_transform=True,
                                                  n_jobs=-1, verbose=False,
                                                  voting='soft', weights=None),
                       method='sigmoid', n_jobs=None)
2024-06-10 12:41:09,815:INFO:Initializing create_model()
2024-06-10 12:41:09,815:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AF7743760>, estimator=CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=VotingClassifier(estimators=[('Logistic '
                                                               'Regression',
                                                               LogisticRegression(C=1.0,
                                                                                  class_weight=None,
                                                                                  dual=False,
                                                                                  fit_intercept=True,
                                                                                  intercept_scaling=1,
                                                                                  l1_ratio=None,
                                                                                  max_iter=1000,
                                                                                  multi_class='auto',
                                                                                  n_jobs=None,
                                                                                  penalty='l2',
                                                                                  random_state=740,
                                                                                  solver='lbfgs',
                                                                                  tol=0.0001,
                                                                                  verbose=0,
                                                                                  warm_start=False)),
                                                              ('Linear...
                                                                                          max_leaf_nodes=None,
                                                                                          min_impurity_decrease=0.0,
                                                                                          min_samples_leaf=1,
                                                                                          min_samples_split=2,
                                                                                          min_weight_fraction_leaf=0.0,
                                                                                          n_estimators=100,
                                                                                          n_iter_no_change=None,
                                                                                          random_state=740,
                                                                                          subsample=1.0,
                                                                                          tol=0.0001,
                                                                                          validation_fraction=0.1,
                                                                                          verbose=0,
                                                                                          warm_start=False))],
                                                  flatten_transform=True,
                                                  n_jobs=-1, verbose=False,
                                                  voting='soft', weights=None),
                       method='sigmoid', n_jobs=None), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-06-10 12:41:09,815:INFO:Checking exceptions
2024-06-10 12:41:09,817:INFO:Importing libraries
2024-06-10 12:41:09,817:INFO:Copying training dataset
2024-06-10 12:41:09,817:INFO:Defining folds
2024-06-10 12:41:09,817:INFO:Declaring metric variables
2024-06-10 12:41:09,817:INFO:Importing untrained model
2024-06-10 12:41:09,817:INFO:Declaring custom model
2024-06-10 12:41:09,817:INFO:Voting Classifier Imported successfully
2024-06-10 12:41:09,817:INFO:Cross validation set to False
2024-06-10 12:41:09,817:INFO:Fitting Model
2024-06-10 12:41:12,687:INFO:Pipeline(memory=Memory(location=None),
         steps=[('placeholder', None),
                ('actual_estimator',
                 CalibratedClassifierCV(cv=5, ensemble=True,
                                        estimator=VotingClassifier(estimators=[('Logistic '
                                                                                'Regression',
                                                                                LogisticRegression(C=1.0,
                                                                                                   class_weight=None,
                                                                                                   dual=False,
                                                                                                   fit_intercept=True,
                                                                                                   intercept_scaling=1,
                                                                                                   l1_ratio=None,
                                                                                                   max_iter=1000,
                                                                                                   multi_class='auto',
                                                                                                   n_jobs=None,
                                                                                                   penalty...
                                                                                                           min_impurity_decrease=0.0,
                                                                                                           min_samples_leaf=1,
                                                                                                           min_samples_split=2,
                                                                                                           min_weight_fraction_leaf=0.0,
                                                                                                           n_estimators=100,
                                                                                                           n_iter_no_change=None,
                                                                                                           random_state=740,
                                                                                                           subsample=1.0,
                                                                                                           tol=0.0001,
                                                                                                           validation_fraction=0.1,
                                                                                                           verbose=0,
                                                                                                           warm_start=False))],
                                                                   flatten_transform=True,
                                                                   n_jobs=-1,
                                                                   verbose=False,
                                                                   voting='soft',
                                                                   weights=None),
                                        method='sigmoid', n_jobs=None))],
         verbose=False)
2024-06-10 12:41:12,687:INFO:create_model() successfully completed......................................
2024-06-10 12:41:12,878:INFO:_master_model_container: 22
2024-06-10 12:41:12,878:INFO:_display_container: 14
2024-06-10 12:41:12,934:INFO:Pipeline(memory=Memory(location=None),
         steps=[('placeholder', None),
                ('actual_estimator',
                 CalibratedClassifierCV(cv=5, ensemble=True,
                                        estimator=VotingClassifier(estimators=[('Logistic '
                                                                                'Regression',
                                                                                LogisticRegression(C=1.0,
                                                                                                   class_weight=None,
                                                                                                   dual=False,
                                                                                                   fit_intercept=True,
                                                                                                   intercept_scaling=1,
                                                                                                   l1_ratio=None,
                                                                                                   max_iter=1000,
                                                                                                   multi_class='auto',
                                                                                                   n_jobs=None,
                                                                                                   penalty...
                                                                                                           min_impurity_decrease=0.0,
                                                                                                           min_samples_leaf=1,
                                                                                                           min_samples_split=2,
                                                                                                           min_weight_fraction_leaf=0.0,
                                                                                                           n_estimators=100,
                                                                                                           n_iter_no_change=None,
                                                                                                           random_state=740,
                                                                                                           subsample=1.0,
                                                                                                           tol=0.0001,
                                                                                                           validation_fraction=0.1,
                                                                                                           verbose=0,
                                                                                                           warm_start=False))],
                                                                   flatten_transform=True,
                                                                   n_jobs=-1,
                                                                   verbose=False,
                                                                   voting='soft',
                                                                   weights=None),
                                        method='sigmoid', n_jobs=None))],
         verbose=False)
2024-06-10 12:41:12,934:INFO:finalize_model() successfully completed......................................
2024-06-10 12:41:13,301:INFO:Initializing plot_model()
2024-06-10 12:41:13,301:INFO:plot_model(plot=threshold, fold=None, verbose=True, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('placeholder', None),
                ('actual_estimator',
                 CalibratedClassifierCV(cv=5, ensemble=True,
                                        estimator=VotingClassifier(estimators=[('Logistic '
                                                                                'Regression',
                                                                                LogisticRegression(C=1.0,
                                                                                                   class_weight=None,
                                                                                                   dual=False,
                                                                                                   fit_intercept=True,
                                                                                                   intercept_scaling=1,
                                                                                                   l1_ratio=None,
                                                                                                   max_iter=1000,
                                                                                                   multi_class='auto',
                                                                                                   n_jobs=None,
                                                                                                   penalty...
                                                                                                           min_impurity_decrease=0.0,
                                                                                                           min_samples_leaf=1,
                                                                                                           min_samples_split=2,
                                                                                                           min_weight_fraction_leaf=0.0,
                                                                                                           n_estimators=100,
                                                                                                           n_iter_no_change=None,
                                                                                                           random_state=740,
                                                                                                           subsample=1.0,
                                                                                                           tol=0.0001,
                                                                                                           validation_fraction=0.1,
                                                                                                           verbose=0,
                                                                                                           warm_start=False))],
                                                                   flatten_transform=True,
                                                                   n_jobs=-1,
                                                                   verbose=False,
                                                                   voting='soft',
                                                                   weights=None),
                                        method='sigmoid', n_jobs=None))],
         verbose=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AF7743760>, system=True)
2024-06-10 12:41:13,301:INFO:Checking exceptions
2024-06-10 12:41:13,308:INFO:Preloading libraries
2024-06-10 12:41:13,601:INFO:Copying training dataset
2024-06-10 12:41:13,601:INFO:Plot type: threshold
2024-06-10 12:41:13,635:INFO:Fitting Model
2024-06-10 12:43:16,081:INFO:Scoring test/hold-out set
2024-06-10 12:43:16,701:INFO:Visual Rendered Successfully
2024-06-10 12:43:16,836:INFO:plot_model() successfully completed......................................
2024-06-10 12:43:16,899:INFO:Initializing plot_model()
2024-06-10 12:43:16,899:INFO:plot_model(plot=boundary, fold=None, verbose=True, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('placeholder', None),
                ('actual_estimator',
                 CalibratedClassifierCV(cv=5, ensemble=True,
                                        estimator=VotingClassifier(estimators=[('Logistic '
                                                                                'Regression',
                                                                                LogisticRegression(C=1.0,
                                                                                                   class_weight=None,
                                                                                                   dual=False,
                                                                                                   fit_intercept=True,
                                                                                                   intercept_scaling=1,
                                                                                                   l1_ratio=None,
                                                                                                   max_iter=1000,
                                                                                                   multi_class='auto',
                                                                                                   n_jobs=None,
                                                                                                   penalty...
                                                                                                           min_impurity_decrease=0.0,
                                                                                                           min_samples_leaf=1,
                                                                                                           min_samples_split=2,
                                                                                                           min_weight_fraction_leaf=0.0,
                                                                                                           n_estimators=100,
                                                                                                           n_iter_no_change=None,
                                                                                                           random_state=740,
                                                                                                           subsample=1.0,
                                                                                                           tol=0.0001,
                                                                                                           validation_fraction=0.1,
                                                                                                           verbose=0,
                                                                                                           warm_start=False))],
                                                                   flatten_transform=True,
                                                                   n_jobs=-1,
                                                                   verbose=False,
                                                                   voting='soft',
                                                                   weights=None),
                                        method='sigmoid', n_jobs=None))],
         verbose=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000029AF7743760>, system=True)
2024-06-10 12:43:16,899:INFO:Checking exceptions
2024-06-10 12:43:16,899:INFO:Preloading libraries
2024-06-10 12:43:17,044:INFO:Copying training dataset
2024-06-10 12:43:17,044:INFO:Plot type: boundary
2024-06-10 12:43:17,054:INFO:Fitting StandardScaler()
2024-06-10 12:43:17,065:INFO:Fitting PCA()
2024-06-10 12:43:17,077:INFO:Fitting Model
2024-06-10 12:43:21,243:INFO:Visual Rendered Successfully
2024-06-10 12:43:21,458:INFO:plot_model() successfully completed......................................
2024-06-12 11:22:02,198:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-12 11:22:02,198:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-12 11:22:02,198:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-12 11:22:02,198:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-12 11:22:04,929:INFO:PyCaret ClassificationExperiment
2024-06-12 11:22:04,929:INFO:Logging name: clf-default-name
2024-06-12 11:22:04,929:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-12 11:22:04,929:INFO:version 3.3.2
2024-06-12 11:22:04,929:INFO:Initializing setup()
2024-06-12 11:22:04,929:INFO:self.USI: d6fb
2024-06-12 11:22:04,929:INFO:self._variable_keys: {'gpu_param', 'exp_name_log', 'log_plots_param', 'html_param', 'y_train', 'X_test', 'USI', 'gpu_n_jobs_param', 'memory', 'X', 'logging_param', 'is_multiclass', 'n_jobs_param', 'fold_shuffle_param', 'y_test', 'fold_generator', 'fix_imbalance', '_ml_usecase', 'y', 'seed', 'X_train', 'fold_groups_param', '_available_plots', 'data', 'pipeline', 'idx', 'exp_id', 'target_param'}
2024-06-12 11:22:04,929:INFO:Checking environment
2024-06-12 11:22:04,929:INFO:python_version: 3.9.13
2024-06-12 11:22:04,929:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2024-06-12 11:22:04,929:INFO:machine: AMD64
2024-06-12 11:22:04,929:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-12 11:22:04,929:INFO:Memory: svmem(total=16843341824, available=4714016768, percent=72.0, used=12129325056, free=4714016768)
2024-06-12 11:22:04,929:INFO:Physical Core: 4
2024-06-12 11:22:04,929:INFO:Logical Core: 8
2024-06-12 11:22:04,929:INFO:Checking libraries
2024-06-12 11:22:04,929:INFO:System:
2024-06-12 11:22:04,929:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2024-06-12 11:22:04,929:INFO:executable: c:\ProgramData\Anaconda3\python.exe
2024-06-12 11:22:04,929:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-12 11:22:04,929:INFO:PyCaret required dependencies:
2024-06-12 11:22:05,251:INFO:                 pip: 22.2.2
2024-06-12 11:22:05,251:INFO:          setuptools: 63.4.1
2024-06-12 11:22:05,251:INFO:             pycaret: 3.3.2
2024-06-12 11:22:05,251:INFO:             IPython: 7.31.1
2024-06-12 11:22:05,251:INFO:          ipywidgets: 7.6.5
2024-06-12 11:22:05,251:INFO:                tqdm: 4.64.1
2024-06-12 11:22:05,251:INFO:               numpy: 1.21.5
2024-06-12 11:22:05,251:INFO:              pandas: 1.4.4
2024-06-12 11:22:05,251:INFO:              jinja2: 2.11.3
2024-06-12 11:22:05,256:INFO:               scipy: 1.9.1
2024-06-12 11:22:05,256:INFO:              joblib: 1.1.0
2024-06-12 11:22:05,256:INFO:             sklearn: 1.0.2
2024-06-12 11:22:05,256:INFO:                pyod: 2.0.0
2024-06-12 11:22:05,256:INFO:            imblearn: 0.12.3
2024-06-12 11:22:05,256:INFO:   category_encoders: 2.6.3
2024-06-12 11:22:05,256:INFO:            lightgbm: 4.3.0
2024-06-12 11:22:05,256:INFO:               numba: 0.55.1
2024-06-12 11:22:05,256:INFO:            requests: 2.28.1
2024-06-12 11:22:05,256:INFO:          matplotlib: 3.5.2
2024-06-12 11:22:05,256:INFO:          scikitplot: 0.3.7
2024-06-12 11:22:05,256:INFO:         yellowbrick: 1.5
2024-06-12 11:22:05,256:INFO:              plotly: 5.9.0
2024-06-12 11:22:05,256:INFO:    plotly-resampler: Not installed
2024-06-12 11:22:05,256:INFO:             kaleido: 0.2.1
2024-06-12 11:22:05,256:INFO:           schemdraw: 0.15
2024-06-12 11:22:05,256:INFO:         statsmodels: 0.13.2
2024-06-12 11:22:05,256:INFO:              sktime: 0.26.0
2024-06-12 11:22:05,256:INFO:               tbats: 1.1.3
2024-06-12 11:22:05,256:INFO:            pmdarima: 2.0.4
2024-06-12 11:22:05,256:INFO:              psutil: 5.9.0
2024-06-12 11:22:05,256:INFO:          markupsafe: 2.0.1
2024-06-12 11:22:05,256:INFO:             pickle5: Not installed
2024-06-12 11:22:05,256:INFO:         cloudpickle: 2.0.0
2024-06-12 11:22:05,256:INFO:         deprecation: 2.1.0
2024-06-12 11:22:05,256:INFO:              xxhash: 3.4.1
2024-06-12 11:22:05,256:INFO:           wurlitzer: Not installed
2024-06-12 11:22:05,256:INFO:PyCaret optional dependencies:
2024-06-12 11:22:05,276:INFO:                shap: Not installed
2024-06-12 11:22:05,276:INFO:           interpret: Not installed
2024-06-12 11:22:05,276:INFO:                umap: 0.5.6
2024-06-12 11:22:05,276:INFO:     ydata_profiling: 4.2.0
2024-06-12 11:22:05,276:INFO:  explainerdashboard: Not installed
2024-06-12 11:22:05,276:INFO:             autoviz: Not installed
2024-06-12 11:22:05,276:INFO:           fairlearn: Not installed
2024-06-12 11:22:05,276:INFO:          deepchecks: Not installed
2024-06-12 11:22:05,276:INFO:             xgboost: Not installed
2024-06-12 11:22:05,276:INFO:            catboost: Not installed
2024-06-12 11:22:05,276:INFO:              kmodes: Not installed
2024-06-12 11:22:05,276:INFO:             mlxtend: Not installed
2024-06-12 11:22:05,276:INFO:       statsforecast: Not installed
2024-06-12 11:22:05,276:INFO:        tune_sklearn: Not installed
2024-06-12 11:22:05,276:INFO:                 ray: Not installed
2024-06-12 11:22:05,276:INFO:            hyperopt: Not installed
2024-06-12 11:22:05,276:INFO:              optuna: Not installed
2024-06-12 11:22:05,276:INFO:               skopt: Not installed
2024-06-12 11:22:05,276:INFO:              mlflow: Not installed
2024-06-12 11:22:05,276:INFO:              gradio: Not installed
2024-06-12 11:22:05,276:INFO:             fastapi: Not installed
2024-06-12 11:22:05,276:INFO:             uvicorn: Not installed
2024-06-12 11:22:05,276:INFO:              m2cgen: Not installed
2024-06-12 11:22:05,276:INFO:           evidently: Not installed
2024-06-12 11:22:05,276:INFO:               fugue: Not installed
2024-06-12 11:22:05,276:INFO:           streamlit: Not installed
2024-06-12 11:22:05,276:INFO:             prophet: Not installed
2024-06-12 11:22:05,276:INFO:None
2024-06-12 11:22:05,276:INFO:Set up data.
2024-06-12 11:22:05,280:INFO:Set up folding strategy.
2024-06-12 11:22:05,280:INFO:Set up train/test split.
2024-06-12 11:22:05,286:INFO:Set up index.
2024-06-12 11:22:05,286:INFO:Assigning column types.
2024-06-12 11:22:05,286:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-12 11:22:05,336:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-12 11:22:05,342:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 11:22:05,386:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:22:05,386:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:22:05,426:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-12 11:22:05,426:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 11:22:05,451:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:22:05,451:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:22:05,451:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-12 11:22:05,496:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 11:22:05,539:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:22:05,540:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:22:05,586:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-12 11:22:05,616:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:22:05,616:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:22:05,616:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-12 11:22:05,696:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:22:05,696:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:22:05,786:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:22:05,786:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:22:05,796:INFO:Finished creating preprocessing pipeline.
2024-06-12 11:22:05,796:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\aabir\AppData\Local\Temp\joblib),
         steps=[('placeholder', None)], verbose=False)
2024-06-12 11:22:05,796:INFO:Creating final display dataframe.
2024-06-12 11:22:05,859:INFO:Setup _display_container:                    Description     Value
0                   Session id      6100
1                       Target   Outcome
2                  Target type    Binary
3          Original data shape  (768, 9)
4       Transformed data shape  (768, 9)
5  Transformed train set shape  (537, 9)
6   Transformed test set shape  (231, 9)
7             Numeric features         8
2024-06-12 11:22:05,946:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:22:05,946:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:22:06,018:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:22:06,018:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-12 11:22:06,018:INFO:setup() successfully completed in 1.13s...............
2024-06-12 11:22:06,046:INFO:Initializing compare_models()
2024-06-12 11:22:06,046:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6ABA6E7C0>, include=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=5, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001F6ABA6E7C0>, 'include': None, 'exclude': ['lightgbm', 'xgboost', 'dummy', 'svm', 'ridge', 'knn', 'dt', 'nb', 'qda'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 5, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['lightgbm', 'xgboost', 'dummy', 'svm', 'ridge', 'knn', 'dt', 'nb', 'qda'])
2024-06-12 11:22:06,046:INFO:Checking exceptions
2024-06-12 11:22:06,056:INFO:Preparing display monitor
2024-06-12 11:22:06,143:INFO:Initializing Logistic Regression
2024-06-12 11:22:06,143:INFO:Total runtime is 0.0 minutes
2024-06-12 11:22:06,147:INFO:SubProcess create_model() called ==================================
2024-06-12 11:22:06,147:INFO:Initializing create_model()
2024-06-12 11:22:06,147:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6ABA6E7C0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6A3391760>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 11:22:06,147:INFO:Checking exceptions
2024-06-12 11:22:06,147:INFO:Importing libraries
2024-06-12 11:22:06,147:INFO:Copying training dataset
2024-06-12 11:22:06,159:INFO:Defining folds
2024-06-12 11:22:06,159:INFO:Declaring metric variables
2024-06-12 11:22:06,167:INFO:Importing untrained model
2024-06-12 11:22:06,169:INFO:Logistic Regression Imported successfully
2024-06-12 11:22:06,180:INFO:Starting cross validation
2024-06-12 11:22:06,184:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 11:22:17,539:INFO:Calculating mean and std
2024-06-12 11:22:17,546:INFO:Creating metrics dataframe
2024-06-12 11:22:17,547:INFO:Uploading results into container
2024-06-12 11:22:17,556:INFO:Uploading model into container now
2024-06-12 11:22:17,556:INFO:_master_model_container: 1
2024-06-12 11:22:17,556:INFO:_display_container: 2
2024-06-12 11:22:17,556:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6100, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-06-12 11:22:17,556:INFO:create_model() successfully completed......................................
2024-06-12 11:22:17,736:INFO:SubProcess create_model() end ==================================
2024-06-12 11:22:17,736:INFO:Creating metrics dataframe
2024-06-12 11:22:17,756:INFO:Initializing Random Forest Classifier
2024-06-12 11:22:17,756:INFO:Total runtime is 0.19355297485987347 minutes
2024-06-12 11:22:17,766:INFO:SubProcess create_model() called ==================================
2024-06-12 11:22:17,766:INFO:Initializing create_model()
2024-06-12 11:22:17,766:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6ABA6E7C0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6A3391760>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 11:22:17,766:INFO:Checking exceptions
2024-06-12 11:22:17,766:INFO:Importing libraries
2024-06-12 11:22:17,766:INFO:Copying training dataset
2024-06-12 11:22:17,778:INFO:Defining folds
2024-06-12 11:22:17,778:INFO:Declaring metric variables
2024-06-12 11:22:17,786:INFO:Importing untrained model
2024-06-12 11:22:17,796:INFO:Random Forest Classifier Imported successfully
2024-06-12 11:22:17,816:INFO:Starting cross validation
2024-06-12 11:22:17,816:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 11:22:18,587:INFO:Calculating mean and std
2024-06-12 11:22:18,587:INFO:Creating metrics dataframe
2024-06-12 11:22:18,587:INFO:Uploading results into container
2024-06-12 11:22:18,587:INFO:Uploading model into container now
2024-06-12 11:22:18,587:INFO:_master_model_container: 2
2024-06-12 11:22:18,587:INFO:_display_container: 2
2024-06-12 11:22:18,587:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=6100, verbose=0,
                       warm_start=False)
2024-06-12 11:22:18,587:INFO:create_model() successfully completed......................................
2024-06-12 11:22:18,756:INFO:SubProcess create_model() end ==================================
2024-06-12 11:22:18,756:INFO:Creating metrics dataframe
2024-06-12 11:22:18,766:INFO:Initializing Ada Boost Classifier
2024-06-12 11:22:18,766:INFO:Total runtime is 0.21039096514383954 minutes
2024-06-12 11:22:18,770:INFO:SubProcess create_model() called ==================================
2024-06-12 11:22:18,770:INFO:Initializing create_model()
2024-06-12 11:22:18,776:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6ABA6E7C0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6A3391760>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 11:22:18,776:INFO:Checking exceptions
2024-06-12 11:22:18,776:INFO:Importing libraries
2024-06-12 11:22:18,776:INFO:Copying training dataset
2024-06-12 11:22:18,776:INFO:Defining folds
2024-06-12 11:22:18,776:INFO:Declaring metric variables
2024-06-12 11:22:18,786:INFO:Importing untrained model
2024-06-12 11:22:18,786:INFO:Ada Boost Classifier Imported successfully
2024-06-12 11:22:18,796:INFO:Starting cross validation
2024-06-12 11:22:18,801:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 11:22:18,826:WARNING:C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-06-12 11:22:18,834:WARNING:C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-06-12 11:22:18,834:WARNING:C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-06-12 11:22:18,834:WARNING:C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-06-12 11:22:18,834:WARNING:C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-06-12 11:22:18,834:WARNING:C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-06-12 11:22:18,834:WARNING:C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-06-12 11:22:19,060:WARNING:C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-06-12 11:22:19,092:WARNING:C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-06-12 11:22:19,294:INFO:Calculating mean and std
2024-06-12 11:22:19,297:INFO:Creating metrics dataframe
2024-06-12 11:22:19,308:INFO:Uploading results into container
2024-06-12 11:22:19,309:INFO:Uploading model into container now
2024-06-12 11:22:19,309:INFO:_master_model_container: 3
2024-06-12 11:22:19,309:INFO:_display_container: 2
2024-06-12 11:22:19,309:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=6100)
2024-06-12 11:22:19,309:INFO:create_model() successfully completed......................................
2024-06-12 11:22:19,556:INFO:SubProcess create_model() end ==================================
2024-06-12 11:22:19,560:INFO:Creating metrics dataframe
2024-06-12 11:22:19,573:INFO:Initializing Gradient Boosting Classifier
2024-06-12 11:22:19,573:INFO:Total runtime is 0.22384655872980755 minutes
2024-06-12 11:22:19,576:INFO:SubProcess create_model() called ==================================
2024-06-12 11:22:19,576:INFO:Initializing create_model()
2024-06-12 11:22:19,576:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6ABA6E7C0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6A3391760>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 11:22:19,582:INFO:Checking exceptions
2024-06-12 11:22:19,582:INFO:Importing libraries
2024-06-12 11:22:19,582:INFO:Copying training dataset
2024-06-12 11:22:19,586:INFO:Defining folds
2024-06-12 11:22:19,586:INFO:Declaring metric variables
2024-06-12 11:22:19,596:INFO:Importing untrained model
2024-06-12 11:22:19,641:INFO:Gradient Boosting Classifier Imported successfully
2024-06-12 11:22:19,656:INFO:Starting cross validation
2024-06-12 11:22:19,656:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 11:22:20,551:INFO:Calculating mean and std
2024-06-12 11:22:20,551:INFO:Creating metrics dataframe
2024-06-12 11:22:20,556:INFO:Uploading results into container
2024-06-12 11:22:20,556:INFO:Uploading model into container now
2024-06-12 11:22:20,556:INFO:_master_model_container: 4
2024-06-12 11:22:20,556:INFO:_display_container: 2
2024-06-12 11:22:20,556:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6100, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-06-12 11:22:20,556:INFO:create_model() successfully completed......................................
2024-06-12 11:22:20,746:INFO:SubProcess create_model() end ==================================
2024-06-12 11:22:20,746:INFO:Creating metrics dataframe
2024-06-12 11:22:20,760:INFO:Initializing Linear Discriminant Analysis
2024-06-12 11:22:20,760:INFO:Total runtime is 0.2436254421869914 minutes
2024-06-12 11:22:20,766:INFO:SubProcess create_model() called ==================================
2024-06-12 11:22:20,766:INFO:Initializing create_model()
2024-06-12 11:22:20,766:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6ABA6E7C0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6A3391760>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 11:22:20,766:INFO:Checking exceptions
2024-06-12 11:22:20,766:INFO:Importing libraries
2024-06-12 11:22:20,766:INFO:Copying training dataset
2024-06-12 11:22:20,776:INFO:Defining folds
2024-06-12 11:22:20,776:INFO:Declaring metric variables
2024-06-12 11:22:20,786:INFO:Importing untrained model
2024-06-12 11:22:20,789:INFO:Linear Discriminant Analysis Imported successfully
2024-06-12 11:22:20,796:INFO:Starting cross validation
2024-06-12 11:22:20,796:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 11:22:21,091:INFO:Calculating mean and std
2024-06-12 11:22:21,094:INFO:Creating metrics dataframe
2024-06-12 11:22:21,096:INFO:Uploading results into container
2024-06-12 11:22:21,096:INFO:Uploading model into container now
2024-06-12 11:22:21,103:INFO:_master_model_container: 5
2024-06-12 11:22:21,106:INFO:_display_container: 2
2024-06-12 11:22:21,107:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-06-12 11:22:21,107:INFO:create_model() successfully completed......................................
2024-06-12 11:22:21,331:INFO:SubProcess create_model() end ==================================
2024-06-12 11:22:21,331:INFO:Creating metrics dataframe
2024-06-12 11:22:21,336:INFO:Initializing Extra Trees Classifier
2024-06-12 11:22:21,336:INFO:Total runtime is 0.2532224774360657 minutes
2024-06-12 11:22:21,347:INFO:SubProcess create_model() called ==================================
2024-06-12 11:22:21,347:INFO:Initializing create_model()
2024-06-12 11:22:21,347:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6ABA6E7C0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6A3391760>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 11:22:21,347:INFO:Checking exceptions
2024-06-12 11:22:21,347:INFO:Importing libraries
2024-06-12 11:22:21,347:INFO:Copying training dataset
2024-06-12 11:22:21,356:INFO:Defining folds
2024-06-12 11:22:21,356:INFO:Declaring metric variables
2024-06-12 11:22:21,366:INFO:Importing untrained model
2024-06-12 11:22:21,376:INFO:Extra Trees Classifier Imported successfully
2024-06-12 11:22:21,386:INFO:Starting cross validation
2024-06-12 11:22:21,386:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 11:22:22,253:INFO:Calculating mean and std
2024-06-12 11:22:22,256:INFO:Creating metrics dataframe
2024-06-12 11:22:22,269:INFO:Uploading results into container
2024-06-12 11:22:22,269:INFO:Uploading model into container now
2024-06-12 11:22:22,271:INFO:_master_model_container: 6
2024-06-12 11:22:22,271:INFO:_display_container: 2
2024-06-12 11:22:22,271:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=6100, verbose=0,
                     warm_start=False)
2024-06-12 11:22:22,271:INFO:create_model() successfully completed......................................
2024-06-12 11:22:22,726:INFO:SubProcess create_model() end ==================================
2024-06-12 11:22:22,726:INFO:Creating metrics dataframe
2024-06-12 11:22:22,768:INFO:Initializing create_model()
2024-06-12 11:22:22,768:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6ABA6E7C0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6100, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 11:22:22,768:INFO:Checking exceptions
2024-06-12 11:22:22,776:INFO:Importing libraries
2024-06-12 11:22:22,776:INFO:Copying training dataset
2024-06-12 11:22:22,791:INFO:Defining folds
2024-06-12 11:22:22,791:INFO:Declaring metric variables
2024-06-12 11:22:22,791:INFO:Importing untrained model
2024-06-12 11:22:22,791:INFO:Declaring custom model
2024-06-12 11:22:22,791:INFO:Logistic Regression Imported successfully
2024-06-12 11:22:22,796:INFO:Cross validation set to False
2024-06-12 11:22:22,796:INFO:Fitting Model
2024-06-12 11:22:22,837:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6100, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-06-12 11:22:22,837:INFO:create_model() successfully completed......................................
2024-06-12 11:22:23,128:INFO:Initializing create_model()
2024-06-12 11:22:23,128:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6ABA6E7C0>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=6100, verbose=0,
                     warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 11:22:23,128:INFO:Checking exceptions
2024-06-12 11:22:23,136:INFO:Importing libraries
2024-06-12 11:22:23,136:INFO:Copying training dataset
2024-06-12 11:22:23,136:INFO:Defining folds
2024-06-12 11:22:23,144:INFO:Declaring metric variables
2024-06-12 11:22:23,144:INFO:Importing untrained model
2024-06-12 11:22:23,146:INFO:Declaring custom model
2024-06-12 11:22:23,146:INFO:Extra Trees Classifier Imported successfully
2024-06-12 11:22:23,146:INFO:Cross validation set to False
2024-06-12 11:22:23,146:INFO:Fitting Model
2024-06-12 11:22:23,366:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=6100, verbose=0,
                     warm_start=False)
2024-06-12 11:22:23,366:INFO:create_model() successfully completed......................................
2024-06-12 11:22:23,586:INFO:Initializing create_model()
2024-06-12 11:22:23,586:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6ABA6E7C0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 11:22:23,586:INFO:Checking exceptions
2024-06-12 11:22:23,596:INFO:Importing libraries
2024-06-12 11:22:23,596:INFO:Copying training dataset
2024-06-12 11:22:23,601:INFO:Defining folds
2024-06-12 11:22:23,601:INFO:Declaring metric variables
2024-06-12 11:22:23,601:INFO:Importing untrained model
2024-06-12 11:22:23,601:INFO:Declaring custom model
2024-06-12 11:22:23,601:INFO:Linear Discriminant Analysis Imported successfully
2024-06-12 11:22:23,601:INFO:Cross validation set to False
2024-06-12 11:22:23,601:INFO:Fitting Model
2024-06-12 11:22:23,651:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-06-12 11:22:23,651:INFO:create_model() successfully completed......................................
2024-06-12 11:22:23,939:INFO:Initializing create_model()
2024-06-12 11:22:23,939:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6ABA6E7C0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6100, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 11:22:23,939:INFO:Checking exceptions
2024-06-12 11:22:23,939:INFO:Importing libraries
2024-06-12 11:22:23,946:INFO:Copying training dataset
2024-06-12 11:22:23,956:INFO:Defining folds
2024-06-12 11:22:23,956:INFO:Declaring metric variables
2024-06-12 11:22:23,956:INFO:Importing untrained model
2024-06-12 11:22:23,956:INFO:Declaring custom model
2024-06-12 11:22:23,956:INFO:Gradient Boosting Classifier Imported successfully
2024-06-12 11:22:23,956:INFO:Cross validation set to False
2024-06-12 11:22:23,956:INFO:Fitting Model
2024-06-12 11:22:24,276:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6100, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-06-12 11:22:24,276:INFO:create_model() successfully completed......................................
2024-06-12 11:22:24,476:INFO:Initializing create_model()
2024-06-12 11:22:24,476:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6ABA6E7C0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=6100, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 11:22:24,476:INFO:Checking exceptions
2024-06-12 11:22:24,476:INFO:Importing libraries
2024-06-12 11:22:24,476:INFO:Copying training dataset
2024-06-12 11:22:24,486:INFO:Defining folds
2024-06-12 11:22:24,486:INFO:Declaring metric variables
2024-06-12 11:22:24,486:INFO:Importing untrained model
2024-06-12 11:22:24,486:INFO:Declaring custom model
2024-06-12 11:22:24,486:INFO:Random Forest Classifier Imported successfully
2024-06-12 11:22:24,486:INFO:Cross validation set to False
2024-06-12 11:22:24,486:INFO:Fitting Model
2024-06-12 11:22:24,696:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=6100, verbose=0,
                       warm_start=False)
2024-06-12 11:22:24,696:INFO:create_model() successfully completed......................................
2024-06-12 11:22:24,881:INFO:_master_model_container: 6
2024-06-12 11:22:24,886:INFO:_display_container: 2
2024-06-12 11:22:24,886:INFO:[LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6100, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=6100, verbose=0,
                     warm_start=False), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6100, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=6100, verbose=0,
                       warm_start=False)]
2024-06-12 11:22:24,886:INFO:compare_models() successfully completed......................................
2024-06-12 11:22:24,918:INFO:Initializing create_model()
2024-06-12 11:22:24,918:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6ABA6E7C0>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 11:22:24,918:INFO:Checking exceptions
2024-06-12 11:22:25,002:INFO:Importing libraries
2024-06-12 11:22:25,002:INFO:Copying training dataset
2024-06-12 11:22:25,013:INFO:Defining folds
2024-06-12 11:22:25,013:INFO:Declaring metric variables
2024-06-12 11:22:25,020:INFO:Importing untrained model
2024-06-12 11:22:25,026:INFO:Random Forest Classifier Imported successfully
2024-06-12 11:22:25,041:INFO:Starting cross validation
2024-06-12 11:22:25,041:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 11:22:25,879:INFO:Calculating mean and std
2024-06-12 11:22:25,879:INFO:Creating metrics dataframe
2024-06-12 11:22:25,893:INFO:Finalizing model
2024-06-12 11:22:26,266:INFO:Uploading results into container
2024-06-12 11:22:26,266:INFO:Uploading model into container now
2024-06-12 11:22:26,293:INFO:_master_model_container: 7
2024-06-12 11:22:26,293:INFO:_display_container: 3
2024-06-12 11:22:26,296:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=6100, verbose=0,
                       warm_start=False)
2024-06-12 11:22:26,296:INFO:create_model() successfully completed......................................
2024-06-12 11:22:26,554:INFO:Initializing create_model()
2024-06-12 11:22:26,556:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6ABA6E7C0>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 11:22:26,556:INFO:Checking exceptions
2024-06-12 11:22:26,581:INFO:Importing libraries
2024-06-12 11:22:26,586:INFO:Copying training dataset
2024-06-12 11:22:26,594:INFO:Defining folds
2024-06-12 11:22:26,594:INFO:Declaring metric variables
2024-06-12 11:22:26,598:INFO:Importing untrained model
2024-06-12 11:22:26,606:INFO:Logistic Regression Imported successfully
2024-06-12 11:22:26,616:INFO:Starting cross validation
2024-06-12 11:22:26,620:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 11:22:26,806:INFO:Calculating mean and std
2024-06-12 11:22:26,808:INFO:Creating metrics dataframe
2024-06-12 11:22:26,831:INFO:Finalizing model
2024-06-12 11:22:26,915:INFO:Uploading results into container
2024-06-12 11:22:26,918:INFO:Uploading model into container now
2024-06-12 11:22:26,946:INFO:_master_model_container: 8
2024-06-12 11:22:26,948:INFO:_display_container: 4
2024-06-12 11:22:26,948:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6100, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-06-12 11:22:26,948:INFO:create_model() successfully completed......................................
2024-06-12 11:22:27,200:INFO:Initializing create_model()
2024-06-12 11:22:27,200:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6ABA6E7C0>, estimator=lda, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 11:22:27,200:INFO:Checking exceptions
2024-06-12 11:22:27,250:INFO:Importing libraries
2024-06-12 11:22:27,254:INFO:Copying training dataset
2024-06-12 11:22:27,257:INFO:Defining folds
2024-06-12 11:22:27,257:INFO:Declaring metric variables
2024-06-12 11:22:27,267:INFO:Importing untrained model
2024-06-12 11:22:27,276:INFO:Linear Discriminant Analysis Imported successfully
2024-06-12 11:22:27,299:INFO:Starting cross validation
2024-06-12 11:22:27,300:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 11:22:27,411:INFO:Calculating mean and std
2024-06-12 11:22:27,411:INFO:Creating metrics dataframe
2024-06-12 11:22:27,416:INFO:Finalizing model
2024-06-12 11:22:27,426:INFO:Uploading results into container
2024-06-12 11:22:27,431:INFO:Uploading model into container now
2024-06-12 11:22:27,442:INFO:_master_model_container: 9
2024-06-12 11:22:27,442:INFO:_display_container: 5
2024-06-12 11:22:27,442:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-06-12 11:22:27,442:INFO:create_model() successfully completed......................................
2024-06-12 11:22:27,606:INFO:Initializing create_model()
2024-06-12 11:22:27,606:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6ABA6E7C0>, estimator=gbc, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 11:22:27,608:INFO:Checking exceptions
2024-06-12 11:22:27,635:INFO:Importing libraries
2024-06-12 11:22:27,635:INFO:Copying training dataset
2024-06-12 11:22:27,642:INFO:Defining folds
2024-06-12 11:22:27,642:INFO:Declaring metric variables
2024-06-12 11:22:27,646:INFO:Importing untrained model
2024-06-12 11:22:27,654:INFO:Gradient Boosting Classifier Imported successfully
2024-06-12 11:22:27,658:INFO:Starting cross validation
2024-06-12 11:22:27,661:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 11:22:28,264:INFO:Calculating mean and std
2024-06-12 11:22:28,264:INFO:Creating metrics dataframe
2024-06-12 11:22:28,271:INFO:Finalizing model
2024-06-12 11:22:28,456:INFO:Uploading results into container
2024-06-12 11:22:28,456:INFO:Uploading model into container now
2024-06-12 11:22:28,476:INFO:_master_model_container: 10
2024-06-12 11:22:28,476:INFO:_display_container: 6
2024-06-12 11:22:28,476:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6100, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-06-12 11:22:28,476:INFO:create_model() successfully completed......................................
2024-06-12 11:22:28,666:INFO:Initializing tune_model()
2024-06-12 11:22:28,666:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=6100, verbose=0,
                       warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6ABA6E7C0>)
2024-06-12 11:22:28,666:INFO:Checking exceptions
2024-06-12 11:22:28,702:INFO:Copying training dataset
2024-06-12 11:22:28,710:INFO:Checking base model
2024-06-12 11:22:28,710:INFO:Base model : Random Forest Classifier
2024-06-12 11:22:28,724:INFO:Declaring metric variables
2024-06-12 11:22:28,732:INFO:Defining Hyperparameters
2024-06-12 11:22:28,893:INFO:Tuning with n_jobs=-1
2024-06-12 11:22:28,893:INFO:Initializing RandomizedSearchCV
2024-06-12 11:22:39,704:INFO:best_params: {'actual_estimator__n_estimators': 230, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.02, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 10, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': {}, 'actual_estimator__bootstrap': True}
2024-06-12 11:22:39,706:INFO:Hyperparameter search completed
2024-06-12 11:22:39,706:INFO:SubProcess create_model() called ==================================
2024-06-12 11:22:39,706:INFO:Initializing create_model()
2024-06-12 11:22:39,706:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6ABA6E7C0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=6100, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6ABACC220>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 230, 'min_samples_split': 2, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.02, 'max_features': 'log2', 'max_depth': 10, 'criterion': 'gini', 'class_weight': {}, 'bootstrap': True})
2024-06-12 11:22:39,706:INFO:Checking exceptions
2024-06-12 11:22:39,706:INFO:Importing libraries
2024-06-12 11:22:39,706:INFO:Copying training dataset
2024-06-12 11:22:39,711:INFO:Defining folds
2024-06-12 11:22:39,711:INFO:Declaring metric variables
2024-06-12 11:22:39,716:INFO:Importing untrained model
2024-06-12 11:22:39,716:INFO:Declaring custom model
2024-06-12 11:22:39,719:INFO:Random Forest Classifier Imported successfully
2024-06-12 11:22:39,727:INFO:Starting cross validation
2024-06-12 11:22:39,727:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 11:22:41,066:INFO:Calculating mean and std
2024-06-12 11:22:41,066:INFO:Creating metrics dataframe
2024-06-12 11:22:41,071:INFO:Finalizing model
2024-06-12 11:22:41,448:INFO:Uploading results into container
2024-06-12 11:22:41,448:INFO:Uploading model into container now
2024-06-12 11:22:41,448:INFO:_master_model_container: 11
2024-06-12 11:22:41,448:INFO:_display_container: 7
2024-06-12 11:22:41,448:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=10, max_features='log2',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.02, min_samples_leaf=4,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=230, n_jobs=-1,
                       oob_score=False, random_state=6100, verbose=0,
                       warm_start=False)
2024-06-12 11:22:41,448:INFO:create_model() successfully completed......................................
2024-06-12 11:22:41,596:INFO:SubProcess create_model() end ==================================
2024-06-12 11:22:41,596:INFO:choose_better activated
2024-06-12 11:22:41,606:INFO:SubProcess create_model() called ==================================
2024-06-12 11:22:41,606:INFO:Initializing create_model()
2024-06-12 11:22:41,606:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6ABA6E7C0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=6100, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 11:22:41,606:INFO:Checking exceptions
2024-06-12 11:22:41,606:INFO:Importing libraries
2024-06-12 11:22:41,606:INFO:Copying training dataset
2024-06-12 11:22:41,616:INFO:Defining folds
2024-06-12 11:22:41,616:INFO:Declaring metric variables
2024-06-12 11:22:41,616:INFO:Importing untrained model
2024-06-12 11:22:41,616:INFO:Declaring custom model
2024-06-12 11:22:41,616:INFO:Random Forest Classifier Imported successfully
2024-06-12 11:22:41,616:INFO:Starting cross validation
2024-06-12 11:22:41,616:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 11:22:42,466:INFO:Calculating mean and std
2024-06-12 11:22:42,466:INFO:Creating metrics dataframe
2024-06-12 11:22:42,466:INFO:Finalizing model
2024-06-12 11:22:42,626:INFO:Uploading results into container
2024-06-12 11:22:42,626:INFO:Uploading model into container now
2024-06-12 11:22:42,626:INFO:_master_model_container: 12
2024-06-12 11:22:42,626:INFO:_display_container: 8
2024-06-12 11:22:42,626:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=6100, verbose=0,
                       warm_start=False)
2024-06-12 11:22:42,626:INFO:create_model() successfully completed......................................
2024-06-12 11:22:42,776:INFO:SubProcess create_model() end ==================================
2024-06-12 11:22:42,776:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=6100, verbose=0,
                       warm_start=False) result for AUC is 0.8301
2024-06-12 11:22:42,776:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=10, max_features='log2',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.02, min_samples_leaf=4,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=230, n_jobs=-1,
                       oob_score=False, random_state=6100, verbose=0,
                       warm_start=False) result for AUC is 0.8376
2024-06-12 11:22:42,776:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=10, max_features='log2',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.02, min_samples_leaf=4,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=230, n_jobs=-1,
                       oob_score=False, random_state=6100, verbose=0,
                       warm_start=False) is best model
2024-06-12 11:22:42,776:INFO:choose_better completed
2024-06-12 11:22:42,793:INFO:_master_model_container: 12
2024-06-12 11:22:42,793:INFO:_display_container: 7
2024-06-12 11:22:42,793:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=10, max_features='log2',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.02, min_samples_leaf=4,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=230, n_jobs=-1,
                       oob_score=False, random_state=6100, verbose=0,
                       warm_start=False)
2024-06-12 11:22:42,793:INFO:tune_model() successfully completed......................................
2024-06-12 11:22:42,963:INFO:Initializing tune_model()
2024-06-12 11:22:42,963:INFO:tune_model(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6100, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6ABA6E7C0>)
2024-06-12 11:22:42,963:INFO:Checking exceptions
2024-06-12 11:22:42,993:INFO:Copying training dataset
2024-06-12 11:22:42,996:INFO:Checking base model
2024-06-12 11:22:42,996:INFO:Base model : Logistic Regression
2024-06-12 11:22:43,006:INFO:Declaring metric variables
2024-06-12 11:22:43,006:INFO:Defining Hyperparameters
2024-06-12 11:22:43,160:INFO:Tuning with n_jobs=-1
2024-06-12 11:22:43,160:INFO:Initializing RandomizedSearchCV
2024-06-12 11:22:43,864:INFO:best_params: {'actual_estimator__class_weight': {}, 'actual_estimator__C': 1.34}
2024-06-12 11:22:43,864:INFO:Hyperparameter search completed
2024-06-12 11:22:43,864:INFO:SubProcess create_model() called ==================================
2024-06-12 11:22:43,864:INFO:Initializing create_model()
2024-06-12 11:22:43,864:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6ABA6E7C0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6100, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6A6AB3C40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'class_weight': {}, 'C': 1.34})
2024-06-12 11:22:43,864:INFO:Checking exceptions
2024-06-12 11:22:43,864:INFO:Importing libraries
2024-06-12 11:22:43,866:INFO:Copying training dataset
2024-06-12 11:22:43,866:INFO:Defining folds
2024-06-12 11:22:43,866:INFO:Declaring metric variables
2024-06-12 11:22:43,871:INFO:Importing untrained model
2024-06-12 11:22:43,871:INFO:Declaring custom model
2024-06-12 11:22:43,876:INFO:Logistic Regression Imported successfully
2024-06-12 11:22:43,886:INFO:Starting cross validation
2024-06-12 11:22:43,886:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 11:22:44,048:INFO:Calculating mean and std
2024-06-12 11:22:44,048:INFO:Creating metrics dataframe
2024-06-12 11:22:44,056:INFO:Finalizing model
2024-06-12 11:22:44,082:INFO:Uploading results into container
2024-06-12 11:22:44,086:INFO:Uploading model into container now
2024-06-12 11:22:44,086:INFO:_master_model_container: 13
2024-06-12 11:22:44,086:INFO:_display_container: 8
2024-06-12 11:22:44,086:INFO:LogisticRegression(C=1.34, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6100, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-06-12 11:22:44,086:INFO:create_model() successfully completed......................................
2024-06-12 11:22:44,238:INFO:SubProcess create_model() end ==================================
2024-06-12 11:22:44,246:INFO:choose_better activated
2024-06-12 11:22:44,249:INFO:SubProcess create_model() called ==================================
2024-06-12 11:22:44,249:INFO:Initializing create_model()
2024-06-12 11:22:44,249:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6ABA6E7C0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6100, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 11:22:44,249:INFO:Checking exceptions
2024-06-12 11:22:44,249:INFO:Importing libraries
2024-06-12 11:22:44,249:INFO:Copying training dataset
2024-06-12 11:22:44,249:INFO:Defining folds
2024-06-12 11:22:44,249:INFO:Declaring metric variables
2024-06-12 11:22:44,249:INFO:Importing untrained model
2024-06-12 11:22:44,249:INFO:Declaring custom model
2024-06-12 11:22:44,256:INFO:Logistic Regression Imported successfully
2024-06-12 11:22:44,256:INFO:Starting cross validation
2024-06-12 11:22:44,256:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 11:22:44,393:INFO:Calculating mean and std
2024-06-12 11:22:44,393:INFO:Creating metrics dataframe
2024-06-12 11:22:44,396:INFO:Finalizing model
2024-06-12 11:22:44,431:INFO:Uploading results into container
2024-06-12 11:22:44,431:INFO:Uploading model into container now
2024-06-12 11:22:44,431:INFO:_master_model_container: 14
2024-06-12 11:22:44,431:INFO:_display_container: 9
2024-06-12 11:22:44,431:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6100, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-06-12 11:22:44,431:INFO:create_model() successfully completed......................................
2024-06-12 11:22:44,586:INFO:SubProcess create_model() end ==================================
2024-06-12 11:22:44,586:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6100, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.8423
2024-06-12 11:22:44,586:INFO:LogisticRegression(C=1.34, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6100, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.8424
2024-06-12 11:22:44,586:INFO:LogisticRegression(C=1.34, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6100, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2024-06-12 11:22:44,586:INFO:choose_better completed
2024-06-12 11:22:44,596:INFO:_master_model_container: 14
2024-06-12 11:22:44,596:INFO:_display_container: 8
2024-06-12 11:22:44,596:INFO:LogisticRegression(C=1.34, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6100, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-06-12 11:22:44,596:INFO:tune_model() successfully completed......................................
2024-06-12 11:22:44,773:INFO:Initializing tune_model()
2024-06-12 11:22:44,773:INFO:tune_model(estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6ABA6E7C0>)
2024-06-12 11:22:44,773:INFO:Checking exceptions
2024-06-12 11:22:44,814:INFO:Copying training dataset
2024-06-12 11:22:44,822:INFO:Checking base model
2024-06-12 11:22:44,822:INFO:Base model : Linear Discriminant Analysis
2024-06-12 11:22:44,826:INFO:Declaring metric variables
2024-06-12 11:22:44,830:INFO:Defining Hyperparameters
2024-06-12 11:22:45,017:INFO:Tuning with n_jobs=-1
2024-06-12 11:22:45,017:INFO:Initializing RandomizedSearchCV
2024-06-12 11:22:45,370:INFO:best_params: {'actual_estimator__solver': 'lsqr', 'actual_estimator__shrinkage': 0.0001}
2024-06-12 11:22:45,372:INFO:Hyperparameter search completed
2024-06-12 11:22:45,372:INFO:SubProcess create_model() called ==================================
2024-06-12 11:22:45,372:INFO:Initializing create_model()
2024-06-12 11:22:45,372:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6ABA6E7C0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6ABACC220>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'solver': 'lsqr', 'shrinkage': 0.0001})
2024-06-12 11:22:45,372:INFO:Checking exceptions
2024-06-12 11:22:45,372:INFO:Importing libraries
2024-06-12 11:22:45,372:INFO:Copying training dataset
2024-06-12 11:22:45,372:INFO:Defining folds
2024-06-12 11:22:45,372:INFO:Declaring metric variables
2024-06-12 11:22:45,376:INFO:Importing untrained model
2024-06-12 11:22:45,379:INFO:Declaring custom model
2024-06-12 11:22:45,381:INFO:Linear Discriminant Analysis Imported successfully
2024-06-12 11:22:45,386:INFO:Starting cross validation
2024-06-12 11:22:45,386:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 11:22:45,492:INFO:Calculating mean and std
2024-06-12 11:22:45,492:INFO:Creating metrics dataframe
2024-06-12 11:22:45,496:INFO:Finalizing model
2024-06-12 11:22:45,518:INFO:Uploading results into container
2024-06-12 11:22:45,526:INFO:Uploading model into container now
2024-06-12 11:22:45,526:INFO:_master_model_container: 15
2024-06-12 11:22:45,526:INFO:_display_container: 9
2024-06-12 11:22:45,528:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=0.0001, solver='lsqr',
                           store_covariance=False, tol=0.0001)
2024-06-12 11:22:45,528:INFO:create_model() successfully completed......................................
2024-06-12 11:22:45,676:INFO:SubProcess create_model() end ==================================
2024-06-12 11:22:45,676:INFO:choose_better activated
2024-06-12 11:22:45,680:INFO:SubProcess create_model() called ==================================
2024-06-12 11:22:45,680:INFO:Initializing create_model()
2024-06-12 11:22:45,680:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6ABA6E7C0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 11:22:45,680:INFO:Checking exceptions
2024-06-12 11:22:45,684:INFO:Importing libraries
2024-06-12 11:22:45,684:INFO:Copying training dataset
2024-06-12 11:22:45,686:INFO:Defining folds
2024-06-12 11:22:45,686:INFO:Declaring metric variables
2024-06-12 11:22:45,686:INFO:Importing untrained model
2024-06-12 11:22:45,686:INFO:Declaring custom model
2024-06-12 11:22:45,686:INFO:Linear Discriminant Analysis Imported successfully
2024-06-12 11:22:45,686:INFO:Starting cross validation
2024-06-12 11:22:45,686:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 11:22:45,765:INFO:Calculating mean and std
2024-06-12 11:22:45,766:INFO:Creating metrics dataframe
2024-06-12 11:22:45,766:INFO:Finalizing model
2024-06-12 11:22:45,771:INFO:Uploading results into container
2024-06-12 11:22:45,771:INFO:Uploading model into container now
2024-06-12 11:22:45,771:INFO:_master_model_container: 16
2024-06-12 11:22:45,771:INFO:_display_container: 10
2024-06-12 11:22:45,771:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-06-12 11:22:45,771:INFO:create_model() successfully completed......................................
2024-06-12 11:22:45,926:INFO:SubProcess create_model() end ==================================
2024-06-12 11:22:45,926:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001) result for AUC is 0.8383
2024-06-12 11:22:45,926:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=0.0001, solver='lsqr',
                           store_covariance=False, tol=0.0001) result for AUC is 0.8377
2024-06-12 11:22:45,926:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001) is best model
2024-06-12 11:22:45,926:INFO:choose_better completed
2024-06-12 11:22:45,926:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-06-12 11:22:45,939:INFO:_master_model_container: 16
2024-06-12 11:22:45,939:INFO:_display_container: 9
2024-06-12 11:22:45,939:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-06-12 11:22:45,939:INFO:tune_model() successfully completed......................................
2024-06-12 11:22:46,096:INFO:Initializing tune_model()
2024-06-12 11:22:46,096:INFO:tune_model(estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6100, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6ABA6E7C0>)
2024-06-12 11:22:46,096:INFO:Checking exceptions
2024-06-12 11:22:46,126:INFO:Copying training dataset
2024-06-12 11:22:46,136:INFO:Checking base model
2024-06-12 11:22:46,136:INFO:Base model : Gradient Boosting Classifier
2024-06-12 11:22:46,146:INFO:Declaring metric variables
2024-06-12 11:22:46,146:INFO:Defining Hyperparameters
2024-06-12 11:22:46,296:INFO:Tuning with n_jobs=-1
2024-06-12 11:22:46,296:INFO:Initializing RandomizedSearchCV
2024-06-12 11:22:51,916:INFO:best_params: {'actual_estimator__subsample': 0.25, 'actual_estimator__n_estimators': 230, 'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.05, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 5, 'actual_estimator__learning_rate': 0.005}
2024-06-12 11:22:51,916:INFO:Hyperparameter search completed
2024-06-12 11:22:51,918:INFO:SubProcess create_model() called ==================================
2024-06-12 11:22:51,918:INFO:Initializing create_model()
2024-06-12 11:22:51,918:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6ABA6E7C0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6100, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6A68300D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.25, 'n_estimators': 230, 'min_samples_split': 7, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.05, 'max_features': 'log2', 'max_depth': 5, 'learning_rate': 0.005})
2024-06-12 11:22:51,918:INFO:Checking exceptions
2024-06-12 11:22:51,918:INFO:Importing libraries
2024-06-12 11:22:51,918:INFO:Copying training dataset
2024-06-12 11:22:51,926:INFO:Defining folds
2024-06-12 11:22:51,926:INFO:Declaring metric variables
2024-06-12 11:22:51,926:INFO:Importing untrained model
2024-06-12 11:22:51,926:INFO:Declaring custom model
2024-06-12 11:22:51,926:INFO:Gradient Boosting Classifier Imported successfully
2024-06-12 11:22:51,938:INFO:Starting cross validation
2024-06-12 11:22:51,938:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 11:22:52,966:INFO:Calculating mean and std
2024-06-12 11:22:52,966:INFO:Creating metrics dataframe
2024-06-12 11:22:52,972:INFO:Finalizing model
2024-06-12 11:22:53,256:INFO:Uploading results into container
2024-06-12 11:22:53,259:INFO:Uploading model into container now
2024-06-12 11:22:53,260:INFO:_master_model_container: 17
2024-06-12 11:22:53,260:INFO:_display_container: 10
2024-06-12 11:22:53,260:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.005, loss='log_loss', max_depth=5,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=4,
                           min_samples_split=7, min_weight_fraction_leaf=0.0,
                           n_estimators=230, n_iter_no_change=None,
                           random_state=6100, subsample=0.25, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-06-12 11:22:53,260:INFO:create_model() successfully completed......................................
2024-06-12 11:22:53,416:INFO:SubProcess create_model() end ==================================
2024-06-12 11:22:53,416:INFO:choose_better activated
2024-06-12 11:22:53,426:INFO:SubProcess create_model() called ==================================
2024-06-12 11:22:53,426:INFO:Initializing create_model()
2024-06-12 11:22:53,426:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6ABA6E7C0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6100, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 11:22:53,426:INFO:Checking exceptions
2024-06-12 11:22:53,426:INFO:Importing libraries
2024-06-12 11:22:53,426:INFO:Copying training dataset
2024-06-12 11:22:53,434:INFO:Defining folds
2024-06-12 11:22:53,434:INFO:Declaring metric variables
2024-06-12 11:22:53,436:INFO:Importing untrained model
2024-06-12 11:22:53,436:INFO:Declaring custom model
2024-06-12 11:22:53,436:INFO:Gradient Boosting Classifier Imported successfully
2024-06-12 11:22:53,437:INFO:Starting cross validation
2024-06-12 11:22:53,438:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 11:22:54,026:INFO:Calculating mean and std
2024-06-12 11:22:54,026:INFO:Creating metrics dataframe
2024-06-12 11:22:54,026:INFO:Finalizing model
2024-06-12 11:22:54,186:INFO:Uploading results into container
2024-06-12 11:22:54,186:INFO:Uploading model into container now
2024-06-12 11:22:54,186:INFO:_master_model_container: 18
2024-06-12 11:22:54,186:INFO:_display_container: 11
2024-06-12 11:22:54,186:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6100, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-06-12 11:22:54,186:INFO:create_model() successfully completed......................................
2024-06-12 11:22:54,336:INFO:SubProcess create_model() end ==================================
2024-06-12 11:22:54,336:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6100, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for AUC is 0.8366
2024-06-12 11:22:54,338:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.005, loss='log_loss', max_depth=5,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=4,
                           min_samples_split=7, min_weight_fraction_leaf=0.0,
                           n_estimators=230, n_iter_no_change=None,
                           random_state=6100, subsample=0.25, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for AUC is 0.8491
2024-06-12 11:22:54,338:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.005, loss='log_loss', max_depth=5,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=4,
                           min_samples_split=7, min_weight_fraction_leaf=0.0,
                           n_estimators=230, n_iter_no_change=None,
                           random_state=6100, subsample=0.25, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2024-06-12 11:22:54,338:INFO:choose_better completed
2024-06-12 11:22:54,348:INFO:_master_model_container: 18
2024-06-12 11:22:54,348:INFO:_display_container: 10
2024-06-12 11:22:54,348:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.005, loss='log_loss', max_depth=5,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=4,
                           min_samples_split=7, min_weight_fraction_leaf=0.0,
                           n_estimators=230, n_iter_no_change=None,
                           random_state=6100, subsample=0.25, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-06-12 11:22:54,348:INFO:tune_model() successfully completed......................................
2024-06-12 11:22:54,562:INFO:Initializing stack_models()
2024-06-12 11:22:54,562:INFO:stack_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6ABA6E7C0>, estimator_list=[LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6100, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=6100, verbose=0,
                     warm_start=False), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6100, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=6100, verbose=0,
                       warm_start=False)], meta_model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6100, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), meta_model_fold=5, fold=None, round=4, method=auto, restack=False, choose_better=False, optimize=AUC, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2024-06-12 11:22:54,562:INFO:Checking exceptions
2024-06-12 11:22:54,566:INFO:Defining meta model
2024-06-12 11:22:54,606:INFO:Getting model names
2024-06-12 11:22:54,606:INFO:[('Logistic Regression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6100, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)), ('Extra Trees Classifier', ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=6100, verbose=0,
                     warm_start=False)), ('Linear Discriminant Analysis', LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)), ('Gradient Boosting Classifier', GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6100, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)), ('Random Forest Classifier', RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=6100, verbose=0,
                       warm_start=False))]
2024-06-12 11:22:54,610:INFO:SubProcess create_model() called ==================================
2024-06-12 11:22:54,628:INFO:Initializing create_model()
2024-06-12 11:22:54,628:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6ABA6E7C0>, estimator=StackingClassifier(cv=5,
                   estimators=[('Logistic Regression',
                                LogisticRegression(C=1.0, class_weight=None,
                                                   dual=False,
                                                   fit_intercept=True,
                                                   intercept_scaling=1,
                                                   l1_ratio=None, max_iter=1000,
                                                   multi_class='auto',
                                                   n_jobs=None, penalty='l2',
                                                   random_state=6100,
                                                   solver='lbfgs', tol=0.0001,
                                                   verbose=0,
                                                   warm_start=False)),
                               ('Extra Trees Classifier',
                                ExtraTreesClassifier(bootstrap...
                                                       random_state=6100,
                                                       verbose=0,
                                                       warm_start=False))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=6100,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=False, stack_method='auto',
                   verbose=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6A3318B80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 11:22:54,628:INFO:Checking exceptions
2024-06-12 11:22:54,628:INFO:Importing libraries
2024-06-12 11:22:54,628:INFO:Copying training dataset
2024-06-12 11:22:54,638:INFO:Defining folds
2024-06-12 11:22:54,638:INFO:Declaring metric variables
2024-06-12 11:22:54,651:INFO:Importing untrained model
2024-06-12 11:22:54,651:INFO:Declaring custom model
2024-06-12 11:22:54,666:INFO:Stacking Classifier Imported successfully
2024-06-12 11:22:54,670:INFO:Starting cross validation
2024-06-12 11:22:54,675:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 11:23:05,827:INFO:Calculating mean and std
2024-06-12 11:23:05,827:INFO:Creating metrics dataframe
2024-06-12 11:23:05,848:INFO:Finalizing model
2024-06-12 11:23:07,326:INFO:Uploading results into container
2024-06-12 11:23:07,326:INFO:Uploading model into container now
2024-06-12 11:23:07,326:INFO:_master_model_container: 19
2024-06-12 11:23:07,326:INFO:_display_container: 11
2024-06-12 11:23:07,353:INFO:StackingClassifier(cv=5,
                   estimators=[('Logistic Regression',
                                LogisticRegression(C=1.0, class_weight=None,
                                                   dual=False,
                                                   fit_intercept=True,
                                                   intercept_scaling=1,
                                                   l1_ratio=None, max_iter=1000,
                                                   multi_class='auto',
                                                   n_jobs=None, penalty='l2',
                                                   random_state=6100,
                                                   solver='lbfgs', tol=0.0001,
                                                   verbose=0,
                                                   warm_start=False)),
                               ('Extra Trees Classifier',
                                ExtraTreesClassifier(bootstrap...
                                                       random_state=6100,
                                                       verbose=0,
                                                       warm_start=False))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=6100,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=False, stack_method='auto',
                   verbose=0)
2024-06-12 11:23:07,353:INFO:create_model() successfully completed......................................
2024-06-12 11:23:07,536:INFO:SubProcess create_model() end ==================================
2024-06-12 11:23:07,551:INFO:_master_model_container: 19
2024-06-12 11:23:07,551:INFO:_display_container: 11
2024-06-12 11:23:07,559:INFO:StackingClassifier(cv=5,
                   estimators=[('Logistic Regression',
                                LogisticRegression(C=1.0, class_weight=None,
                                                   dual=False,
                                                   fit_intercept=True,
                                                   intercept_scaling=1,
                                                   l1_ratio=None, max_iter=1000,
                                                   multi_class='auto',
                                                   n_jobs=None, penalty='l2',
                                                   random_state=6100,
                                                   solver='lbfgs', tol=0.0001,
                                                   verbose=0,
                                                   warm_start=False)),
                               ('Extra Trees Classifier',
                                ExtraTreesClassifier(bootstrap...
                                                       random_state=6100,
                                                       verbose=0,
                                                       warm_start=False))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=6100,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=False, stack_method='auto',
                   verbose=0)
2024-06-12 11:23:07,559:INFO:stack_models() successfully completed......................................
2024-06-12 11:23:07,746:INFO:Initializing plot_model()
2024-06-12 11:23:07,746:INFO:plot_model(plot=boundary, fold=None, verbose=True, display=None, display_format=None, estimator=StackingClassifier(cv=5,
                   estimators=[('Logistic Regression',
                                LogisticRegression(C=1.0, class_weight=None,
                                                   dual=False,
                                                   fit_intercept=True,
                                                   intercept_scaling=1,
                                                   l1_ratio=None, max_iter=1000,
                                                   multi_class='auto',
                                                   n_jobs=None, penalty='l2',
                                                   random_state=6100,
                                                   solver='lbfgs', tol=0.0001,
                                                   verbose=0,
                                                   warm_start=False)),
                               ('Extra Trees Classifier',
                                ExtraTreesClassifier(bootstrap...
                                                       random_state=6100,
                                                       verbose=0,
                                                       warm_start=False))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=6100,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=False, stack_method='auto',
                   verbose=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6ABA6E7C0>, system=True)
2024-06-12 11:23:07,746:INFO:Checking exceptions
2024-06-12 11:23:07,756:INFO:Preloading libraries
2024-06-12 11:23:07,806:INFO:Copying training dataset
2024-06-12 11:23:07,806:INFO:Plot type: boundary
2024-06-12 11:23:07,830:INFO:Fitting StandardScaler()
2024-06-12 11:23:07,836:INFO:Fitting PCA()
2024-06-12 11:23:07,877:INFO:Fitting Model
2024-06-12 11:23:11,230:INFO:Visual Rendered Successfully
2024-06-12 11:23:11,536:INFO:plot_model() successfully completed......................................
2024-06-12 11:23:11,576:INFO:Initializing plot_model()
2024-06-12 11:23:11,576:INFO:plot_model(plot=auc, fold=None, verbose=True, display=None, display_format=None, estimator=StackingClassifier(cv=5,
                   estimators=[('Logistic Regression',
                                LogisticRegression(C=1.0, class_weight=None,
                                                   dual=False,
                                                   fit_intercept=True,
                                                   intercept_scaling=1,
                                                   l1_ratio=None, max_iter=1000,
                                                   multi_class='auto',
                                                   n_jobs=None, penalty='l2',
                                                   random_state=6100,
                                                   solver='lbfgs', tol=0.0001,
                                                   verbose=0,
                                                   warm_start=False)),
                               ('Extra Trees Classifier',
                                ExtraTreesClassifier(bootstrap...
                                                       random_state=6100,
                                                       verbose=0,
                                                       warm_start=False))],
                   final_estimator=LogisticRegression(C=1.0, class_weight=None,
                                                      dual=False,
                                                      fit_intercept=True,
                                                      intercept_scaling=1,
                                                      l1_ratio=None,
                                                      max_iter=1000,
                                                      multi_class='auto',
                                                      n_jobs=None, penalty='l2',
                                                      random_state=6100,
                                                      solver='lbfgs',
                                                      tol=0.0001, verbose=0,
                                                      warm_start=False),
                   n_jobs=-1, passthrough=False, stack_method='auto',
                   verbose=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6ABA6E7C0>, system=True)
2024-06-12 11:23:11,576:INFO:Checking exceptions
2024-06-12 11:23:11,587:INFO:Preloading libraries
2024-06-12 11:23:11,648:INFO:Copying training dataset
2024-06-12 11:23:11,648:INFO:Plot type: auc
2024-06-12 11:23:11,696:INFO:Fitting Model
2024-06-12 11:23:11,698:INFO:Scoring test/hold-out set
2024-06-12 11:23:12,071:INFO:Visual Rendered Successfully
2024-06-12 11:23:12,324:INFO:plot_model() successfully completed......................................
2024-06-12 11:23:12,931:INFO:Initializing blend_models()
2024-06-12 11:23:12,931:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6ABA6E7C0>, estimator_list=[LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6100, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=6100, verbose=0,
                     warm_start=False), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6100, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=6100, verbose=0,
                       warm_start=False)], fold=None, round=4, choose_better=False, optimize=AUC, method=soft, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2024-06-12 11:23:12,931:INFO:Checking exceptions
2024-06-12 11:23:12,996:INFO:Importing libraries
2024-06-12 11:23:12,996:INFO:Copying training dataset
2024-06-12 11:23:13,006:INFO:Getting model names
2024-06-12 11:23:13,016:INFO:SubProcess create_model() called ==================================
2024-06-12 11:23:13,029:INFO:Initializing create_model()
2024-06-12 11:23:13,029:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6ABA6E7C0>, estimator=VotingClassifier(estimators=[('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=6100,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Extra Trees Classifier',
                              ExtraTreesClassifier(bootstrap=False,...
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=6100,
                                                     verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6A5E55040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 11:23:13,029:INFO:Checking exceptions
2024-06-12 11:23:13,029:INFO:Importing libraries
2024-06-12 11:23:13,029:INFO:Copying training dataset
2024-06-12 11:23:13,036:INFO:Defining folds
2024-06-12 11:23:13,036:INFO:Declaring metric variables
2024-06-12 11:23:13,044:INFO:Importing untrained model
2024-06-12 11:23:13,044:INFO:Declaring custom model
2024-06-12 11:23:13,056:INFO:Voting Classifier Imported successfully
2024-06-12 11:23:13,070:INFO:Starting cross validation
2024-06-12 11:23:13,072:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 11:23:15,560:INFO:Calculating mean and std
2024-06-12 11:23:15,560:INFO:Creating metrics dataframe
2024-06-12 11:23:15,571:INFO:Finalizing model
2024-06-12 11:23:15,882:INFO:Uploading results into container
2024-06-12 11:23:15,882:INFO:Uploading model into container now
2024-06-12 11:23:15,885:INFO:_master_model_container: 20
2024-06-12 11:23:15,885:INFO:_display_container: 12
2024-06-12 11:23:15,892:INFO:VotingClassifier(estimators=[('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=6100,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Extra Trees Classifier',
                              ExtraTreesClassifier(bootstrap=False,...
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=6100,
                                                     verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2024-06-12 11:23:15,892:INFO:create_model() successfully completed......................................
2024-06-12 11:23:16,056:INFO:SubProcess create_model() end ==================================
2024-06-12 11:23:16,065:INFO:_master_model_container: 20
2024-06-12 11:23:16,065:INFO:_display_container: 12
2024-06-12 11:23:16,076:INFO:VotingClassifier(estimators=[('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=6100,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Extra Trees Classifier',
                              ExtraTreesClassifier(bootstrap=False,...
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=6100,
                                                     verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2024-06-12 11:23:16,076:INFO:blend_models() successfully completed......................................
2024-06-12 11:23:16,306:INFO:Initializing plot_model()
2024-06-12 11:23:16,312:INFO:plot_model(plot=boundary, fold=None, verbose=True, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=6100,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Extra Trees Classifier',
                              ExtraTreesClassifier(bootstrap=False,...
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=6100,
                                                     verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6ABA6E7C0>, system=True)
2024-06-12 11:23:16,312:INFO:Checking exceptions
2024-06-12 11:23:16,320:INFO:Preloading libraries
2024-06-12 11:23:16,349:INFO:Copying training dataset
2024-06-12 11:23:16,349:INFO:Plot type: boundary
2024-06-12 11:23:16,366:INFO:Fitting StandardScaler()
2024-06-12 11:23:16,376:INFO:Fitting PCA()
2024-06-12 11:23:16,396:INFO:Fitting Model
2024-06-12 11:23:19,096:INFO:Visual Rendered Successfully
2024-06-12 11:23:19,519:INFO:plot_model() successfully completed......................................
2024-06-12 11:23:19,547:INFO:Initializing plot_model()
2024-06-12 11:23:19,547:INFO:plot_model(plot=auc, fold=None, verbose=True, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=6100,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Extra Trees Classifier',
                              ExtraTreesClassifier(bootstrap=False,...
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=6100,
                                                     verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6ABA6E7C0>, system=True)
2024-06-12 11:23:19,547:INFO:Checking exceptions
2024-06-12 11:23:19,556:INFO:Preloading libraries
2024-06-12 11:23:19,603:INFO:Copying training dataset
2024-06-12 11:23:19,603:INFO:Plot type: auc
2024-06-12 11:23:19,652:INFO:Fitting Model
2024-06-12 11:23:19,652:INFO:Scoring test/hold-out set
2024-06-12 11:23:20,306:INFO:Visual Rendered Successfully
2024-06-12 11:23:20,517:INFO:plot_model() successfully completed......................................
2024-06-12 11:23:21,186:INFO:Initializing blend_models()
2024-06-12 11:23:21,186:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6ABA6E7C0>, estimator_list=[LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6100, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=6100, verbose=0,
                     warm_start=False), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6100, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=6100, verbose=0,
                       warm_start=False)], fold=None, round=4, choose_better=False, optimize=AUC, method=hard, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2024-06-12 11:23:21,186:INFO:Checking exceptions
2024-06-12 11:23:21,296:INFO:Importing libraries
2024-06-12 11:23:21,296:INFO:Copying training dataset
2024-06-12 11:23:21,311:INFO:Getting model names
2024-06-12 11:23:21,320:INFO:SubProcess create_model() called ==================================
2024-06-12 11:23:21,328:INFO:Initializing create_model()
2024-06-12 11:23:21,328:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6ABA6E7C0>, estimator=VotingClassifier(estimators=[('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=6100,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Extra Trees Classifier',
                              ExtraTreesClassifier(bootstrap=False,...
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=6100,
                                                     verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6A5E26AC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 11:23:21,328:INFO:Checking exceptions
2024-06-12 11:23:21,328:INFO:Importing libraries
2024-06-12 11:23:21,328:INFO:Copying training dataset
2024-06-12 11:23:21,337:INFO:Defining folds
2024-06-12 11:23:21,337:INFO:Declaring metric variables
2024-06-12 11:23:21,346:INFO:Importing untrained model
2024-06-12 11:23:21,346:INFO:Declaring custom model
2024-06-12 11:23:21,356:INFO:Voting Classifier Imported successfully
2024-06-12 11:23:21,376:INFO:Starting cross validation
2024-06-12 11:23:21,379:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 11:23:22,976:WARNING:C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2024-06-12 11:23:22,976:WARNING:C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2024-06-12 11:23:22,996:WARNING:C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2024-06-12 11:23:22,996:WARNING:C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2024-06-12 11:23:23,005:WARNING:C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2024-06-12 11:23:23,021:WARNING:C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2024-06-12 11:23:24,116:WARNING:C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2024-06-12 11:23:24,176:WARNING:C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2024-06-12 11:23:24,216:INFO:Calculating mean and std
2024-06-12 11:23:24,221:INFO:Creating metrics dataframe
2024-06-12 11:23:24,240:INFO:Finalizing model
2024-06-12 11:23:24,906:INFO:Uploading results into container
2024-06-12 11:23:24,906:INFO:Uploading model into container now
2024-06-12 11:23:24,916:INFO:_master_model_container: 21
2024-06-12 11:23:24,916:INFO:_display_container: 13
2024-06-12 11:23:24,937:INFO:VotingClassifier(estimators=[('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=6100,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Extra Trees Classifier',
                              ExtraTreesClassifier(bootstrap=False,...
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=6100,
                                                     verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None)
2024-06-12 11:23:24,937:INFO:create_model() successfully completed......................................
2024-06-12 11:23:25,228:INFO:SubProcess create_model() end ==================================
2024-06-12 11:23:25,276:INFO:_master_model_container: 21
2024-06-12 11:23:25,276:INFO:_display_container: 13
2024-06-12 11:23:25,300:INFO:VotingClassifier(estimators=[('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=6100,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Extra Trees Classifier',
                              ExtraTreesClassifier(bootstrap=False,...
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=6100,
                                                     verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None)
2024-06-12 11:23:25,300:INFO:blend_models() successfully completed......................................
2024-06-12 11:23:25,757:INFO:Initializing plot_model()
2024-06-12 11:23:25,757:INFO:plot_model(plot=boundary, fold=None, verbose=True, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=6100,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Extra Trees Classifier',
                              ExtraTreesClassifier(bootstrap=False,...
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=6100,
                                                     verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6ABA6E7C0>, system=True)
2024-06-12 11:23:25,757:INFO:Checking exceptions
2024-06-12 11:23:25,776:INFO:Preloading libraries
2024-06-12 11:23:25,846:INFO:Copying training dataset
2024-06-12 11:23:25,846:INFO:Plot type: boundary
2024-06-12 11:23:25,901:INFO:Fitting StandardScaler()
2024-06-12 11:23:25,921:INFO:Fitting PCA()
2024-06-12 11:23:25,971:INFO:Fitting Model
2024-06-12 11:23:31,907:INFO:Visual Rendered Successfully
2024-06-12 11:23:32,186:INFO:plot_model() successfully completed......................................
2024-06-12 11:23:32,658:INFO:Initializing calibrate_model()
2024-06-12 11:23:32,658:INFO:calibrate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6ABA6E7C0>, estimator=VotingClassifier(estimators=[('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=6100,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Extra Trees Classifier',
                              ExtraTreesClassifier(bootstrap=False,...
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=6100,
                                                     verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), method=sigmoid, calibrate_fold=5, fold=None, round=4, fit_kwargs=None, groups=None, verbose=True, return_train_score=False)
2024-06-12 11:23:32,663:INFO:Checking exceptions
2024-06-12 11:23:32,666:INFO:Preloading libraries
2024-06-12 11:23:32,666:INFO:Preparing display monitor
2024-06-12 11:23:32,696:INFO:Getting model name
2024-06-12 11:23:32,703:INFO:Base model : Voting Classifier
2024-06-12 11:23:32,716:INFO:Importing untrained CalibratedClassifierCV
2024-06-12 11:23:32,716:INFO:SubProcess create_model() called ==================================
2024-06-12 11:23:32,742:INFO:Initializing create_model()
2024-06-12 11:23:32,742:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6ABA6E7C0>, estimator=CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=VotingClassifier(estimators=[('Logistic '
                                                               'Regression',
                                                               LogisticRegression(C=1.0,
                                                                                  class_weight=None,
                                                                                  dual=False,
                                                                                  fit_intercept=True,
                                                                                  intercept_scaling=1,
                                                                                  l1_ratio=None,
                                                                                  max_iter=1000,
                                                                                  multi_class='auto',
                                                                                  n_jobs=None,
                                                                                  penalty='l2',
                                                                                  random_state=6100,
                                                                                  solver='lbfgs',
                                                                                  tol=0.0001,
                                                                                  verbose=0,
                                                                                  warm_start=False)),
                                                              ('Extra...
                                                                                      max_features='sqrt',
                                                                                      max_leaf_nodes=None,
                                                                                      max_samples=None,
                                                                                      min_impurity_decrease=0.0,
                                                                                      min_samples_leaf=1,
                                                                                      min_samples_split=2,
                                                                                      min_weight_fraction_leaf=0.0,
                                                                                      monotonic_cst=None,
                                                                                      n_estimators=100,
                                                                                      n_jobs=-1,
                                                                                      oob_score=False,
                                                                                      random_state=6100,
                                                                                      verbose=0,
                                                                                      warm_start=False))],
                                                  flatten_transform=True,
                                                  n_jobs=-1, verbose=False,
                                                  voting='soft', weights=None),
                       method='sigmoid', n_jobs=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F6B7EB5280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 11:23:32,742:INFO:Checking exceptions
2024-06-12 11:23:32,742:INFO:Importing libraries
2024-06-12 11:23:32,742:INFO:Copying training dataset
2024-06-12 11:23:32,742:INFO:Defining folds
2024-06-12 11:23:32,742:INFO:Declaring metric variables
2024-06-12 11:23:32,751:INFO:Importing untrained model
2024-06-12 11:23:32,751:INFO:Declaring custom model
2024-06-12 11:23:32,760:INFO:Voting Classifier Imported successfully
2024-06-12 11:23:32,767:INFO:Starting cross validation
2024-06-12 11:23:32,774:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-12 11:23:44,348:INFO:Calculating mean and std
2024-06-12 11:23:44,348:INFO:Creating metrics dataframe
2024-06-12 11:23:44,356:INFO:Finalizing model
2024-06-12 11:23:46,206:INFO:Uploading results into container
2024-06-12 11:23:46,206:INFO:Uploading model into container now
2024-06-12 11:23:46,206:INFO:_master_model_container: 22
2024-06-12 11:23:46,206:INFO:_display_container: 14
2024-06-12 11:23:46,225:INFO:CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=VotingClassifier(estimators=[('Logistic '
                                                               'Regression',
                                                               LogisticRegression(C=1.0,
                                                                                  class_weight=None,
                                                                                  dual=False,
                                                                                  fit_intercept=True,
                                                                                  intercept_scaling=1,
                                                                                  l1_ratio=None,
                                                                                  max_iter=1000,
                                                                                  multi_class='auto',
                                                                                  n_jobs=None,
                                                                                  penalty='l2',
                                                                                  random_state=6100,
                                                                                  solver='lbfgs',
                                                                                  tol=0.0001,
                                                                                  verbose=0,
                                                                                  warm_start=False)),
                                                              ('Extra...
                                                                                      max_features='sqrt',
                                                                                      max_leaf_nodes=None,
                                                                                      max_samples=None,
                                                                                      min_impurity_decrease=0.0,
                                                                                      min_samples_leaf=1,
                                                                                      min_samples_split=2,
                                                                                      min_weight_fraction_leaf=0.0,
                                                                                      monotonic_cst=None,
                                                                                      n_estimators=100,
                                                                                      n_jobs=-1,
                                                                                      oob_score=False,
                                                                                      random_state=6100,
                                                                                      verbose=0,
                                                                                      warm_start=False))],
                                                  flatten_transform=True,
                                                  n_jobs=-1, verbose=False,
                                                  voting='soft', weights=None),
                       method='sigmoid', n_jobs=None)
2024-06-12 11:23:46,225:INFO:create_model() successfully completed......................................
2024-06-12 11:23:46,418:INFO:SubProcess create_model() end ==================================
2024-06-12 11:23:46,436:INFO:_master_model_container: 22
2024-06-12 11:23:46,436:INFO:_display_container: 14
2024-06-12 11:23:46,455:INFO:CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=VotingClassifier(estimators=[('Logistic '
                                                               'Regression',
                                                               LogisticRegression(C=1.0,
                                                                                  class_weight=None,
                                                                                  dual=False,
                                                                                  fit_intercept=True,
                                                                                  intercept_scaling=1,
                                                                                  l1_ratio=None,
                                                                                  max_iter=1000,
                                                                                  multi_class='auto',
                                                                                  n_jobs=None,
                                                                                  penalty='l2',
                                                                                  random_state=6100,
                                                                                  solver='lbfgs',
                                                                                  tol=0.0001,
                                                                                  verbose=0,
                                                                                  warm_start=False)),
                                                              ('Extra...
                                                                                      max_features='sqrt',
                                                                                      max_leaf_nodes=None,
                                                                                      max_samples=None,
                                                                                      min_impurity_decrease=0.0,
                                                                                      min_samples_leaf=1,
                                                                                      min_samples_split=2,
                                                                                      min_weight_fraction_leaf=0.0,
                                                                                      monotonic_cst=None,
                                                                                      n_estimators=100,
                                                                                      n_jobs=-1,
                                                                                      oob_score=False,
                                                                                      random_state=6100,
                                                                                      verbose=0,
                                                                                      warm_start=False))],
                                                  flatten_transform=True,
                                                  n_jobs=-1, verbose=False,
                                                  voting='soft', weights=None),
                       method='sigmoid', n_jobs=None)
2024-06-12 11:23:46,455:INFO:calibrate_model() successfully completed......................................
2024-06-12 11:23:46,675:INFO:Initializing finalize_model()
2024-06-12 11:23:46,675:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6ABA6E7C0>, estimator=CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=VotingClassifier(estimators=[('Logistic '
                                                               'Regression',
                                                               LogisticRegression(C=1.0,
                                                                                  class_weight=None,
                                                                                  dual=False,
                                                                                  fit_intercept=True,
                                                                                  intercept_scaling=1,
                                                                                  l1_ratio=None,
                                                                                  max_iter=1000,
                                                                                  multi_class='auto',
                                                                                  n_jobs=None,
                                                                                  penalty='l2',
                                                                                  random_state=6100,
                                                                                  solver='lbfgs',
                                                                                  tol=0.0001,
                                                                                  verbose=0,
                                                                                  warm_start=False)),
                                                              ('Extra...
                                                                                      max_features='sqrt',
                                                                                      max_leaf_nodes=None,
                                                                                      max_samples=None,
                                                                                      min_impurity_decrease=0.0,
                                                                                      min_samples_leaf=1,
                                                                                      min_samples_split=2,
                                                                                      min_weight_fraction_leaf=0.0,
                                                                                      monotonic_cst=None,
                                                                                      n_estimators=100,
                                                                                      n_jobs=-1,
                                                                                      oob_score=False,
                                                                                      random_state=6100,
                                                                                      verbose=0,
                                                                                      warm_start=False))],
                                                  flatten_transform=True,
                                                  n_jobs=-1, verbose=False,
                                                  voting='soft', weights=None),
                       method='sigmoid', n_jobs=None), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-06-12 11:23:46,690:INFO:Finalizing CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=VotingClassifier(estimators=[('Logistic '
                                                               'Regression',
                                                               LogisticRegression(C=1.0,
                                                                                  class_weight=None,
                                                                                  dual=False,
                                                                                  fit_intercept=True,
                                                                                  intercept_scaling=1,
                                                                                  l1_ratio=None,
                                                                                  max_iter=1000,
                                                                                  multi_class='auto',
                                                                                  n_jobs=None,
                                                                                  penalty='l2',
                                                                                  random_state=6100,
                                                                                  solver='lbfgs',
                                                                                  tol=0.0001,
                                                                                  verbose=0,
                                                                                  warm_start=False)),
                                                              ('Extra...
                                                                                      max_features='sqrt',
                                                                                      max_leaf_nodes=None,
                                                                                      max_samples=None,
                                                                                      min_impurity_decrease=0.0,
                                                                                      min_samples_leaf=1,
                                                                                      min_samples_split=2,
                                                                                      min_weight_fraction_leaf=0.0,
                                                                                      monotonic_cst=None,
                                                                                      n_estimators=100,
                                                                                      n_jobs=-1,
                                                                                      oob_score=False,
                                                                                      random_state=6100,
                                                                                      verbose=0,
                                                                                      warm_start=False))],
                                                  flatten_transform=True,
                                                  n_jobs=-1, verbose=False,
                                                  voting='soft', weights=None),
                       method='sigmoid', n_jobs=None)
2024-06-12 11:23:46,716:INFO:Initializing create_model()
2024-06-12 11:23:46,716:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6ABA6E7C0>, estimator=CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=VotingClassifier(estimators=[('Logistic '
                                                               'Regression',
                                                               LogisticRegression(C=1.0,
                                                                                  class_weight=None,
                                                                                  dual=False,
                                                                                  fit_intercept=True,
                                                                                  intercept_scaling=1,
                                                                                  l1_ratio=None,
                                                                                  max_iter=1000,
                                                                                  multi_class='auto',
                                                                                  n_jobs=None,
                                                                                  penalty='l2',
                                                                                  random_state=6100,
                                                                                  solver='lbfgs',
                                                                                  tol=0.0001,
                                                                                  verbose=0,
                                                                                  warm_start=False)),
                                                              ('Extra...
                                                                                      max_features='sqrt',
                                                                                      max_leaf_nodes=None,
                                                                                      max_samples=None,
                                                                                      min_impurity_decrease=0.0,
                                                                                      min_samples_leaf=1,
                                                                                      min_samples_split=2,
                                                                                      min_weight_fraction_leaf=0.0,
                                                                                      monotonic_cst=None,
                                                                                      n_estimators=100,
                                                                                      n_jobs=-1,
                                                                                      oob_score=False,
                                                                                      random_state=6100,
                                                                                      verbose=0,
                                                                                      warm_start=False))],
                                                  flatten_transform=True,
                                                  n_jobs=-1, verbose=False,
                                                  voting='soft', weights=None),
                       method='sigmoid', n_jobs=None), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 11:23:46,716:INFO:Checking exceptions
2024-06-12 11:23:46,719:INFO:Importing libraries
2024-06-12 11:23:46,719:INFO:Copying training dataset
2024-06-12 11:23:46,719:INFO:Defining folds
2024-06-12 11:23:46,719:INFO:Declaring metric variables
2024-06-12 11:23:46,719:INFO:Importing untrained model
2024-06-12 11:23:46,719:INFO:Declaring custom model
2024-06-12 11:23:46,719:INFO:Voting Classifier Imported successfully
2024-06-12 11:23:46,719:INFO:Cross validation set to False
2024-06-12 11:23:46,719:INFO:Fitting Model
2024-06-12 11:23:48,548:INFO:Pipeline(memory=Memory(location=None),
         steps=[('placeholder', None),
                ('actual_estimator',
                 CalibratedClassifierCV(cv=5, ensemble=True,
                                        estimator=VotingClassifier(estimators=[('Logistic '
                                                                                'Regression',
                                                                                LogisticRegression(C=1.0,
                                                                                                   class_weight=None,
                                                                                                   dual=False,
                                                                                                   fit_intercept=True,
                                                                                                   intercept_scaling=1,
                                                                                                   l1_ratio=None,
                                                                                                   max_iter=1000,
                                                                                                   multi_class='auto',
                                                                                                   n_jobs=None,
                                                                                                   penalty...
                                                                                                       max_leaf_nodes=None,
                                                                                                       max_samples=None,
                                                                                                       min_impurity_decrease=0.0,
                                                                                                       min_samples_leaf=1,
                                                                                                       min_samples_split=2,
                                                                                                       min_weight_fraction_leaf=0.0,
                                                                                                       monotonic_cst=None,
                                                                                                       n_estimators=100,
                                                                                                       n_jobs=-1,
                                                                                                       oob_score=False,
                                                                                                       random_state=6100,
                                                                                                       verbose=0,
                                                                                                       warm_start=False))],
                                                                   flatten_transform=True,
                                                                   n_jobs=-1,
                                                                   verbose=False,
                                                                   voting='soft',
                                                                   weights=None),
                                        method='sigmoid', n_jobs=None))],
         verbose=False)
2024-06-12 11:23:48,548:INFO:create_model() successfully completed......................................
2024-06-12 11:23:48,725:INFO:_master_model_container: 22
2024-06-12 11:23:48,725:INFO:_display_container: 14
2024-06-12 11:23:48,765:INFO:Pipeline(memory=Memory(location=None),
         steps=[('placeholder', None),
                ('actual_estimator',
                 CalibratedClassifierCV(cv=5, ensemble=True,
                                        estimator=VotingClassifier(estimators=[('Logistic '
                                                                                'Regression',
                                                                                LogisticRegression(C=1.0,
                                                                                                   class_weight=None,
                                                                                                   dual=False,
                                                                                                   fit_intercept=True,
                                                                                                   intercept_scaling=1,
                                                                                                   l1_ratio=None,
                                                                                                   max_iter=1000,
                                                                                                   multi_class='auto',
                                                                                                   n_jobs=None,
                                                                                                   penalty...
                                                                                                       max_leaf_nodes=None,
                                                                                                       max_samples=None,
                                                                                                       min_impurity_decrease=0.0,
                                                                                                       min_samples_leaf=1,
                                                                                                       min_samples_split=2,
                                                                                                       min_weight_fraction_leaf=0.0,
                                                                                                       monotonic_cst=None,
                                                                                                       n_estimators=100,
                                                                                                       n_jobs=-1,
                                                                                                       oob_score=False,
                                                                                                       random_state=6100,
                                                                                                       verbose=0,
                                                                                                       warm_start=False))],
                                                                   flatten_transform=True,
                                                                   n_jobs=-1,
                                                                   verbose=False,
                                                                   voting='soft',
                                                                   weights=None),
                                        method='sigmoid', n_jobs=None))],
         verbose=False)
2024-06-12 11:23:48,765:INFO:finalize_model() successfully completed......................................
2024-06-12 11:23:48,989:INFO:Initializing plot_model()
2024-06-12 11:23:48,989:INFO:plot_model(plot=threshold, fold=None, verbose=True, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('placeholder', None),
                ('actual_estimator',
                 CalibratedClassifierCV(cv=5, ensemble=True,
                                        estimator=VotingClassifier(estimators=[('Logistic '
                                                                                'Regression',
                                                                                LogisticRegression(C=1.0,
                                                                                                   class_weight=None,
                                                                                                   dual=False,
                                                                                                   fit_intercept=True,
                                                                                                   intercept_scaling=1,
                                                                                                   l1_ratio=None,
                                                                                                   max_iter=1000,
                                                                                                   multi_class='auto',
                                                                                                   n_jobs=None,
                                                                                                   penalty...
                                                                                                       max_leaf_nodes=None,
                                                                                                       max_samples=None,
                                                                                                       min_impurity_decrease=0.0,
                                                                                                       min_samples_leaf=1,
                                                                                                       min_samples_split=2,
                                                                                                       min_weight_fraction_leaf=0.0,
                                                                                                       monotonic_cst=None,
                                                                                                       n_estimators=100,
                                                                                                       n_jobs=-1,
                                                                                                       oob_score=False,
                                                                                                       random_state=6100,
                                                                                                       verbose=0,
                                                                                                       warm_start=False))],
                                                                   flatten_transform=True,
                                                                   n_jobs=-1,
                                                                   verbose=False,
                                                                   voting='soft',
                                                                   weights=None),
                                        method='sigmoid', n_jobs=None))],
         verbose=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6ABA6E7C0>, system=True)
2024-06-12 11:23:48,989:INFO:Checking exceptions
2024-06-12 11:23:48,995:INFO:Preloading libraries
2024-06-12 11:23:49,176:INFO:Copying training dataset
2024-06-12 11:23:49,176:INFO:Plot type: threshold
2024-06-12 11:23:49,206:INFO:Fitting Model
2024-06-12 11:26:16,095:INFO:Scoring test/hold-out set
2024-06-12 11:26:17,327:INFO:Visual Rendered Successfully
2024-06-12 11:26:17,646:INFO:plot_model() successfully completed......................................
2024-06-12 11:26:17,754:INFO:Initializing plot_model()
2024-06-12 11:26:17,754:INFO:plot_model(plot=boundary, fold=None, verbose=True, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('placeholder', None),
                ('actual_estimator',
                 CalibratedClassifierCV(cv=5, ensemble=True,
                                        estimator=VotingClassifier(estimators=[('Logistic '
                                                                                'Regression',
                                                                                LogisticRegression(C=1.0,
                                                                                                   class_weight=None,
                                                                                                   dual=False,
                                                                                                   fit_intercept=True,
                                                                                                   intercept_scaling=1,
                                                                                                   l1_ratio=None,
                                                                                                   max_iter=1000,
                                                                                                   multi_class='auto',
                                                                                                   n_jobs=None,
                                                                                                   penalty...
                                                                                                       max_leaf_nodes=None,
                                                                                                       max_samples=None,
                                                                                                       min_impurity_decrease=0.0,
                                                                                                       min_samples_leaf=1,
                                                                                                       min_samples_split=2,
                                                                                                       min_weight_fraction_leaf=0.0,
                                                                                                       monotonic_cst=None,
                                                                                                       n_estimators=100,
                                                                                                       n_jobs=-1,
                                                                                                       oob_score=False,
                                                                                                       random_state=6100,
                                                                                                       verbose=0,
                                                                                                       warm_start=False))],
                                                                   flatten_transform=True,
                                                                   n_jobs=-1,
                                                                   verbose=False,
                                                                   voting='soft',
                                                                   weights=None),
                                        method='sigmoid', n_jobs=None))],
         verbose=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6ABA6E7C0>, system=True)
2024-06-12 11:26:17,754:INFO:Checking exceptions
2024-06-12 11:26:17,756:INFO:Preloading libraries
2024-06-12 11:26:18,025:INFO:Copying training dataset
2024-06-12 11:26:18,025:INFO:Plot type: boundary
2024-06-12 11:26:18,060:INFO:Fitting StandardScaler()
2024-06-12 11:26:18,070:INFO:Fitting PCA()
2024-06-12 11:26:18,105:INFO:Fitting Model
2024-06-12 11:26:24,515:INFO:Visual Rendered Successfully
2024-06-12 11:26:24,778:INFO:plot_model() successfully completed......................................
2024-06-12 11:37:39,606:INFO:Initializing finalize_model()
2024-06-12 11:37:39,606:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6ABA6E7C0>, estimator=CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=VotingClassifier(estimators=[('Logistic '
                                                               'Regression',
                                                               LogisticRegression(C=1.0,
                                                                                  class_weight=None,
                                                                                  dual=False,
                                                                                  fit_intercept=True,
                                                                                  intercept_scaling=1,
                                                                                  l1_ratio=None,
                                                                                  max_iter=1000,
                                                                                  multi_class='auto',
                                                                                  n_jobs=None,
                                                                                  penalty='l2',
                                                                                  random_state=6100,
                                                                                  solver='lbfgs',
                                                                                  tol=0.0001,
                                                                                  verbose=0,
                                                                                  warm_start=False)),
                                                              ('Extra...
                                                                                      max_features='sqrt',
                                                                                      max_leaf_nodes=None,
                                                                                      max_samples=None,
                                                                                      min_impurity_decrease=0.0,
                                                                                      min_samples_leaf=1,
                                                                                      min_samples_split=2,
                                                                                      min_weight_fraction_leaf=0.0,
                                                                                      monotonic_cst=None,
                                                                                      n_estimators=100,
                                                                                      n_jobs=-1,
                                                                                      oob_score=False,
                                                                                      random_state=6100,
                                                                                      verbose=0,
                                                                                      warm_start=False))],
                                                  flatten_transform=True,
                                                  n_jobs=-1, verbose=False,
                                                  voting='soft', weights=None),
                       method='sigmoid', n_jobs=None), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-06-12 11:37:39,622:INFO:Finalizing CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=VotingClassifier(estimators=[('Logistic '
                                                               'Regression',
                                                               LogisticRegression(C=1.0,
                                                                                  class_weight=None,
                                                                                  dual=False,
                                                                                  fit_intercept=True,
                                                                                  intercept_scaling=1,
                                                                                  l1_ratio=None,
                                                                                  max_iter=1000,
                                                                                  multi_class='auto',
                                                                                  n_jobs=None,
                                                                                  penalty='l2',
                                                                                  random_state=6100,
                                                                                  solver='lbfgs',
                                                                                  tol=0.0001,
                                                                                  verbose=0,
                                                                                  warm_start=False)),
                                                              ('Extra...
                                                                                      max_features='sqrt',
                                                                                      max_leaf_nodes=None,
                                                                                      max_samples=None,
                                                                                      min_impurity_decrease=0.0,
                                                                                      min_samples_leaf=1,
                                                                                      min_samples_split=2,
                                                                                      min_weight_fraction_leaf=0.0,
                                                                                      monotonic_cst=None,
                                                                                      n_estimators=100,
                                                                                      n_jobs=-1,
                                                                                      oob_score=False,
                                                                                      random_state=6100,
                                                                                      verbose=0,
                                                                                      warm_start=False))],
                                                  flatten_transform=True,
                                                  n_jobs=-1, verbose=False,
                                                  voting='soft', weights=None),
                       method='sigmoid', n_jobs=None)
2024-06-12 11:37:39,655:INFO:Initializing create_model()
2024-06-12 11:37:39,655:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6ABA6E7C0>, estimator=CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=VotingClassifier(estimators=[('Logistic '
                                                               'Regression',
                                                               LogisticRegression(C=1.0,
                                                                                  class_weight=None,
                                                                                  dual=False,
                                                                                  fit_intercept=True,
                                                                                  intercept_scaling=1,
                                                                                  l1_ratio=None,
                                                                                  max_iter=1000,
                                                                                  multi_class='auto',
                                                                                  n_jobs=None,
                                                                                  penalty='l2',
                                                                                  random_state=6100,
                                                                                  solver='lbfgs',
                                                                                  tol=0.0001,
                                                                                  verbose=0,
                                                                                  warm_start=False)),
                                                              ('Extra...
                                                                                      max_features='sqrt',
                                                                                      max_leaf_nodes=None,
                                                                                      max_samples=None,
                                                                                      min_impurity_decrease=0.0,
                                                                                      min_samples_leaf=1,
                                                                                      min_samples_split=2,
                                                                                      min_weight_fraction_leaf=0.0,
                                                                                      monotonic_cst=None,
                                                                                      n_estimators=100,
                                                                                      n_jobs=-1,
                                                                                      oob_score=False,
                                                                                      random_state=6100,
                                                                                      verbose=0,
                                                                                      warm_start=False))],
                                                  flatten_transform=True,
                                                  n_jobs=-1, verbose=False,
                                                  voting='soft', weights=None),
                       method='sigmoid', n_jobs=None), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-06-12 11:37:39,655:INFO:Checking exceptions
2024-06-12 11:37:39,662:INFO:Importing libraries
2024-06-12 11:37:39,662:INFO:Copying training dataset
2024-06-12 11:37:39,662:INFO:Defining folds
2024-06-12 11:37:39,662:INFO:Declaring metric variables
2024-06-12 11:37:39,662:INFO:Importing untrained model
2024-06-12 11:37:39,662:INFO:Declaring custom model
2024-06-12 11:37:39,664:INFO:Voting Classifier Imported successfully
2024-06-12 11:37:39,664:INFO:Cross validation set to False
2024-06-12 11:37:39,664:INFO:Fitting Model
2024-06-12 11:37:48,135:INFO:Pipeline(memory=Memory(location=None),
         steps=[('placeholder', None),
                ('actual_estimator',
                 CalibratedClassifierCV(cv=5, ensemble=True,
                                        estimator=VotingClassifier(estimators=[('Logistic '
                                                                                'Regression',
                                                                                LogisticRegression(C=1.0,
                                                                                                   class_weight=None,
                                                                                                   dual=False,
                                                                                                   fit_intercept=True,
                                                                                                   intercept_scaling=1,
                                                                                                   l1_ratio=None,
                                                                                                   max_iter=1000,
                                                                                                   multi_class='auto',
                                                                                                   n_jobs=None,
                                                                                                   penalty...
                                                                                                       max_leaf_nodes=None,
                                                                                                       max_samples=None,
                                                                                                       min_impurity_decrease=0.0,
                                                                                                       min_samples_leaf=1,
                                                                                                       min_samples_split=2,
                                                                                                       min_weight_fraction_leaf=0.0,
                                                                                                       monotonic_cst=None,
                                                                                                       n_estimators=100,
                                                                                                       n_jobs=-1,
                                                                                                       oob_score=False,
                                                                                                       random_state=6100,
                                                                                                       verbose=0,
                                                                                                       warm_start=False))],
                                                                   flatten_transform=True,
                                                                   n_jobs=-1,
                                                                   verbose=False,
                                                                   voting='soft',
                                                                   weights=None),
                                        method='sigmoid', n_jobs=None))],
         verbose=False)
2024-06-12 11:37:48,135:INFO:create_model() successfully completed......................................
2024-06-12 11:37:48,322:INFO:_master_model_container: 22
2024-06-12 11:37:48,327:INFO:_display_container: 14
2024-06-12 11:37:48,353:INFO:Pipeline(memory=Memory(location=None),
         steps=[('placeholder', None),
                ('actual_estimator',
                 CalibratedClassifierCV(cv=5, ensemble=True,
                                        estimator=VotingClassifier(estimators=[('Logistic '
                                                                                'Regression',
                                                                                LogisticRegression(C=1.0,
                                                                                                   class_weight=None,
                                                                                                   dual=False,
                                                                                                   fit_intercept=True,
                                                                                                   intercept_scaling=1,
                                                                                                   l1_ratio=None,
                                                                                                   max_iter=1000,
                                                                                                   multi_class='auto',
                                                                                                   n_jobs=None,
                                                                                                   penalty...
                                                                                                       max_leaf_nodes=None,
                                                                                                       max_samples=None,
                                                                                                       min_impurity_decrease=0.0,
                                                                                                       min_samples_leaf=1,
                                                                                                       min_samples_split=2,
                                                                                                       min_weight_fraction_leaf=0.0,
                                                                                                       monotonic_cst=None,
                                                                                                       n_estimators=100,
                                                                                                       n_jobs=-1,
                                                                                                       oob_score=False,
                                                                                                       random_state=6100,
                                                                                                       verbose=0,
                                                                                                       warm_start=False))],
                                                                   flatten_transform=True,
                                                                   n_jobs=-1,
                                                                   verbose=False,
                                                                   voting='soft',
                                                                   weights=None),
                                        method='sigmoid', n_jobs=None))],
         verbose=False)
2024-06-12 11:37:48,353:INFO:finalize_model() successfully completed......................................
2024-06-13 14:31:28,258:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-13 14:31:28,258:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-13 14:31:28,258:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-13 14:31:28,258:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-06-13 14:31:33,313:INFO:PyCaret ClassificationExperiment
2024-06-13 14:31:33,313:INFO:Logging name: clf-default-name
2024-06-13 14:31:33,313:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-06-13 14:31:33,313:INFO:version 3.3.2
2024-06-13 14:31:33,313:INFO:Initializing setup()
2024-06-13 14:31:33,313:INFO:self.USI: 2287
2024-06-13 14:31:33,313:INFO:self._variable_keys: {'y', 'logging_param', 'X_test', 'y_train', 'fold_groups_param', 'html_param', '_available_plots', '_ml_usecase', 'exp_id', 'exp_name_log', 'data', 'log_plots_param', 'USI', 'seed', 'gpu_param', 'fold_generator', 'idx', 'target_param', 'gpu_n_jobs_param', 'y_test', 'n_jobs_param', 'X_train', 'is_multiclass', 'pipeline', 'fix_imbalance', 'X', 'fold_shuffle_param', 'memory'}
2024-06-13 14:31:33,313:INFO:Checking environment
2024-06-13 14:31:33,313:INFO:python_version: 3.9.13
2024-06-13 14:31:33,313:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2024-06-13 14:31:33,313:INFO:machine: AMD64
2024-06-13 14:31:33,313:INFO:platform: Windows-10-10.0.22631-SP0
2024-06-13 14:31:33,313:INFO:Memory: svmem(total=16843341824, available=4015243264, percent=76.2, used=12828098560, free=4015243264)
2024-06-13 14:31:33,313:INFO:Physical Core: 4
2024-06-13 14:31:33,313:INFO:Logical Core: 8
2024-06-13 14:31:33,313:INFO:Checking libraries
2024-06-13 14:31:33,313:INFO:System:
2024-06-13 14:31:33,313:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2024-06-13 14:31:33,313:INFO:executable: c:\ProgramData\Anaconda3\python.exe
2024-06-13 14:31:33,313:INFO:   machine: Windows-10-10.0.22631-SP0
2024-06-13 14:31:33,313:INFO:PyCaret required dependencies:
2024-06-13 14:31:33,736:INFO:                 pip: 22.2.2
2024-06-13 14:31:33,736:INFO:          setuptools: 63.4.1
2024-06-13 14:31:33,736:INFO:             pycaret: 3.3.2
2024-06-13 14:31:33,736:INFO:             IPython: 7.31.1
2024-06-13 14:31:33,736:INFO:          ipywidgets: 7.6.5
2024-06-13 14:31:33,736:INFO:                tqdm: 4.64.1
2024-06-13 14:31:33,736:INFO:               numpy: 1.21.5
2024-06-13 14:31:33,736:INFO:              pandas: 1.4.4
2024-06-13 14:31:33,736:INFO:              jinja2: 2.11.3
2024-06-13 14:31:33,752:INFO:               scipy: 1.9.1
2024-06-13 14:31:33,752:INFO:              joblib: 1.1.0
2024-06-13 14:31:33,752:INFO:             sklearn: 1.0.2
2024-06-13 14:31:33,752:INFO:                pyod: 2.0.0
2024-06-13 14:31:33,752:INFO:            imblearn: 0.12.3
2024-06-13 14:31:33,752:INFO:   category_encoders: 2.6.3
2024-06-13 14:31:33,752:INFO:            lightgbm: 4.3.0
2024-06-13 14:31:33,752:INFO:               numba: 0.55.1
2024-06-13 14:31:33,752:INFO:            requests: 2.28.1
2024-06-13 14:31:33,752:INFO:          matplotlib: 3.5.2
2024-06-13 14:31:33,752:INFO:          scikitplot: 0.3.7
2024-06-13 14:31:33,752:INFO:         yellowbrick: 1.5
2024-06-13 14:31:33,752:INFO:              plotly: 5.9.0
2024-06-13 14:31:33,752:INFO:    plotly-resampler: Not installed
2024-06-13 14:31:33,752:INFO:             kaleido: 0.2.1
2024-06-13 14:31:33,752:INFO:           schemdraw: 0.15
2024-06-13 14:31:33,752:INFO:         statsmodels: 0.13.2
2024-06-13 14:31:33,752:INFO:              sktime: 0.26.0
2024-06-13 14:31:33,752:INFO:               tbats: 1.1.3
2024-06-13 14:31:33,752:INFO:            pmdarima: 2.0.4
2024-06-13 14:31:33,752:INFO:              psutil: 5.9.0
2024-06-13 14:31:33,752:INFO:          markupsafe: 2.0.1
2024-06-13 14:31:33,752:INFO:             pickle5: Not installed
2024-06-13 14:31:33,752:INFO:         cloudpickle: 2.0.0
2024-06-13 14:31:33,752:INFO:         deprecation: 2.1.0
2024-06-13 14:31:33,752:INFO:              xxhash: 3.4.1
2024-06-13 14:31:33,752:INFO:           wurlitzer: Not installed
2024-06-13 14:31:33,752:INFO:PyCaret optional dependencies:
2024-06-13 14:31:33,783:INFO:                shap: Not installed
2024-06-13 14:31:33,783:INFO:           interpret: Not installed
2024-06-13 14:31:33,783:INFO:                umap: 0.5.6
2024-06-13 14:31:33,783:INFO:     ydata_profiling: 4.2.0
2024-06-13 14:31:33,783:INFO:  explainerdashboard: Not installed
2024-06-13 14:31:33,783:INFO:             autoviz: Not installed
2024-06-13 14:31:33,783:INFO:           fairlearn: Not installed
2024-06-13 14:31:33,783:INFO:          deepchecks: Not installed
2024-06-13 14:31:33,783:INFO:             xgboost: Not installed
2024-06-13 14:31:33,783:INFO:            catboost: Not installed
2024-06-13 14:31:33,783:INFO:              kmodes: Not installed
2024-06-13 14:31:33,783:INFO:             mlxtend: Not installed
2024-06-13 14:31:33,783:INFO:       statsforecast: Not installed
2024-06-13 14:31:33,783:INFO:        tune_sklearn: Not installed
2024-06-13 14:31:33,783:INFO:                 ray: Not installed
2024-06-13 14:31:33,783:INFO:            hyperopt: Not installed
2024-06-13 14:31:33,783:INFO:              optuna: Not installed
2024-06-13 14:31:33,783:INFO:               skopt: Not installed
2024-06-13 14:31:33,783:INFO:              mlflow: Not installed
2024-06-13 14:31:33,783:INFO:              gradio: Not installed
2024-06-13 14:31:33,783:INFO:             fastapi: Not installed
2024-06-13 14:31:33,783:INFO:             uvicorn: Not installed
2024-06-13 14:31:33,783:INFO:              m2cgen: Not installed
2024-06-13 14:31:33,783:INFO:           evidently: Not installed
2024-06-13 14:31:33,783:INFO:               fugue: Not installed
2024-06-13 14:31:33,783:INFO:           streamlit: Not installed
2024-06-13 14:31:33,783:INFO:             prophet: Not installed
2024-06-13 14:31:33,783:INFO:None
2024-06-13 14:31:33,783:INFO:Set up data.
2024-06-13 14:31:33,783:INFO:Set up folding strategy.
2024-06-13 14:31:33,783:INFO:Set up train/test split.
2024-06-13 14:31:33,799:INFO:Set up index.
2024-06-13 14:31:33,799:INFO:Assigning column types.
2024-06-13 14:31:33,799:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-06-13 14:31:33,846:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-13 14:31:33,846:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-13 14:31:33,910:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 14:31:33,910:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 14:31:33,941:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-06-13 14:31:33,941:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-13 14:31:33,972:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 14:31:33,972:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 14:31:33,972:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-06-13 14:31:34,020:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-13 14:31:34,035:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 14:31:34,035:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 14:31:34,082:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-06-13 14:31:34,120:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 14:31:34,120:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 14:31:34,120:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-06-13 14:31:34,214:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 14:31:34,229:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 14:31:34,292:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 14:31:34,292:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 14:31:34,300:INFO:Finished creating preprocessing pipeline.
2024-06-13 14:31:34,308:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\aabir\AppData\Local\Temp\joblib),
         steps=[('placeholder', None)], verbose=False)
2024-06-13 14:31:34,308:INFO:Creating final display dataframe.
2024-06-13 14:31:34,371:INFO:Setup _display_container:                    Description     Value
0                   Session id      4783
1                       Target   Outcome
2                  Target type    Binary
3          Original data shape  (768, 9)
4       Transformed data shape  (768, 9)
5  Transformed train set shape  (537, 9)
6   Transformed test set shape  (231, 9)
7             Numeric features         8
2024-06-13 14:31:34,482:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 14:31:34,482:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 14:31:34,614:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 14:31:34,614:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-06-13 14:31:34,614:INFO:setup() successfully completed in 1.31s...............
2024-06-13 14:31:34,636:INFO:Initializing compare_models()
2024-06-13 14:31:34,636:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002982933B3D0>, include=None, fold=None, round=4, cross_validation=True, sort=AUC, n_select=5, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002982933B3D0>, 'include': None, 'exclude': ['lightgbm', 'xgboost', 'dummy', 'svm', 'ridge', 'knn', 'dt', 'nb', 'qda'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'AUC', 'n_select': 5, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['lightgbm', 'xgboost', 'dummy', 'svm', 'ridge', 'knn', 'dt', 'nb', 'qda'])
2024-06-13 14:31:34,636:INFO:Checking exceptions
2024-06-13 14:31:34,647:INFO:Preparing display monitor
2024-06-13 14:31:34,712:INFO:Initializing Logistic Regression
2024-06-13 14:31:34,712:INFO:Total runtime is 0.0 minutes
2024-06-13 14:31:34,720:INFO:SubProcess create_model() called ==================================
2024-06-13 14:31:34,720:INFO:Initializing create_model()
2024-06-13 14:31:34,720:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002982933B3D0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000298223538E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-13 14:31:34,720:INFO:Checking exceptions
2024-06-13 14:31:34,720:INFO:Importing libraries
2024-06-13 14:31:34,720:INFO:Copying training dataset
2024-06-13 14:31:34,724:INFO:Defining folds
2024-06-13 14:31:34,724:INFO:Declaring metric variables
2024-06-13 14:31:34,735:INFO:Importing untrained model
2024-06-13 14:31:34,746:INFO:Logistic Regression Imported successfully
2024-06-13 14:31:34,757:INFO:Starting cross validation
2024-06-13 14:31:34,763:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-13 14:31:47,114:INFO:Calculating mean and std
2024-06-13 14:31:47,114:INFO:Creating metrics dataframe
2024-06-13 14:31:47,123:INFO:Uploading results into container
2024-06-13 14:31:47,124:INFO:Uploading model into container now
2024-06-13 14:31:47,125:INFO:_master_model_container: 1
2024-06-13 14:31:47,125:INFO:_display_container: 2
2024-06-13 14:31:47,128:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4783, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-06-13 14:31:47,128:INFO:create_model() successfully completed......................................
2024-06-13 14:31:47,377:INFO:SubProcess create_model() end ==================================
2024-06-13 14:31:47,377:INFO:Creating metrics dataframe
2024-06-13 14:31:47,408:INFO:Initializing Random Forest Classifier
2024-06-13 14:31:47,409:INFO:Total runtime is 0.21162155866622925 minutes
2024-06-13 14:31:47,421:INFO:SubProcess create_model() called ==================================
2024-06-13 14:31:47,422:INFO:Initializing create_model()
2024-06-13 14:31:47,422:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002982933B3D0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000298223538E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-13 14:31:47,422:INFO:Checking exceptions
2024-06-13 14:31:47,422:INFO:Importing libraries
2024-06-13 14:31:47,422:INFO:Copying training dataset
2024-06-13 14:31:47,434:INFO:Defining folds
2024-06-13 14:31:47,435:INFO:Declaring metric variables
2024-06-13 14:31:47,444:INFO:Importing untrained model
2024-06-13 14:31:47,446:INFO:Random Forest Classifier Imported successfully
2024-06-13 14:31:47,461:INFO:Starting cross validation
2024-06-13 14:31:47,461:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-13 14:31:48,395:INFO:Calculating mean and std
2024-06-13 14:31:48,395:INFO:Creating metrics dataframe
2024-06-13 14:31:48,395:INFO:Uploading results into container
2024-06-13 14:31:48,395:INFO:Uploading model into container now
2024-06-13 14:31:48,395:INFO:_master_model_container: 2
2024-06-13 14:31:48,395:INFO:_display_container: 2
2024-06-13 14:31:48,395:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=4783, verbose=0,
                       warm_start=False)
2024-06-13 14:31:48,395:INFO:create_model() successfully completed......................................
2024-06-13 14:31:48,697:INFO:SubProcess create_model() end ==================================
2024-06-13 14:31:48,697:INFO:Creating metrics dataframe
2024-06-13 14:31:48,702:INFO:Initializing Ada Boost Classifier
2024-06-13 14:31:48,702:INFO:Total runtime is 0.23316487868626912 minutes
2024-06-13 14:31:48,717:INFO:SubProcess create_model() called ==================================
2024-06-13 14:31:48,717:INFO:Initializing create_model()
2024-06-13 14:31:48,717:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002982933B3D0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000298223538E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-13 14:31:48,717:INFO:Checking exceptions
2024-06-13 14:31:48,717:INFO:Importing libraries
2024-06-13 14:31:48,717:INFO:Copying training dataset
2024-06-13 14:31:48,723:INFO:Defining folds
2024-06-13 14:31:48,723:INFO:Declaring metric variables
2024-06-13 14:31:48,726:INFO:Importing untrained model
2024-06-13 14:31:48,737:INFO:Ada Boost Classifier Imported successfully
2024-06-13 14:31:48,752:INFO:Starting cross validation
2024-06-13 14:31:48,755:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-13 14:31:48,800:WARNING:C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-06-13 14:31:48,800:WARNING:C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-06-13 14:31:48,800:WARNING:C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-06-13 14:31:48,817:WARNING:C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-06-13 14:31:49,123:WARNING:C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-06-13 14:31:49,138:WARNING:C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-06-13 14:31:49,375:INFO:Calculating mean and std
2024-06-13 14:31:49,375:INFO:Creating metrics dataframe
2024-06-13 14:31:49,375:INFO:Uploading results into container
2024-06-13 14:31:49,375:INFO:Uploading model into container now
2024-06-13 14:31:49,375:INFO:_master_model_container: 3
2024-06-13 14:31:49,375:INFO:_display_container: 2
2024-06-13 14:31:49,375:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=4783)
2024-06-13 14:31:49,375:INFO:create_model() successfully completed......................................
2024-06-13 14:31:49,596:INFO:SubProcess create_model() end ==================================
2024-06-13 14:31:49,596:INFO:Creating metrics dataframe
2024-06-13 14:31:49,618:INFO:Initializing Gradient Boosting Classifier
2024-06-13 14:31:49,618:INFO:Total runtime is 0.24843854904174803 minutes
2024-06-13 14:31:49,624:INFO:SubProcess create_model() called ==================================
2024-06-13 14:31:49,624:INFO:Initializing create_model()
2024-06-13 14:31:49,624:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002982933B3D0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000298223538E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-13 14:31:49,624:INFO:Checking exceptions
2024-06-13 14:31:49,624:INFO:Importing libraries
2024-06-13 14:31:49,624:INFO:Copying training dataset
2024-06-13 14:31:49,635:INFO:Defining folds
2024-06-13 14:31:49,635:INFO:Declaring metric variables
2024-06-13 14:31:49,647:INFO:Importing untrained model
2024-06-13 14:31:49,655:INFO:Gradient Boosting Classifier Imported successfully
2024-06-13 14:31:49,660:INFO:Starting cross validation
2024-06-13 14:31:49,668:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-13 14:31:50,379:INFO:Calculating mean and std
2024-06-13 14:31:50,382:INFO:Creating metrics dataframe
2024-06-13 14:31:50,390:INFO:Uploading results into container
2024-06-13 14:31:50,391:INFO:Uploading model into container now
2024-06-13 14:31:50,392:INFO:_master_model_container: 4
2024-06-13 14:31:50,392:INFO:_display_container: 2
2024-06-13 14:31:50,392:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4783, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-06-13 14:31:50,392:INFO:create_model() successfully completed......................................
2024-06-13 14:31:50,660:INFO:SubProcess create_model() end ==================================
2024-06-13 14:31:50,660:INFO:Creating metrics dataframe
2024-06-13 14:31:50,679:INFO:Initializing Linear Discriminant Analysis
2024-06-13 14:31:50,679:INFO:Total runtime is 0.26612138748168945 minutes
2024-06-13 14:31:50,682:INFO:SubProcess create_model() called ==================================
2024-06-13 14:31:50,682:INFO:Initializing create_model()
2024-06-13 14:31:50,682:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002982933B3D0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000298223538E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-13 14:31:50,682:INFO:Checking exceptions
2024-06-13 14:31:50,682:INFO:Importing libraries
2024-06-13 14:31:50,682:INFO:Copying training dataset
2024-06-13 14:31:50,691:INFO:Defining folds
2024-06-13 14:31:50,699:INFO:Declaring metric variables
2024-06-13 14:31:50,709:INFO:Importing untrained model
2024-06-13 14:31:50,721:INFO:Linear Discriminant Analysis Imported successfully
2024-06-13 14:31:50,732:INFO:Starting cross validation
2024-06-13 14:31:50,732:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-13 14:31:51,030:INFO:Calculating mean and std
2024-06-13 14:31:51,030:INFO:Creating metrics dataframe
2024-06-13 14:31:51,035:INFO:Uploading results into container
2024-06-13 14:31:51,035:INFO:Uploading model into container now
2024-06-13 14:31:51,035:INFO:_master_model_container: 5
2024-06-13 14:31:51,035:INFO:_display_container: 2
2024-06-13 14:31:51,035:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-06-13 14:31:51,035:INFO:create_model() successfully completed......................................
2024-06-13 14:31:51,198:INFO:SubProcess create_model() end ==================================
2024-06-13 14:31:51,198:INFO:Creating metrics dataframe
2024-06-13 14:31:51,213:INFO:Initializing Extra Trees Classifier
2024-06-13 14:31:51,213:INFO:Total runtime is 0.27501265207926434 minutes
2024-06-13 14:31:51,222:INFO:SubProcess create_model() called ==================================
2024-06-13 14:31:51,222:INFO:Initializing create_model()
2024-06-13 14:31:51,222:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002982933B3D0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000298223538E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-13 14:31:51,222:INFO:Checking exceptions
2024-06-13 14:31:51,223:INFO:Importing libraries
2024-06-13 14:31:51,223:INFO:Copying training dataset
2024-06-13 14:31:51,223:INFO:Defining folds
2024-06-13 14:31:51,223:INFO:Declaring metric variables
2024-06-13 14:31:51,237:INFO:Importing untrained model
2024-06-13 14:31:51,237:INFO:Extra Trees Classifier Imported successfully
2024-06-13 14:31:51,246:INFO:Starting cross validation
2024-06-13 14:31:51,246:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-13 14:31:51,869:INFO:Calculating mean and std
2024-06-13 14:31:51,869:INFO:Creating metrics dataframe
2024-06-13 14:31:51,869:INFO:Uploading results into container
2024-06-13 14:31:51,869:INFO:Uploading model into container now
2024-06-13 14:31:51,869:INFO:_master_model_container: 6
2024-06-13 14:31:51,869:INFO:_display_container: 2
2024-06-13 14:31:51,884:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=4783, verbose=0,
                     warm_start=False)
2024-06-13 14:31:51,884:INFO:create_model() successfully completed......................................
2024-06-13 14:31:52,045:INFO:SubProcess create_model() end ==================================
2024-06-13 14:31:52,045:INFO:Creating metrics dataframe
2024-06-13 14:31:52,080:INFO:Initializing create_model()
2024-06-13 14:31:52,080:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002982933B3D0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-13 14:31:52,080:INFO:Checking exceptions
2024-06-13 14:31:52,080:INFO:Importing libraries
2024-06-13 14:31:52,080:INFO:Copying training dataset
2024-06-13 14:31:52,080:INFO:Defining folds
2024-06-13 14:31:52,080:INFO:Declaring metric variables
2024-06-13 14:31:52,090:INFO:Importing untrained model
2024-06-13 14:31:52,090:INFO:Declaring custom model
2024-06-13 14:31:52,090:INFO:Linear Discriminant Analysis Imported successfully
2024-06-13 14:31:52,093:INFO:Cross validation set to False
2024-06-13 14:31:52,093:INFO:Fitting Model
2024-06-13 14:31:52,123:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-06-13 14:31:52,123:INFO:create_model() successfully completed......................................
2024-06-13 14:31:52,302:INFO:Initializing create_model()
2024-06-13 14:31:52,302:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002982933B3D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4783, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-13 14:31:52,302:INFO:Checking exceptions
2024-06-13 14:31:52,302:INFO:Importing libraries
2024-06-13 14:31:52,302:INFO:Copying training dataset
2024-06-13 14:31:52,312:INFO:Defining folds
2024-06-13 14:31:52,312:INFO:Declaring metric variables
2024-06-13 14:31:52,312:INFO:Importing untrained model
2024-06-13 14:31:52,312:INFO:Declaring custom model
2024-06-13 14:31:52,312:INFO:Logistic Regression Imported successfully
2024-06-13 14:31:52,312:INFO:Cross validation set to False
2024-06-13 14:31:52,312:INFO:Fitting Model
2024-06-13 14:31:52,343:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4783, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-06-13 14:31:52,343:INFO:create_model() successfully completed......................................
2024-06-13 14:31:52,510:INFO:Initializing create_model()
2024-06-13 14:31:52,510:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002982933B3D0>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=4783, verbose=0,
                     warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-13 14:31:52,510:INFO:Checking exceptions
2024-06-13 14:31:52,510:INFO:Importing libraries
2024-06-13 14:31:52,510:INFO:Copying training dataset
2024-06-13 14:31:52,510:INFO:Defining folds
2024-06-13 14:31:52,510:INFO:Declaring metric variables
2024-06-13 14:31:52,510:INFO:Importing untrained model
2024-06-13 14:31:52,510:INFO:Declaring custom model
2024-06-13 14:31:52,510:INFO:Extra Trees Classifier Imported successfully
2024-06-13 14:31:52,510:INFO:Cross validation set to False
2024-06-13 14:31:52,510:INFO:Fitting Model
2024-06-13 14:31:52,668:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=4783, verbose=0,
                     warm_start=False)
2024-06-13 14:31:52,668:INFO:create_model() successfully completed......................................
2024-06-13 14:31:52,824:INFO:Initializing create_model()
2024-06-13 14:31:52,824:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002982933B3D0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4783, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-13 14:31:52,824:INFO:Checking exceptions
2024-06-13 14:31:52,824:INFO:Importing libraries
2024-06-13 14:31:52,824:INFO:Copying training dataset
2024-06-13 14:31:52,840:INFO:Defining folds
2024-06-13 14:31:52,840:INFO:Declaring metric variables
2024-06-13 14:31:52,840:INFO:Importing untrained model
2024-06-13 14:31:52,840:INFO:Declaring custom model
2024-06-13 14:31:52,840:INFO:Gradient Boosting Classifier Imported successfully
2024-06-13 14:31:52,840:INFO:Cross validation set to False
2024-06-13 14:31:52,840:INFO:Fitting Model
2024-06-13 14:31:52,997:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4783, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-06-13 14:31:52,997:INFO:create_model() successfully completed......................................
2024-06-13 14:31:53,155:INFO:Initializing create_model()
2024-06-13 14:31:53,155:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002982933B3D0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=4783, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-13 14:31:53,155:INFO:Checking exceptions
2024-06-13 14:31:53,155:INFO:Importing libraries
2024-06-13 14:31:53,171:INFO:Copying training dataset
2024-06-13 14:31:53,171:INFO:Defining folds
2024-06-13 14:31:53,171:INFO:Declaring metric variables
2024-06-13 14:31:53,171:INFO:Importing untrained model
2024-06-13 14:31:53,171:INFO:Declaring custom model
2024-06-13 14:31:53,171:INFO:Random Forest Classifier Imported successfully
2024-06-13 14:31:53,171:INFO:Cross validation set to False
2024-06-13 14:31:53,171:INFO:Fitting Model
2024-06-13 14:31:53,406:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=4783, verbose=0,
                       warm_start=False)
2024-06-13 14:31:53,406:INFO:create_model() successfully completed......................................
2024-06-13 14:31:53,581:INFO:_master_model_container: 6
2024-06-13 14:31:53,581:INFO:_display_container: 2
2024-06-13 14:31:53,581:INFO:[LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4783, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=4783, verbose=0,
                     warm_start=False), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4783, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=4783, verbose=0,
                       warm_start=False)]
2024-06-13 14:31:53,581:INFO:compare_models() successfully completed......................................
2024-06-13 14:31:53,613:INFO:Initializing create_model()
2024-06-13 14:31:53,613:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002982933B3D0>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-13 14:31:53,613:INFO:Checking exceptions
2024-06-13 14:31:53,661:INFO:Importing libraries
2024-06-13 14:31:53,661:INFO:Copying training dataset
2024-06-13 14:31:53,661:INFO:Defining folds
2024-06-13 14:31:53,661:INFO:Declaring metric variables
2024-06-13 14:31:53,671:INFO:Importing untrained model
2024-06-13 14:31:53,676:INFO:Random Forest Classifier Imported successfully
2024-06-13 14:31:53,695:INFO:Starting cross validation
2024-06-13 14:31:53,696:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-13 14:31:54,427:INFO:Calculating mean and std
2024-06-13 14:31:54,427:INFO:Creating metrics dataframe
2024-06-13 14:31:54,427:INFO:Finalizing model
2024-06-13 14:31:54,631:INFO:Uploading results into container
2024-06-13 14:31:54,631:INFO:Uploading model into container now
2024-06-13 14:31:54,647:INFO:_master_model_container: 7
2024-06-13 14:31:54,647:INFO:_display_container: 3
2024-06-13 14:31:54,647:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=4783, verbose=0,
                       warm_start=False)
2024-06-13 14:31:54,647:INFO:create_model() successfully completed......................................
2024-06-13 14:31:54,819:INFO:Initializing create_model()
2024-06-13 14:31:54,819:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002982933B3D0>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-13 14:31:54,819:INFO:Checking exceptions
2024-06-13 14:31:54,885:INFO:Importing libraries
2024-06-13 14:31:54,885:INFO:Copying training dataset
2024-06-13 14:31:54,891:INFO:Defining folds
2024-06-13 14:31:54,891:INFO:Declaring metric variables
2024-06-13 14:31:54,900:INFO:Importing untrained model
2024-06-13 14:31:54,908:INFO:Logistic Regression Imported successfully
2024-06-13 14:31:54,919:INFO:Starting cross validation
2024-06-13 14:31:54,920:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-13 14:31:55,066:INFO:Calculating mean and std
2024-06-13 14:31:55,066:INFO:Creating metrics dataframe
2024-06-13 14:31:55,066:INFO:Finalizing model
2024-06-13 14:31:55,113:INFO:Uploading results into container
2024-06-13 14:31:55,113:INFO:Uploading model into container now
2024-06-13 14:31:55,129:INFO:_master_model_container: 8
2024-06-13 14:31:55,129:INFO:_display_container: 4
2024-06-13 14:31:55,129:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4783, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-06-13 14:31:55,129:INFO:create_model() successfully completed......................................
2024-06-13 14:31:55,302:INFO:Initializing create_model()
2024-06-13 14:31:55,302:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002982933B3D0>, estimator=lda, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-13 14:31:55,302:INFO:Checking exceptions
2024-06-13 14:31:55,335:INFO:Importing libraries
2024-06-13 14:31:55,336:INFO:Copying training dataset
2024-06-13 14:31:55,342:INFO:Defining folds
2024-06-13 14:31:55,342:INFO:Declaring metric variables
2024-06-13 14:31:55,350:INFO:Importing untrained model
2024-06-13 14:31:55,351:INFO:Linear Discriminant Analysis Imported successfully
2024-06-13 14:31:55,366:INFO:Starting cross validation
2024-06-13 14:31:55,367:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-13 14:31:55,455:INFO:Calculating mean and std
2024-06-13 14:31:55,455:INFO:Creating metrics dataframe
2024-06-13 14:31:55,455:INFO:Finalizing model
2024-06-13 14:31:55,474:INFO:Uploading results into container
2024-06-13 14:31:55,474:INFO:Uploading model into container now
2024-06-13 14:31:55,487:INFO:_master_model_container: 9
2024-06-13 14:31:55,487:INFO:_display_container: 5
2024-06-13 14:31:55,487:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-06-13 14:31:55,487:INFO:create_model() successfully completed......................................
2024-06-13 14:31:55,659:INFO:Initializing create_model()
2024-06-13 14:31:55,659:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002982933B3D0>, estimator=gbc, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-13 14:31:55,659:INFO:Checking exceptions
2024-06-13 14:31:55,686:INFO:Importing libraries
2024-06-13 14:31:55,687:INFO:Copying training dataset
2024-06-13 14:31:55,689:INFO:Defining folds
2024-06-13 14:31:55,689:INFO:Declaring metric variables
2024-06-13 14:31:55,695:INFO:Importing untrained model
2024-06-13 14:31:55,695:INFO:Gradient Boosting Classifier Imported successfully
2024-06-13 14:31:55,708:INFO:Starting cross validation
2024-06-13 14:31:55,711:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-13 14:31:56,313:INFO:Calculating mean and std
2024-06-13 14:31:56,313:INFO:Creating metrics dataframe
2024-06-13 14:31:56,313:INFO:Finalizing model
2024-06-13 14:31:56,495:INFO:Uploading results into container
2024-06-13 14:31:56,502:INFO:Uploading model into container now
2024-06-13 14:31:56,518:INFO:_master_model_container: 10
2024-06-13 14:31:56,518:INFO:_display_container: 6
2024-06-13 14:31:56,518:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4783, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-06-13 14:31:56,518:INFO:create_model() successfully completed......................................
2024-06-13 14:31:56,922:INFO:Initializing tune_model()
2024-06-13 14:31:56,922:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=4783, verbose=0,
                       warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002982933B3D0>)
2024-06-13 14:31:56,922:INFO:Checking exceptions
2024-06-13 14:31:56,970:INFO:Copying training dataset
2024-06-13 14:31:56,978:INFO:Checking base model
2024-06-13 14:31:56,978:INFO:Base model : Random Forest Classifier
2024-06-13 14:31:56,978:INFO:Declaring metric variables
2024-06-13 14:31:56,991:INFO:Defining Hyperparameters
2024-06-13 14:31:57,180:INFO:Tuning with n_jobs=-1
2024-06-13 14:31:57,180:INFO:Initializing RandomizedSearchCV
2024-06-13 14:32:05,344:INFO:best_params: {'actual_estimator__n_estimators': 80, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0.01, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 7, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': 'balanced', 'actual_estimator__bootstrap': True}
2024-06-13 14:32:05,344:INFO:Hyperparameter search completed
2024-06-13 14:32:05,344:INFO:SubProcess create_model() called ==================================
2024-06-13 14:32:05,344:INFO:Initializing create_model()
2024-06-13 14:32:05,344:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002982933B3D0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=4783, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029829791DF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 80, 'min_samples_split': 10, 'min_samples_leaf': 6, 'min_impurity_decrease': 0.01, 'max_features': 'log2', 'max_depth': 7, 'criterion': 'gini', 'class_weight': 'balanced', 'bootstrap': True})
2024-06-13 14:32:05,344:INFO:Checking exceptions
2024-06-13 14:32:05,344:INFO:Importing libraries
2024-06-13 14:32:05,344:INFO:Copying training dataset
2024-06-13 14:32:05,344:INFO:Defining folds
2024-06-13 14:32:05,344:INFO:Declaring metric variables
2024-06-13 14:32:05,360:INFO:Importing untrained model
2024-06-13 14:32:05,360:INFO:Declaring custom model
2024-06-13 14:32:05,360:INFO:Random Forest Classifier Imported successfully
2024-06-13 14:32:05,375:INFO:Starting cross validation
2024-06-13 14:32:05,375:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-13 14:32:06,120:INFO:Calculating mean and std
2024-06-13 14:32:06,121:INFO:Creating metrics dataframe
2024-06-13 14:32:06,121:INFO:Finalizing model
2024-06-13 14:32:06,276:INFO:Uploading results into container
2024-06-13 14:32:06,276:INFO:Uploading model into container now
2024-06-13 14:32:06,276:INFO:_master_model_container: 11
2024-06-13 14:32:06,276:INFO:_display_container: 7
2024-06-13 14:32:06,276:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=7, max_features='log2',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.01, min_samples_leaf=6,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=80, n_jobs=-1,
                       oob_score=False, random_state=4783, verbose=0,
                       warm_start=False)
2024-06-13 14:32:06,276:INFO:create_model() successfully completed......................................
2024-06-13 14:32:06,457:INFO:SubProcess create_model() end ==================================
2024-06-13 14:32:06,457:INFO:choose_better activated
2024-06-13 14:32:06,465:INFO:SubProcess create_model() called ==================================
2024-06-13 14:32:06,465:INFO:Initializing create_model()
2024-06-13 14:32:06,465:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002982933B3D0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=4783, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-13 14:32:06,465:INFO:Checking exceptions
2024-06-13 14:32:06,465:INFO:Importing libraries
2024-06-13 14:32:06,465:INFO:Copying training dataset
2024-06-13 14:32:06,465:INFO:Defining folds
2024-06-13 14:32:06,465:INFO:Declaring metric variables
2024-06-13 14:32:06,465:INFO:Importing untrained model
2024-06-13 14:32:06,465:INFO:Declaring custom model
2024-06-13 14:32:06,465:INFO:Random Forest Classifier Imported successfully
2024-06-13 14:32:06,465:INFO:Starting cross validation
2024-06-13 14:32:06,481:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-13 14:32:07,524:INFO:Calculating mean and std
2024-06-13 14:32:07,524:INFO:Creating metrics dataframe
2024-06-13 14:32:07,524:INFO:Finalizing model
2024-06-13 14:32:07,787:INFO:Uploading results into container
2024-06-13 14:32:07,790:INFO:Uploading model into container now
2024-06-13 14:32:07,790:INFO:_master_model_container: 12
2024-06-13 14:32:07,790:INFO:_display_container: 8
2024-06-13 14:32:07,792:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=4783, verbose=0,
                       warm_start=False)
2024-06-13 14:32:07,792:INFO:create_model() successfully completed......................................
2024-06-13 14:32:07,946:INFO:SubProcess create_model() end ==================================
2024-06-13 14:32:07,956:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=4783, verbose=0,
                       warm_start=False) result for AUC is 0.8273
2024-06-13 14:32:07,956:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=7, max_features='log2',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.01, min_samples_leaf=6,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=80, n_jobs=-1,
                       oob_score=False, random_state=4783, verbose=0,
                       warm_start=False) result for AUC is 0.8387
2024-06-13 14:32:07,956:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=7, max_features='log2',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.01, min_samples_leaf=6,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=80, n_jobs=-1,
                       oob_score=False, random_state=4783, verbose=0,
                       warm_start=False) is best model
2024-06-13 14:32:07,956:INFO:choose_better completed
2024-06-13 14:32:07,968:INFO:_master_model_container: 12
2024-06-13 14:32:07,968:INFO:_display_container: 7
2024-06-13 14:32:07,968:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=7, max_features='log2',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.01, min_samples_leaf=6,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=80, n_jobs=-1,
                       oob_score=False, random_state=4783, verbose=0,
                       warm_start=False)
2024-06-13 14:32:07,968:INFO:tune_model() successfully completed......................................
2024-06-13 14:32:08,179:INFO:Initializing tune_model()
2024-06-13 14:32:08,179:INFO:tune_model(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4783, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002982933B3D0>)
2024-06-13 14:32:08,179:INFO:Checking exceptions
2024-06-13 14:32:08,227:INFO:Copying training dataset
2024-06-13 14:32:08,235:INFO:Checking base model
2024-06-13 14:32:08,235:INFO:Base model : Logistic Regression
2024-06-13 14:32:08,241:INFO:Declaring metric variables
2024-06-13 14:32:08,249:INFO:Defining Hyperparameters
2024-06-13 14:32:08,491:INFO:Tuning with n_jobs=-1
2024-06-13 14:32:08,491:INFO:Initializing RandomizedSearchCV
2024-06-13 14:32:09,502:INFO:best_params: {'actual_estimator__class_weight': 'balanced', 'actual_estimator__C': 8.786}
2024-06-13 14:32:09,502:INFO:Hyperparameter search completed
2024-06-13 14:32:09,502:INFO:SubProcess create_model() called ==================================
2024-06-13 14:32:09,502:INFO:Initializing create_model()
2024-06-13 14:32:09,502:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002982933B3D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4783, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002982255BFA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'class_weight': 'balanced', 'C': 8.786})
2024-06-13 14:32:09,502:INFO:Checking exceptions
2024-06-13 14:32:09,502:INFO:Importing libraries
2024-06-13 14:32:09,502:INFO:Copying training dataset
2024-06-13 14:32:09,502:INFO:Defining folds
2024-06-13 14:32:09,502:INFO:Declaring metric variables
2024-06-13 14:32:09,513:INFO:Importing untrained model
2024-06-13 14:32:09,513:INFO:Declaring custom model
2024-06-13 14:32:09,513:INFO:Logistic Regression Imported successfully
2024-06-13 14:32:09,524:INFO:Starting cross validation
2024-06-13 14:32:09,524:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-13 14:32:09,702:INFO:Calculating mean and std
2024-06-13 14:32:09,702:INFO:Creating metrics dataframe
2024-06-13 14:32:09,713:INFO:Finalizing model
2024-06-13 14:32:09,751:INFO:Uploading results into container
2024-06-13 14:32:09,751:INFO:Uploading model into container now
2024-06-13 14:32:09,757:INFO:_master_model_container: 13
2024-06-13 14:32:09,757:INFO:_display_container: 8
2024-06-13 14:32:09,757:INFO:LogisticRegression(C=8.786, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4783, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-06-13 14:32:09,757:INFO:create_model() successfully completed......................................
2024-06-13 14:32:09,943:INFO:SubProcess create_model() end ==================================
2024-06-13 14:32:09,943:INFO:choose_better activated
2024-06-13 14:32:09,947:INFO:SubProcess create_model() called ==================================
2024-06-13 14:32:09,947:INFO:Initializing create_model()
2024-06-13 14:32:09,947:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002982933B3D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4783, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-13 14:32:09,947:INFO:Checking exceptions
2024-06-13 14:32:09,947:INFO:Importing libraries
2024-06-13 14:32:09,947:INFO:Copying training dataset
2024-06-13 14:32:09,960:INFO:Defining folds
2024-06-13 14:32:09,960:INFO:Declaring metric variables
2024-06-13 14:32:09,960:INFO:Importing untrained model
2024-06-13 14:32:09,960:INFO:Declaring custom model
2024-06-13 14:32:09,960:INFO:Logistic Regression Imported successfully
2024-06-13 14:32:09,960:INFO:Starting cross validation
2024-06-13 14:32:09,960:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-13 14:32:10,124:INFO:Calculating mean and std
2024-06-13 14:32:10,124:INFO:Creating metrics dataframe
2024-06-13 14:32:10,124:INFO:Finalizing model
2024-06-13 14:32:10,146:INFO:Uploading results into container
2024-06-13 14:32:10,146:INFO:Uploading model into container now
2024-06-13 14:32:10,146:INFO:_master_model_container: 14
2024-06-13 14:32:10,146:INFO:_display_container: 9
2024-06-13 14:32:10,146:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4783, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-06-13 14:32:10,146:INFO:create_model() successfully completed......................................
2024-06-13 14:32:10,346:INFO:SubProcess create_model() end ==================================
2024-06-13 14:32:10,346:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4783, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.8534
2024-06-13 14:32:10,357:INFO:LogisticRegression(C=8.786, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4783, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for AUC is 0.8532
2024-06-13 14:32:10,357:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4783, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2024-06-13 14:32:10,357:INFO:choose_better completed
2024-06-13 14:32:10,357:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-06-13 14:32:10,368:INFO:_master_model_container: 14
2024-06-13 14:32:10,368:INFO:_display_container: 8
2024-06-13 14:32:10,368:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4783, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-06-13 14:32:10,368:INFO:tune_model() successfully completed......................................
2024-06-13 14:32:10,557:INFO:Initializing tune_model()
2024-06-13 14:32:10,557:INFO:tune_model(estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002982933B3D0>)
2024-06-13 14:32:10,557:INFO:Checking exceptions
2024-06-13 14:32:10,617:INFO:Copying training dataset
2024-06-13 14:32:10,618:INFO:Checking base model
2024-06-13 14:32:10,621:INFO:Base model : Linear Discriminant Analysis
2024-06-13 14:32:10,629:INFO:Declaring metric variables
2024-06-13 14:32:10,630:INFO:Defining Hyperparameters
2024-06-13 14:32:10,824:INFO:Tuning with n_jobs=-1
2024-06-13 14:32:10,824:INFO:Initializing RandomizedSearchCV
2024-06-13 14:32:11,246:INFO:best_params: {'actual_estimator__solver': 'eigen', 'actual_estimator__shrinkage': 'auto'}
2024-06-13 14:32:11,246:INFO:Hyperparameter search completed
2024-06-13 14:32:11,246:INFO:SubProcess create_model() called ==================================
2024-06-13 14:32:11,246:INFO:Initializing create_model()
2024-06-13 14:32:11,246:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002982933B3D0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029828E9ECD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'solver': 'eigen', 'shrinkage': 'auto'})
2024-06-13 14:32:11,246:INFO:Checking exceptions
2024-06-13 14:32:11,246:INFO:Importing libraries
2024-06-13 14:32:11,246:INFO:Copying training dataset
2024-06-13 14:32:11,246:INFO:Defining folds
2024-06-13 14:32:11,246:INFO:Declaring metric variables
2024-06-13 14:32:11,257:INFO:Importing untrained model
2024-06-13 14:32:11,257:INFO:Declaring custom model
2024-06-13 14:32:11,257:INFO:Linear Discriminant Analysis Imported successfully
2024-06-13 14:32:11,268:INFO:Starting cross validation
2024-06-13 14:32:11,268:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-13 14:32:11,379:INFO:Calculating mean and std
2024-06-13 14:32:11,379:INFO:Creating metrics dataframe
2024-06-13 14:32:11,379:INFO:Finalizing model
2024-06-13 14:32:11,402:INFO:Uploading results into container
2024-06-13 14:32:11,402:INFO:Uploading model into container now
2024-06-13 14:32:11,402:INFO:_master_model_container: 15
2024-06-13 14:32:11,402:INFO:_display_container: 9
2024-06-13 14:32:11,402:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage='auto', solver='eigen',
                           store_covariance=False, tol=0.0001)
2024-06-13 14:32:11,402:INFO:create_model() successfully completed......................................
2024-06-13 14:32:11,590:INFO:SubProcess create_model() end ==================================
2024-06-13 14:32:11,590:INFO:choose_better activated
2024-06-13 14:32:11,590:INFO:SubProcess create_model() called ==================================
2024-06-13 14:32:11,590:INFO:Initializing create_model()
2024-06-13 14:32:11,590:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002982933B3D0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-13 14:32:11,590:INFO:Checking exceptions
2024-06-13 14:32:11,601:INFO:Importing libraries
2024-06-13 14:32:11,601:INFO:Copying training dataset
2024-06-13 14:32:11,601:INFO:Defining folds
2024-06-13 14:32:11,601:INFO:Declaring metric variables
2024-06-13 14:32:11,601:INFO:Importing untrained model
2024-06-13 14:32:11,601:INFO:Declaring custom model
2024-06-13 14:32:11,601:INFO:Linear Discriminant Analysis Imported successfully
2024-06-13 14:32:11,601:INFO:Starting cross validation
2024-06-13 14:32:11,601:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-13 14:32:11,705:INFO:Calculating mean and std
2024-06-13 14:32:11,705:INFO:Creating metrics dataframe
2024-06-13 14:32:11,709:INFO:Finalizing model
2024-06-13 14:32:11,709:INFO:Uploading results into container
2024-06-13 14:32:11,716:INFO:Uploading model into container now
2024-06-13 14:32:11,716:INFO:_master_model_container: 16
2024-06-13 14:32:11,716:INFO:_display_container: 10
2024-06-13 14:32:11,716:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-06-13 14:32:11,716:INFO:create_model() successfully completed......................................
2024-06-13 14:32:12,064:INFO:SubProcess create_model() end ==================================
2024-06-13 14:32:12,064:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001) result for AUC is 0.854
2024-06-13 14:32:12,064:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage='auto', solver='eigen',
                           store_covariance=False, tol=0.0001) result for AUC is 0.8517
2024-06-13 14:32:12,064:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001) is best model
2024-06-13 14:32:12,064:INFO:choose_better completed
2024-06-13 14:32:12,064:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-06-13 14:32:12,080:INFO:_master_model_container: 16
2024-06-13 14:32:12,080:INFO:_display_container: 9
2024-06-13 14:32:12,080:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-06-13 14:32:12,080:INFO:tune_model() successfully completed......................................
2024-06-13 14:32:12,357:INFO:Initializing tune_model()
2024-06-13 14:32:12,357:INFO:tune_model(estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4783, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002982933B3D0>)
2024-06-13 14:32:12,357:INFO:Checking exceptions
2024-06-13 14:32:12,411:INFO:Copying training dataset
2024-06-13 14:32:12,418:INFO:Checking base model
2024-06-13 14:32:12,418:INFO:Base model : Gradient Boosting Classifier
2024-06-13 14:32:12,424:INFO:Declaring metric variables
2024-06-13 14:32:12,427:INFO:Defining Hyperparameters
2024-06-13 14:32:12,680:INFO:Tuning with n_jobs=-1
2024-06-13 14:32:12,680:INFO:Initializing RandomizedSearchCV
2024-06-13 14:32:23,923:INFO:best_params: {'actual_estimator__subsample': 0.75, 'actual_estimator__n_estimators': 50, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.5, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 7, 'actual_estimator__learning_rate': 0.01}
2024-06-13 14:32:23,923:INFO:Hyperparameter search completed
2024-06-13 14:32:23,923:INFO:SubProcess create_model() called ==================================
2024-06-13 14:32:23,923:INFO:Initializing create_model()
2024-06-13 14:32:23,923:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002982933B3D0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4783, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000029827593F10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.75, 'n_estimators': 50, 'min_samples_split': 10, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.5, 'max_features': 'log2', 'max_depth': 7, 'learning_rate': 0.01})
2024-06-13 14:32:23,923:INFO:Checking exceptions
2024-06-13 14:32:23,923:INFO:Importing libraries
2024-06-13 14:32:23,923:INFO:Copying training dataset
2024-06-13 14:32:23,931:INFO:Defining folds
2024-06-13 14:32:23,931:INFO:Declaring metric variables
2024-06-13 14:32:23,935:INFO:Importing untrained model
2024-06-13 14:32:23,935:INFO:Declaring custom model
2024-06-13 14:32:23,947:INFO:Gradient Boosting Classifier Imported successfully
2024-06-13 14:32:23,956:INFO:Starting cross validation
2024-06-13 14:32:23,959:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-13 14:32:24,323:INFO:Calculating mean and std
2024-06-13 14:32:24,323:INFO:Creating metrics dataframe
2024-06-13 14:32:24,335:INFO:Finalizing model
2024-06-13 14:32:24,445:INFO:Uploading results into container
2024-06-13 14:32:24,446:INFO:Uploading model into container now
2024-06-13 14:32:24,446:INFO:_master_model_container: 17
2024-06-13 14:32:24,446:INFO:_display_container: 10
2024-06-13 14:32:24,446:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='log_loss', max_depth=7,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.5, min_samples_leaf=4,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=50, n_iter_no_change=None,
                           random_state=4783, subsample=0.75, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-06-13 14:32:24,446:INFO:create_model() successfully completed......................................
2024-06-13 14:32:24,646:INFO:SubProcess create_model() end ==================================
2024-06-13 14:32:24,646:INFO:choose_better activated
2024-06-13 14:32:24,660:INFO:SubProcess create_model() called ==================================
2024-06-13 14:32:24,660:INFO:Initializing create_model()
2024-06-13 14:32:24,660:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002982933B3D0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4783, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-13 14:32:24,660:INFO:Checking exceptions
2024-06-13 14:32:24,660:INFO:Importing libraries
2024-06-13 14:32:24,660:INFO:Copying training dataset
2024-06-13 14:32:24,668:INFO:Defining folds
2024-06-13 14:32:24,668:INFO:Declaring metric variables
2024-06-13 14:32:24,668:INFO:Importing untrained model
2024-06-13 14:32:24,668:INFO:Declaring custom model
2024-06-13 14:32:24,668:INFO:Gradient Boosting Classifier Imported successfully
2024-06-13 14:32:24,668:INFO:Starting cross validation
2024-06-13 14:32:24,668:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-13 14:32:25,212:INFO:Calculating mean and std
2024-06-13 14:32:25,214:INFO:Creating metrics dataframe
2024-06-13 14:32:25,214:INFO:Finalizing model
2024-06-13 14:32:25,423:INFO:Uploading results into container
2024-06-13 14:32:25,423:INFO:Uploading model into container now
2024-06-13 14:32:25,423:INFO:_master_model_container: 18
2024-06-13 14:32:25,423:INFO:_display_container: 11
2024-06-13 14:32:25,423:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4783, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-06-13 14:32:25,423:INFO:create_model() successfully completed......................................
2024-06-13 14:32:25,561:INFO:SubProcess create_model() end ==================================
2024-06-13 14:32:25,567:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4783, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for AUC is 0.8333
2024-06-13 14:32:25,568:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='log_loss', max_depth=7,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.5, min_samples_leaf=4,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=50, n_iter_no_change=None,
                           random_state=4783, subsample=0.75, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for AUC is 0.8389
2024-06-13 14:32:25,568:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='log_loss', max_depth=7,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.5, min_samples_leaf=4,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=50, n_iter_no_change=None,
                           random_state=4783, subsample=0.75, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2024-06-13 14:32:25,568:INFO:choose_better completed
2024-06-13 14:32:25,579:INFO:_master_model_container: 18
2024-06-13 14:32:25,579:INFO:_display_container: 10
2024-06-13 14:32:25,579:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='log_loss', max_depth=7,
                           max_features='log2', max_leaf_nodes=None,
                           min_impurity_decrease=0.5, min_samples_leaf=4,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=50, n_iter_no_change=None,
                           random_state=4783, subsample=0.75, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-06-13 14:32:25,579:INFO:tune_model() successfully completed......................................
2024-06-13 14:32:25,779:INFO:Initializing stack_models()
2024-06-13 14:32:25,779:INFO:stack_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002982933B3D0>, estimator_list=[LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4783, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=4783, verbose=0,
                     warm_start=False), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4783, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=4783, verbose=0,
                       warm_start=False)], meta_model=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), meta_model_fold=5, fold=None, round=4, method=auto, restack=False, choose_better=False, optimize=AUC, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2024-06-13 14:32:25,779:INFO:Checking exceptions
2024-06-13 14:32:25,790:INFO:Defining meta model
2024-06-13 14:32:25,842:INFO:Getting model names
2024-06-13 14:32:25,850:INFO:[('Linear Discriminant Analysis', LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)), ('Logistic Regression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4783, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)), ('Extra Trees Classifier', ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=4783, verbose=0,
                     warm_start=False)), ('Gradient Boosting Classifier', GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4783, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)), ('Random Forest Classifier', RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=4783, verbose=0,
                       warm_start=False))]
2024-06-13 14:32:25,856:INFO:SubProcess create_model() called ==================================
2024-06-13 14:32:25,867:INFO:Initializing create_model()
2024-06-13 14:32:25,867:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002982933B3D0>, estimator=StackingClassifier(cv=5,
                   estimators=[('Linear Discriminant Analysis',
                                LinearDiscriminantAnalysis(covariance_estimator=None,
                                                           n_components=None,
                                                           priors=None,
                                                           shrinkage=None,
                                                           solver='svd',
                                                           store_covariance=False,
                                                           tol=0.0001)),
                               ('Logistic Regression',
                                LogisticRegression(C=1.0, class_weight=None,
                                                   dual=False,
                                                   fit_intercept=True,
                                                   intercept_scaling=1,
                                                   l1_ratio=None, max_iter...
                                                       min_weight_fraction_leaf=0.0,
                                                       monotonic_cst=None,
                                                       n_estimators=100,
                                                       n_jobs=-1,
                                                       oob_score=False,
                                                       random_state=4783,
                                                       verbose=0,
                                                       warm_start=False))],
                   final_estimator=LinearDiscriminantAnalysis(covariance_estimator=None,
                                                              n_components=None,
                                                              priors=None,
                                                              shrinkage=None,
                                                              solver='svd',
                                                              store_covariance=False,
                                                              tol=0.0001),
                   n_jobs=-1, passthrough=False, stack_method='auto',
                   verbose=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000298295926D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-13 14:32:25,867:INFO:Checking exceptions
2024-06-13 14:32:25,867:INFO:Importing libraries
2024-06-13 14:32:25,867:INFO:Copying training dataset
2024-06-13 14:32:25,874:INFO:Defining folds
2024-06-13 14:32:25,874:INFO:Declaring metric variables
2024-06-13 14:32:25,874:INFO:Importing untrained model
2024-06-13 14:32:25,882:INFO:Declaring custom model
2024-06-13 14:32:25,884:INFO:Stacking Classifier Imported successfully
2024-06-13 14:32:25,899:INFO:Starting cross validation
2024-06-13 14:32:25,900:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-13 14:32:41,187:INFO:Calculating mean and std
2024-06-13 14:32:41,194:INFO:Creating metrics dataframe
2024-06-13 14:32:41,214:INFO:Finalizing model
2024-06-13 14:32:44,471:INFO:Uploading results into container
2024-06-13 14:32:44,474:INFO:Uploading model into container now
2024-06-13 14:32:44,474:INFO:_master_model_container: 19
2024-06-13 14:32:44,474:INFO:_display_container: 11
2024-06-13 14:32:44,496:INFO:StackingClassifier(cv=5,
                   estimators=[('Linear Discriminant Analysis',
                                LinearDiscriminantAnalysis(covariance_estimator=None,
                                                           n_components=None,
                                                           priors=None,
                                                           shrinkage=None,
                                                           solver='svd',
                                                           store_covariance=False,
                                                           tol=0.0001)),
                               ('Logistic Regression',
                                LogisticRegression(C=1.0, class_weight=None,
                                                   dual=False,
                                                   fit_intercept=True,
                                                   intercept_scaling=1,
                                                   l1_ratio=None, max_iter...
                                                       min_weight_fraction_leaf=0.0,
                                                       monotonic_cst=None,
                                                       n_estimators=100,
                                                       n_jobs=-1,
                                                       oob_score=False,
                                                       random_state=4783,
                                                       verbose=0,
                                                       warm_start=False))],
                   final_estimator=LinearDiscriminantAnalysis(covariance_estimator=None,
                                                              n_components=None,
                                                              priors=None,
                                                              shrinkage=None,
                                                              solver='svd',
                                                              store_covariance=False,
                                                              tol=0.0001),
                   n_jobs=-1, passthrough=False, stack_method='auto',
                   verbose=0)
2024-06-13 14:32:44,496:INFO:create_model() successfully completed......................................
2024-06-13 14:32:44,773:INFO:SubProcess create_model() end ==================================
2024-06-13 14:32:44,809:INFO:_master_model_container: 19
2024-06-13 14:32:44,809:INFO:_display_container: 11
2024-06-13 14:32:44,832:INFO:StackingClassifier(cv=5,
                   estimators=[('Linear Discriminant Analysis',
                                LinearDiscriminantAnalysis(covariance_estimator=None,
                                                           n_components=None,
                                                           priors=None,
                                                           shrinkage=None,
                                                           solver='svd',
                                                           store_covariance=False,
                                                           tol=0.0001)),
                               ('Logistic Regression',
                                LogisticRegression(C=1.0, class_weight=None,
                                                   dual=False,
                                                   fit_intercept=True,
                                                   intercept_scaling=1,
                                                   l1_ratio=None, max_iter...
                                                       min_weight_fraction_leaf=0.0,
                                                       monotonic_cst=None,
                                                       n_estimators=100,
                                                       n_jobs=-1,
                                                       oob_score=False,
                                                       random_state=4783,
                                                       verbose=0,
                                                       warm_start=False))],
                   final_estimator=LinearDiscriminantAnalysis(covariance_estimator=None,
                                                              n_components=None,
                                                              priors=None,
                                                              shrinkage=None,
                                                              solver='svd',
                                                              store_covariance=False,
                                                              tol=0.0001),
                   n_jobs=-1, passthrough=False, stack_method='auto',
                   verbose=0)
2024-06-13 14:32:44,832:INFO:stack_models() successfully completed......................................
2024-06-13 14:32:45,272:INFO:Initializing plot_model()
2024-06-13 14:32:45,272:INFO:plot_model(plot=boundary, fold=None, verbose=True, display=None, display_format=None, estimator=StackingClassifier(cv=5,
                   estimators=[('Linear Discriminant Analysis',
                                LinearDiscriminantAnalysis(covariance_estimator=None,
                                                           n_components=None,
                                                           priors=None,
                                                           shrinkage=None,
                                                           solver='svd',
                                                           store_covariance=False,
                                                           tol=0.0001)),
                               ('Logistic Regression',
                                LogisticRegression(C=1.0, class_weight=None,
                                                   dual=False,
                                                   fit_intercept=True,
                                                   intercept_scaling=1,
                                                   l1_ratio=None, max_iter...
                                                       min_weight_fraction_leaf=0.0,
                                                       monotonic_cst=None,
                                                       n_estimators=100,
                                                       n_jobs=-1,
                                                       oob_score=False,
                                                       random_state=4783,
                                                       verbose=0,
                                                       warm_start=False))],
                   final_estimator=LinearDiscriminantAnalysis(covariance_estimator=None,
                                                              n_components=None,
                                                              priors=None,
                                                              shrinkage=None,
                                                              solver='svd',
                                                              store_covariance=False,
                                                              tol=0.0001),
                   n_jobs=-1, passthrough=False, stack_method='auto',
                   verbose=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002982933B3D0>, system=True)
2024-06-13 14:32:45,272:INFO:Checking exceptions
2024-06-13 14:32:45,284:INFO:Preloading libraries
2024-06-13 14:32:45,402:INFO:Copying training dataset
2024-06-13 14:32:45,402:INFO:Plot type: boundary
2024-06-13 14:32:45,470:INFO:Fitting StandardScaler()
2024-06-13 14:32:45,491:INFO:Fitting PCA()
2024-06-13 14:32:45,558:INFO:Fitting Model
2024-06-13 14:32:53,297:INFO:Visual Rendered Successfully
2024-06-13 14:32:53,791:INFO:plot_model() successfully completed......................................
2024-06-13 14:32:53,928:INFO:Initializing plot_model()
2024-06-13 14:32:53,928:INFO:plot_model(plot=auc, fold=None, verbose=True, display=None, display_format=None, estimator=StackingClassifier(cv=5,
                   estimators=[('Linear Discriminant Analysis',
                                LinearDiscriminantAnalysis(covariance_estimator=None,
                                                           n_components=None,
                                                           priors=None,
                                                           shrinkage=None,
                                                           solver='svd',
                                                           store_covariance=False,
                                                           tol=0.0001)),
                               ('Logistic Regression',
                                LogisticRegression(C=1.0, class_weight=None,
                                                   dual=False,
                                                   fit_intercept=True,
                                                   intercept_scaling=1,
                                                   l1_ratio=None, max_iter...
                                                       min_weight_fraction_leaf=0.0,
                                                       monotonic_cst=None,
                                                       n_estimators=100,
                                                       n_jobs=-1,
                                                       oob_score=False,
                                                       random_state=4783,
                                                       verbose=0,
                                                       warm_start=False))],
                   final_estimator=LinearDiscriminantAnalysis(covariance_estimator=None,
                                                              n_components=None,
                                                              priors=None,
                                                              shrinkage=None,
                                                              solver='svd',
                                                              store_covariance=False,
                                                              tol=0.0001),
                   n_jobs=-1, passthrough=False, stack_method='auto',
                   verbose=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002982933B3D0>, system=True)
2024-06-13 14:32:53,928:INFO:Checking exceptions
2024-06-13 14:32:53,946:INFO:Preloading libraries
2024-06-13 14:32:54,051:INFO:Copying training dataset
2024-06-13 14:32:54,051:INFO:Plot type: auc
2024-06-13 14:32:54,153:INFO:Fitting Model
2024-06-13 14:32:54,153:INFO:Scoring test/hold-out set
2024-06-13 14:32:55,450:INFO:Visual Rendered Successfully
2024-06-13 14:32:55,771:INFO:plot_model() successfully completed......................................
2024-06-13 14:32:56,855:INFO:Initializing blend_models()
2024-06-13 14:32:56,860:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002982933B3D0>, estimator_list=[LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4783, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=4783, verbose=0,
                     warm_start=False), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4783, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=4783, verbose=0,
                       warm_start=False)], fold=None, round=4, choose_better=False, optimize=AUC, method=soft, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2024-06-13 14:32:56,861:INFO:Checking exceptions
2024-06-13 14:32:56,972:INFO:Importing libraries
2024-06-13 14:32:56,972:INFO:Copying training dataset
2024-06-13 14:32:56,995:INFO:Getting model names
2024-06-13 14:32:57,011:INFO:SubProcess create_model() called ==================================
2024-06-13 14:32:57,035:INFO:Initializing create_model()
2024-06-13 14:32:57,035:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002982933B3D0>, estimator=VotingClassifier(estimators=[('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covariance_estimator=None,
                                                         n_components=None,
                                                         priors=None,
                                                         shrinkage=None,
                                                         solver='svd',
                                                         store_covariance=False,
                                                         tol=0.0001)),
                             ('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 m...
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=4783,
                                                     verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000298296883D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-13 14:32:57,035:INFO:Checking exceptions
2024-06-13 14:32:57,035:INFO:Importing libraries
2024-06-13 14:32:57,035:INFO:Copying training dataset
2024-06-13 14:32:57,040:INFO:Defining folds
2024-06-13 14:32:57,040:INFO:Declaring metric variables
2024-06-13 14:32:57,055:INFO:Importing untrained model
2024-06-13 14:32:57,055:INFO:Declaring custom model
2024-06-13 14:32:57,080:INFO:Voting Classifier Imported successfully
2024-06-13 14:32:57,100:INFO:Starting cross validation
2024-06-13 14:32:57,110:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-13 14:33:02,016:INFO:Calculating mean and std
2024-06-13 14:33:02,024:INFO:Creating metrics dataframe
2024-06-13 14:33:02,043:INFO:Finalizing model
2024-06-13 14:33:02,703:INFO:Uploading results into container
2024-06-13 14:33:02,707:INFO:Uploading model into container now
2024-06-13 14:33:02,708:INFO:_master_model_container: 20
2024-06-13 14:33:02,708:INFO:_display_container: 12
2024-06-13 14:33:02,729:INFO:VotingClassifier(estimators=[('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covariance_estimator=None,
                                                         n_components=None,
                                                         priors=None,
                                                         shrinkage=None,
                                                         solver='svd',
                                                         store_covariance=False,
                                                         tol=0.0001)),
                             ('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 m...
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=4783,
                                                     verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2024-06-13 14:33:02,729:INFO:create_model() successfully completed......................................
2024-06-13 14:33:02,983:INFO:SubProcess create_model() end ==================================
2024-06-13 14:33:03,012:INFO:_master_model_container: 20
2024-06-13 14:33:03,013:INFO:_display_container: 12
2024-06-13 14:33:03,033:INFO:VotingClassifier(estimators=[('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covariance_estimator=None,
                                                         n_components=None,
                                                         priors=None,
                                                         shrinkage=None,
                                                         solver='svd',
                                                         store_covariance=False,
                                                         tol=0.0001)),
                             ('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 m...
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=4783,
                                                     verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2024-06-13 14:33:03,033:INFO:blend_models() successfully completed......................................
2024-06-13 14:33:03,393:INFO:Initializing plot_model()
2024-06-13 14:33:03,394:INFO:plot_model(plot=boundary, fold=None, verbose=True, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covariance_estimator=None,
                                                         n_components=None,
                                                         priors=None,
                                                         shrinkage=None,
                                                         solver='svd',
                                                         store_covariance=False,
                                                         tol=0.0001)),
                             ('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 m...
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=4783,
                                                     verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002982933B3D0>, system=True)
2024-06-13 14:33:03,394:INFO:Checking exceptions
2024-06-13 14:33:03,410:INFO:Preloading libraries
2024-06-13 14:33:03,491:INFO:Copying training dataset
2024-06-13 14:33:03,492:INFO:Plot type: boundary
2024-06-13 14:33:03,543:INFO:Fitting StandardScaler()
2024-06-13 14:33:03,560:INFO:Fitting PCA()
2024-06-13 14:33:03,619:INFO:Fitting Model
2024-06-13 14:33:08,463:INFO:Visual Rendered Successfully
2024-06-13 14:33:08,919:INFO:plot_model() successfully completed......................................
2024-06-13 14:33:09,005:INFO:Initializing plot_model()
2024-06-13 14:33:09,005:INFO:plot_model(plot=auc, fold=None, verbose=True, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covariance_estimator=None,
                                                         n_components=None,
                                                         priors=None,
                                                         shrinkage=None,
                                                         solver='svd',
                                                         store_covariance=False,
                                                         tol=0.0001)),
                             ('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 m...
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=4783,
                                                     verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002982933B3D0>, system=True)
2024-06-13 14:33:09,005:INFO:Checking exceptions
2024-06-13 14:33:09,012:INFO:Preloading libraries
2024-06-13 14:33:09,114:INFO:Copying training dataset
2024-06-13 14:33:09,114:INFO:Plot type: auc
2024-06-13 14:33:09,195:INFO:Fitting Model
2024-06-13 14:33:09,195:INFO:Scoring test/hold-out set
2024-06-13 14:33:10,201:INFO:Visual Rendered Successfully
2024-06-13 14:33:10,608:INFO:plot_model() successfully completed......................................
2024-06-13 14:33:11,612:INFO:Initializing blend_models()
2024-06-13 14:33:11,612:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002982933B3D0>, estimator_list=[LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4783, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=4783, verbose=0,
                     warm_start=False), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4783, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=4783, verbose=0,
                       warm_start=False)], fold=None, round=4, choose_better=False, optimize=AUC, method=hard, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2024-06-13 14:33:11,612:INFO:Checking exceptions
2024-06-13 14:33:11,711:INFO:Importing libraries
2024-06-13 14:33:11,711:INFO:Copying training dataset
2024-06-13 14:33:11,726:INFO:Getting model names
2024-06-13 14:33:11,742:INFO:SubProcess create_model() called ==================================
2024-06-13 14:33:11,762:INFO:Initializing create_model()
2024-06-13 14:33:11,762:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002982933B3D0>, estimator=VotingClassifier(estimators=[('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covariance_estimator=None,
                                                         n_components=None,
                                                         priors=None,
                                                         shrinkage=None,
                                                         solver='svd',
                                                         store_covariance=False,
                                                         tol=0.0001)),
                             ('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 m...
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=4783,
                                                     verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002982180F0A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-13 14:33:11,762:INFO:Checking exceptions
2024-06-13 14:33:11,762:INFO:Importing libraries
2024-06-13 14:33:11,762:INFO:Copying training dataset
2024-06-13 14:33:11,774:INFO:Defining folds
2024-06-13 14:33:11,774:INFO:Declaring metric variables
2024-06-13 14:33:11,783:INFO:Importing untrained model
2024-06-13 14:33:11,783:INFO:Declaring custom model
2024-06-13 14:33:11,807:INFO:Voting Classifier Imported successfully
2024-06-13 14:33:11,820:INFO:Starting cross validation
2024-06-13 14:33:11,820:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-13 14:33:14,558:WARNING:C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2024-06-13 14:33:14,558:WARNING:C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2024-06-13 14:33:14,561:WARNING:C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2024-06-13 14:33:14,561:WARNING:C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2024-06-13 14:33:14,561:WARNING:C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2024-06-13 14:33:14,562:WARNING:C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2024-06-13 14:33:14,587:WARNING:C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2024-06-13 14:33:14,589:WARNING:C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2024-06-13 14:33:15,964:WARNING:C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2024-06-13 14:33:16,006:WARNING:C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\metrics\_scorer.py", line 344, in _score
    response_method = _check_response_method(estimator, self._response_method)
  File "C:\Users\aabir\AppData\Roaming\Python\Python39\site-packages\sklearn\utils\validation.py", line 2106, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: decision_function, predict_proba.

  warnings.warn(

2024-06-13 14:33:16,046:INFO:Calculating mean and std
2024-06-13 14:33:16,050:INFO:Creating metrics dataframe
2024-06-13 14:33:16,068:INFO:Finalizing model
2024-06-13 14:33:16,770:INFO:Uploading results into container
2024-06-13 14:33:16,774:INFO:Uploading model into container now
2024-06-13 14:33:16,777:INFO:_master_model_container: 21
2024-06-13 14:33:16,777:INFO:_display_container: 13
2024-06-13 14:33:16,793:INFO:VotingClassifier(estimators=[('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covariance_estimator=None,
                                                         n_components=None,
                                                         priors=None,
                                                         shrinkage=None,
                                                         solver='svd',
                                                         store_covariance=False,
                                                         tol=0.0001)),
                             ('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 m...
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=4783,
                                                     verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None)
2024-06-13 14:33:16,793:INFO:create_model() successfully completed......................................
2024-06-13 14:33:17,107:INFO:SubProcess create_model() end ==================================
2024-06-13 14:33:17,147:INFO:_master_model_container: 21
2024-06-13 14:33:17,147:INFO:_display_container: 13
2024-06-13 14:33:17,171:INFO:VotingClassifier(estimators=[('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covariance_estimator=None,
                                                         n_components=None,
                                                         priors=None,
                                                         shrinkage=None,
                                                         solver='svd',
                                                         store_covariance=False,
                                                         tol=0.0001)),
                             ('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 m...
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=4783,
                                                     verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None)
2024-06-13 14:33:17,171:INFO:blend_models() successfully completed......................................
2024-06-13 14:33:17,651:INFO:Initializing plot_model()
2024-06-13 14:33:17,651:INFO:plot_model(plot=boundary, fold=None, verbose=True, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covariance_estimator=None,
                                                         n_components=None,
                                                         priors=None,
                                                         shrinkage=None,
                                                         solver='svd',
                                                         store_covariance=False,
                                                         tol=0.0001)),
                             ('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 m...
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=4783,
                                                     verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002982933B3D0>, system=True)
2024-06-13 14:33:17,651:INFO:Checking exceptions
2024-06-13 14:33:17,667:INFO:Preloading libraries
2024-06-13 14:33:17,780:INFO:Copying training dataset
2024-06-13 14:33:17,780:INFO:Plot type: boundary
2024-06-13 14:33:17,840:INFO:Fitting StandardScaler()
2024-06-13 14:33:17,857:INFO:Fitting PCA()
2024-06-13 14:33:17,919:INFO:Fitting Model
2024-06-13 14:33:25,389:INFO:Visual Rendered Successfully
2024-06-13 14:33:25,869:INFO:plot_model() successfully completed......................................
2024-06-13 14:33:26,776:INFO:Initializing calibrate_model()
2024-06-13 14:33:26,776:INFO:calibrate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002982933B3D0>, estimator=VotingClassifier(estimators=[('Linear Discriminant Analysis',
                              LinearDiscriminantAnalysis(covariance_estimator=None,
                                                         n_components=None,
                                                         priors=None,
                                                         shrinkage=None,
                                                         solver='svd',
                                                         store_covariance=False,
                                                         tol=0.0001)),
                             ('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 m...
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=4783,
                                                     verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), method=sigmoid, calibrate_fold=5, fold=None, round=4, fit_kwargs=None, groups=None, verbose=True, return_train_score=False)
2024-06-13 14:33:26,776:INFO:Checking exceptions
2024-06-13 14:33:26,790:INFO:Preloading libraries
2024-06-13 14:33:26,790:INFO:Preparing display monitor
2024-06-13 14:33:26,897:INFO:Getting model name
2024-06-13 14:33:26,900:INFO:Base model : Voting Classifier
2024-06-13 14:33:26,926:INFO:Importing untrained CalibratedClassifierCV
2024-06-13 14:33:26,926:INFO:SubProcess create_model() called ==================================
2024-06-13 14:33:26,976:INFO:Initializing create_model()
2024-06-13 14:33:26,976:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002982933B3D0>, estimator=CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=VotingClassifier(estimators=[('Linear '
                                                               'Discriminant '
                                                               'Analysis',
                                                               LinearDiscriminantAnalysis(covariance_estimator=None,
                                                                                          n_components=None,
                                                                                          priors=None,
                                                                                          shrinkage=None,
                                                                                          solver='svd',
                                                                                          store_covariance=False,
                                                                                          tol=0.0001)),
                                                              ('Logistic '
                                                               'Regression',
                                                               LogisticRegression(C=1.0,
                                                                                  class_weight=None,
                                                                                  dual=False,
                                                                                  fit_interc...
                                                                                      max_features='sqrt',
                                                                                      max_leaf_nodes=None,
                                                                                      max_samples=None,
                                                                                      min_impurity_decrease=0.0,
                                                                                      min_samples_leaf=1,
                                                                                      min_samples_split=2,
                                                                                      min_weight_fraction_leaf=0.0,
                                                                                      monotonic_cst=None,
                                                                                      n_estimators=100,
                                                                                      n_jobs=-1,
                                                                                      oob_score=False,
                                                                                      random_state=4783,
                                                                                      verbose=0,
                                                                                      warm_start=False))],
                                                  flatten_transform=True,
                                                  n_jobs=-1, verbose=False,
                                                  voting='soft', weights=None),
                       method='sigmoid', n_jobs=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000298296A3430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-06-13 14:33:26,976:INFO:Checking exceptions
2024-06-13 14:33:26,976:INFO:Importing libraries
2024-06-13 14:33:26,977:INFO:Copying training dataset
2024-06-13 14:33:26,985:INFO:Defining folds
2024-06-13 14:33:26,985:INFO:Declaring metric variables
2024-06-13 14:33:26,995:INFO:Importing untrained model
2024-06-13 14:33:26,995:INFO:Declaring custom model
2024-06-13 14:33:27,029:INFO:Voting Classifier Imported successfully
2024-06-13 14:33:27,055:INFO:Starting cross validation
2024-06-13 14:33:27,056:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-06-13 14:33:50,141:INFO:Calculating mean and std
2024-06-13 14:33:50,149:INFO:Creating metrics dataframe
2024-06-13 14:33:50,169:INFO:Finalizing model
2024-06-13 14:33:52,763:INFO:Uploading results into container
2024-06-13 14:33:52,763:INFO:Uploading model into container now
2024-06-13 14:33:52,763:INFO:_master_model_container: 22
2024-06-13 14:33:52,763:INFO:_display_container: 14
2024-06-13 14:33:52,791:INFO:CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=VotingClassifier(estimators=[('Linear '
                                                               'Discriminant '
                                                               'Analysis',
                                                               LinearDiscriminantAnalysis(covariance_estimator=None,
                                                                                          n_components=None,
                                                                                          priors=None,
                                                                                          shrinkage=None,
                                                                                          solver='svd',
                                                                                          store_covariance=False,
                                                                                          tol=0.0001)),
                                                              ('Logistic '
                                                               'Regression',
                                                               LogisticRegression(C=1.0,
                                                                                  class_weight=None,
                                                                                  dual=False,
                                                                                  fit_interc...
                                                                                      max_features='sqrt',
                                                                                      max_leaf_nodes=None,
                                                                                      max_samples=None,
                                                                                      min_impurity_decrease=0.0,
                                                                                      min_samples_leaf=1,
                                                                                      min_samples_split=2,
                                                                                      min_weight_fraction_leaf=0.0,
                                                                                      monotonic_cst=None,
                                                                                      n_estimators=100,
                                                                                      n_jobs=-1,
                                                                                      oob_score=False,
                                                                                      random_state=4783,
                                                                                      verbose=0,
                                                                                      warm_start=False))],
                                                  flatten_transform=True,
                                                  n_jobs=-1, verbose=False,
                                                  voting='soft', weights=None),
                       method='sigmoid', n_jobs=None)
2024-06-13 14:33:52,791:INFO:create_model() successfully completed......................................
2024-06-13 14:33:53,003:INFO:SubProcess create_model() end ==================================
2024-06-13 14:33:53,036:INFO:_master_model_container: 22
2024-06-13 14:33:53,036:INFO:_display_container: 14
2024-06-13 14:33:53,062:INFO:CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=VotingClassifier(estimators=[('Linear '
                                                               'Discriminant '
                                                               'Analysis',
                                                               LinearDiscriminantAnalysis(covariance_estimator=None,
                                                                                          n_components=None,
                                                                                          priors=None,
                                                                                          shrinkage=None,
                                                                                          solver='svd',
                                                                                          store_covariance=False,
                                                                                          tol=0.0001)),
                                                              ('Logistic '
                                                               'Regression',
                                                               LogisticRegression(C=1.0,
                                                                                  class_weight=None,
                                                                                  dual=False,
                                                                                  fit_interc...
                                                                                      max_features='sqrt',
                                                                                      max_leaf_nodes=None,
                                                                                      max_samples=None,
                                                                                      min_impurity_decrease=0.0,
                                                                                      min_samples_leaf=1,
                                                                                      min_samples_split=2,
                                                                                      min_weight_fraction_leaf=0.0,
                                                                                      monotonic_cst=None,
                                                                                      n_estimators=100,
                                                                                      n_jobs=-1,
                                                                                      oob_score=False,
                                                                                      random_state=4783,
                                                                                      verbose=0,
                                                                                      warm_start=False))],
                                                  flatten_transform=True,
                                                  n_jobs=-1, verbose=False,
                                                  voting='soft', weights=None),
                       method='sigmoid', n_jobs=None)
2024-06-13 14:33:53,062:INFO:calibrate_model() successfully completed......................................
2024-06-13 14:33:53,396:INFO:Initializing finalize_model()
2024-06-13 14:33:53,396:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002982933B3D0>, estimator=CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=VotingClassifier(estimators=[('Linear '
                                                               'Discriminant '
                                                               'Analysis',
                                                               LinearDiscriminantAnalysis(covariance_estimator=None,
                                                                                          n_components=None,
                                                                                          priors=None,
                                                                                          shrinkage=None,
                                                                                          solver='svd',
                                                                                          store_covariance=False,
                                                                                          tol=0.0001)),
                                                              ('Logistic '
                                                               'Regression',
                                                               LogisticRegression(C=1.0,
                                                                                  class_weight=None,
                                                                                  dual=False,
                                                                                  fit_interc...
                                                                                      max_features='sqrt',
                                                                                      max_leaf_nodes=None,
                                                                                      max_samples=None,
                                                                                      min_impurity_decrease=0.0,
                                                                                      min_samples_leaf=1,
                                                                                      min_samples_split=2,
                                                                                      min_weight_fraction_leaf=0.0,
                                                                                      monotonic_cst=None,
                                                                                      n_estimators=100,
                                                                                      n_jobs=-1,
                                                                                      oob_score=False,
                                                                                      random_state=4783,
                                                                                      verbose=0,
                                                                                      warm_start=False))],
                                                  flatten_transform=True,
                                                  n_jobs=-1, verbose=False,
                                                  voting='soft', weights=None),
                       method='sigmoid', n_jobs=None), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-06-13 14:33:53,412:INFO:Finalizing CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=VotingClassifier(estimators=[('Linear '
                                                               'Discriminant '
                                                               'Analysis',
                                                               LinearDiscriminantAnalysis(covariance_estimator=None,
                                                                                          n_components=None,
                                                                                          priors=None,
                                                                                          shrinkage=None,
                                                                                          solver='svd',
                                                                                          store_covariance=False,
                                                                                          tol=0.0001)),
                                                              ('Logistic '
                                                               'Regression',
                                                               LogisticRegression(C=1.0,
                                                                                  class_weight=None,
                                                                                  dual=False,
                                                                                  fit_interc...
                                                                                      max_features='sqrt',
                                                                                      max_leaf_nodes=None,
                                                                                      max_samples=None,
                                                                                      min_impurity_decrease=0.0,
                                                                                      min_samples_leaf=1,
                                                                                      min_samples_split=2,
                                                                                      min_weight_fraction_leaf=0.0,
                                                                                      monotonic_cst=None,
                                                                                      n_estimators=100,
                                                                                      n_jobs=-1,
                                                                                      oob_score=False,
                                                                                      random_state=4783,
                                                                                      verbose=0,
                                                                                      warm_start=False))],
                                                  flatten_transform=True,
                                                  n_jobs=-1, verbose=False,
                                                  voting='soft', weights=None),
                       method='sigmoid', n_jobs=None)
2024-06-13 14:33:53,429:INFO:Initializing create_model()
2024-06-13 14:33:53,429:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002982933B3D0>, estimator=CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=VotingClassifier(estimators=[('Linear '
                                                               'Discriminant '
                                                               'Analysis',
                                                               LinearDiscriminantAnalysis(covariance_estimator=None,
                                                                                          n_components=None,
                                                                                          priors=None,
                                                                                          shrinkage=None,
                                                                                          solver='svd',
                                                                                          store_covariance=False,
                                                                                          tol=0.0001)),
                                                              ('Logistic '
                                                               'Regression',
                                                               LogisticRegression(C=1.0,
                                                                                  class_weight=None,
                                                                                  dual=False,
                                                                                  fit_interc...
                                                                                      max_features='sqrt',
                                                                                      max_leaf_nodes=None,
                                                                                      max_samples=None,
                                                                                      min_impurity_decrease=0.0,
                                                                                      min_samples_leaf=1,
                                                                                      min_samples_split=2,
                                                                                      min_weight_fraction_leaf=0.0,
                                                                                      monotonic_cst=None,
                                                                                      n_estimators=100,
                                                                                      n_jobs=-1,
                                                                                      oob_score=False,
                                                                                      random_state=4783,
                                                                                      verbose=0,
                                                                                      warm_start=False))],
                                                  flatten_transform=True,
                                                  n_jobs=-1, verbose=False,
                                                  voting='soft', weights=None),
                       method='sigmoid', n_jobs=None), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-06-13 14:33:53,433:INFO:Checking exceptions
2024-06-13 14:33:53,435:INFO:Importing libraries
2024-06-13 14:33:53,435:INFO:Copying training dataset
2024-06-13 14:33:53,435:INFO:Defining folds
2024-06-13 14:33:53,435:INFO:Declaring metric variables
2024-06-13 14:33:53,435:INFO:Importing untrained model
2024-06-13 14:33:53,435:INFO:Declaring custom model
2024-06-13 14:33:53,439:INFO:Voting Classifier Imported successfully
2024-06-13 14:33:53,441:INFO:Cross validation set to False
2024-06-13 14:33:53,441:INFO:Fitting Model
2024-06-13 14:33:55,897:INFO:Pipeline(memory=Memory(location=None),
         steps=[('placeholder', None),
                ('actual_estimator',
                 CalibratedClassifierCV(cv=5, ensemble=True,
                                        estimator=VotingClassifier(estimators=[('Linear '
                                                                                'Discriminant '
                                                                                'Analysis',
                                                                                LinearDiscriminantAnalysis(covariance_estimator=None,
                                                                                                           n_components=None,
                                                                                                           priors=None,
                                                                                                           shrinkage=None,
                                                                                                           solver='svd',
                                                                                                           store_covariance=False,
                                                                                                           tol=0.0001)),
                                                                               ('...
                                                                                                       max_leaf_nodes=None,
                                                                                                       max_samples=None,
                                                                                                       min_impurity_decrease=0.0,
                                                                                                       min_samples_leaf=1,
                                                                                                       min_samples_split=2,
                                                                                                       min_weight_fraction_leaf=0.0,
                                                                                                       monotonic_cst=None,
                                                                                                       n_estimators=100,
                                                                                                       n_jobs=-1,
                                                                                                       oob_score=False,
                                                                                                       random_state=4783,
                                                                                                       verbose=0,
                                                                                                       warm_start=False))],
                                                                   flatten_transform=True,
                                                                   n_jobs=-1,
                                                                   verbose=False,
                                                                   voting='soft',
                                                                   weights=None),
                                        method='sigmoid', n_jobs=None))],
         verbose=False)
2024-06-13 14:33:55,897:INFO:create_model() successfully completed......................................
2024-06-13 14:33:56,141:INFO:_master_model_container: 22
2024-06-13 14:33:56,141:INFO:_display_container: 14
2024-06-13 14:33:56,185:INFO:Pipeline(memory=Memory(location=None),
         steps=[('placeholder', None),
                ('actual_estimator',
                 CalibratedClassifierCV(cv=5, ensemble=True,
                                        estimator=VotingClassifier(estimators=[('Linear '
                                                                                'Discriminant '
                                                                                'Analysis',
                                                                                LinearDiscriminantAnalysis(covariance_estimator=None,
                                                                                                           n_components=None,
                                                                                                           priors=None,
                                                                                                           shrinkage=None,
                                                                                                           solver='svd',
                                                                                                           store_covariance=False,
                                                                                                           tol=0.0001)),
                                                                               ('...
                                                                                                       max_leaf_nodes=None,
                                                                                                       max_samples=None,
                                                                                                       min_impurity_decrease=0.0,
                                                                                                       min_samples_leaf=1,
                                                                                                       min_samples_split=2,
                                                                                                       min_weight_fraction_leaf=0.0,
                                                                                                       monotonic_cst=None,
                                                                                                       n_estimators=100,
                                                                                                       n_jobs=-1,
                                                                                                       oob_score=False,
                                                                                                       random_state=4783,
                                                                                                       verbose=0,
                                                                                                       warm_start=False))],
                                                                   flatten_transform=True,
                                                                   n_jobs=-1,
                                                                   verbose=False,
                                                                   voting='soft',
                                                                   weights=None),
                                        method='sigmoid', n_jobs=None))],
         verbose=False)
2024-06-13 14:33:56,185:INFO:finalize_model() successfully completed......................................
2024-06-13 14:33:56,463:INFO:Initializing plot_model()
2024-06-13 14:33:56,463:INFO:plot_model(plot=threshold, fold=None, verbose=True, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('placeholder', None),
                ('actual_estimator',
                 CalibratedClassifierCV(cv=5, ensemble=True,
                                        estimator=VotingClassifier(estimators=[('Linear '
                                                                                'Discriminant '
                                                                                'Analysis',
                                                                                LinearDiscriminantAnalysis(covariance_estimator=None,
                                                                                                           n_components=None,
                                                                                                           priors=None,
                                                                                                           shrinkage=None,
                                                                                                           solver='svd',
                                                                                                           store_covariance=False,
                                                                                                           tol=0.0001)),
                                                                               ('...
                                                                                                       max_leaf_nodes=None,
                                                                                                       max_samples=None,
                                                                                                       min_impurity_decrease=0.0,
                                                                                                       min_samples_leaf=1,
                                                                                                       min_samples_split=2,
                                                                                                       min_weight_fraction_leaf=0.0,
                                                                                                       monotonic_cst=None,
                                                                                                       n_estimators=100,
                                                                                                       n_jobs=-1,
                                                                                                       oob_score=False,
                                                                                                       random_state=4783,
                                                                                                       verbose=0,
                                                                                                       warm_start=False))],
                                                                   flatten_transform=True,
                                                                   n_jobs=-1,
                                                                   verbose=False,
                                                                   voting='soft',
                                                                   weights=None),
                                        method='sigmoid', n_jobs=None))],
         verbose=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002982933B3D0>, system=True)
2024-06-13 14:33:56,463:INFO:Checking exceptions
2024-06-13 14:33:56,469:INFO:Preloading libraries
2024-06-13 14:33:56,659:INFO:Copying training dataset
2024-06-13 14:33:56,659:INFO:Plot type: threshold
2024-06-13 14:33:56,683:INFO:Fitting Model
2024-06-13 14:36:01,671:INFO:Scoring test/hold-out set
2024-06-13 14:36:02,541:INFO:Visual Rendered Successfully
2024-06-13 14:36:02,731:INFO:plot_model() successfully completed......................................
2024-06-13 14:36:02,825:INFO:Initializing plot_model()
2024-06-13 14:36:02,825:INFO:plot_model(plot=boundary, fold=None, verbose=True, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('placeholder', None),
                ('actual_estimator',
                 CalibratedClassifierCV(cv=5, ensemble=True,
                                        estimator=VotingClassifier(estimators=[('Linear '
                                                                                'Discriminant '
                                                                                'Analysis',
                                                                                LinearDiscriminantAnalysis(covariance_estimator=None,
                                                                                                           n_components=None,
                                                                                                           priors=None,
                                                                                                           shrinkage=None,
                                                                                                           solver='svd',
                                                                                                           store_covariance=False,
                                                                                                           tol=0.0001)),
                                                                               ('...
                                                                                                       max_leaf_nodes=None,
                                                                                                       max_samples=None,
                                                                                                       min_impurity_decrease=0.0,
                                                                                                       min_samples_leaf=1,
                                                                                                       min_samples_split=2,
                                                                                                       min_weight_fraction_leaf=0.0,
                                                                                                       monotonic_cst=None,
                                                                                                       n_estimators=100,
                                                                                                       n_jobs=-1,
                                                                                                       oob_score=False,
                                                                                                       random_state=4783,
                                                                                                       verbose=0,
                                                                                                       warm_start=False))],
                                                                   flatten_transform=True,
                                                                   n_jobs=-1,
                                                                   verbose=False,
                                                                   voting='soft',
                                                                   weights=None),
                                        method='sigmoid', n_jobs=None))],
         verbose=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002982933B3D0>, system=True)
2024-06-13 14:36:02,825:INFO:Checking exceptions
2024-06-13 14:36:02,830:INFO:Preloading libraries
2024-06-13 14:36:02,964:INFO:Copying training dataset
2024-06-13 14:36:02,964:INFO:Plot type: boundary
2024-06-13 14:36:02,977:INFO:Fitting StandardScaler()
2024-06-13 14:36:02,986:INFO:Fitting PCA()
2024-06-13 14:36:02,999:INFO:Fitting Model
2024-06-13 14:36:08,063:INFO:Visual Rendered Successfully
2024-06-13 14:36:08,297:INFO:plot_model() successfully completed......................................
2024-06-13 14:36:09,435:INFO:Initializing finalize_model()
2024-06-13 14:36:09,435:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002982933B3D0>, estimator=CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=VotingClassifier(estimators=[('Linear '
                                                               'Discriminant '
                                                               'Analysis',
                                                               LinearDiscriminantAnalysis(covariance_estimator=None,
                                                                                          n_components=None,
                                                                                          priors=None,
                                                                                          shrinkage=None,
                                                                                          solver='svd',
                                                                                          store_covariance=False,
                                                                                          tol=0.0001)),
                                                              ('Logistic '
                                                               'Regression',
                                                               LogisticRegression(C=1.0,
                                                                                  class_weight=None,
                                                                                  dual=False,
                                                                                  fit_interc...
                                                                                      max_features='sqrt',
                                                                                      max_leaf_nodes=None,
                                                                                      max_samples=None,
                                                                                      min_impurity_decrease=0.0,
                                                                                      min_samples_leaf=1,
                                                                                      min_samples_split=2,
                                                                                      min_weight_fraction_leaf=0.0,
                                                                                      monotonic_cst=None,
                                                                                      n_estimators=100,
                                                                                      n_jobs=-1,
                                                                                      oob_score=False,
                                                                                      random_state=4783,
                                                                                      verbose=0,
                                                                                      warm_start=False))],
                                                  flatten_transform=True,
                                                  n_jobs=-1, verbose=False,
                                                  voting='soft', weights=None),
                       method='sigmoid', n_jobs=None), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-06-13 14:36:09,444:INFO:Finalizing CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=VotingClassifier(estimators=[('Linear '
                                                               'Discriminant '
                                                               'Analysis',
                                                               LinearDiscriminantAnalysis(covariance_estimator=None,
                                                                                          n_components=None,
                                                                                          priors=None,
                                                                                          shrinkage=None,
                                                                                          solver='svd',
                                                                                          store_covariance=False,
                                                                                          tol=0.0001)),
                                                              ('Logistic '
                                                               'Regression',
                                                               LogisticRegression(C=1.0,
                                                                                  class_weight=None,
                                                                                  dual=False,
                                                                                  fit_interc...
                                                                                      max_features='sqrt',
                                                                                      max_leaf_nodes=None,
                                                                                      max_samples=None,
                                                                                      min_impurity_decrease=0.0,
                                                                                      min_samples_leaf=1,
                                                                                      min_samples_split=2,
                                                                                      min_weight_fraction_leaf=0.0,
                                                                                      monotonic_cst=None,
                                                                                      n_estimators=100,
                                                                                      n_jobs=-1,
                                                                                      oob_score=False,
                                                                                      random_state=4783,
                                                                                      verbose=0,
                                                                                      warm_start=False))],
                                                  flatten_transform=True,
                                                  n_jobs=-1, verbose=False,
                                                  voting='soft', weights=None),
                       method='sigmoid', n_jobs=None)
2024-06-13 14:36:09,465:INFO:Initializing create_model()
2024-06-13 14:36:09,465:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002982933B3D0>, estimator=CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=VotingClassifier(estimators=[('Linear '
                                                               'Discriminant '
                                                               'Analysis',
                                                               LinearDiscriminantAnalysis(covariance_estimator=None,
                                                                                          n_components=None,
                                                                                          priors=None,
                                                                                          shrinkage=None,
                                                                                          solver='svd',
                                                                                          store_covariance=False,
                                                                                          tol=0.0001)),
                                                              ('Logistic '
                                                               'Regression',
                                                               LogisticRegression(C=1.0,
                                                                                  class_weight=None,
                                                                                  dual=False,
                                                                                  fit_interc...
                                                                                      max_features='sqrt',
                                                                                      max_leaf_nodes=None,
                                                                                      max_samples=None,
                                                                                      min_impurity_decrease=0.0,
                                                                                      min_samples_leaf=1,
                                                                                      min_samples_split=2,
                                                                                      min_weight_fraction_leaf=0.0,
                                                                                      monotonic_cst=None,
                                                                                      n_estimators=100,
                                                                                      n_jobs=-1,
                                                                                      oob_score=False,
                                                                                      random_state=4783,
                                                                                      verbose=0,
                                                                                      warm_start=False))],
                                                  flatten_transform=True,
                                                  n_jobs=-1, verbose=False,
                                                  voting='soft', weights=None),
                       method='sigmoid', n_jobs=None), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-06-13 14:36:09,465:INFO:Checking exceptions
2024-06-13 14:36:09,465:INFO:Importing libraries
2024-06-13 14:36:09,465:INFO:Copying training dataset
2024-06-13 14:36:09,465:INFO:Defining folds
2024-06-13 14:36:09,465:INFO:Declaring metric variables
2024-06-13 14:36:09,465:INFO:Importing untrained model
2024-06-13 14:36:09,465:INFO:Declaring custom model
2024-06-13 14:36:09,474:INFO:Voting Classifier Imported successfully
2024-06-13 14:36:09,474:INFO:Cross validation set to False
2024-06-13 14:36:09,474:INFO:Fitting Model
2024-06-13 14:36:11,538:INFO:Pipeline(memory=Memory(location=None),
         steps=[('placeholder', None),
                ('actual_estimator',
                 CalibratedClassifierCV(cv=5, ensemble=True,
                                        estimator=VotingClassifier(estimators=[('Linear '
                                                                                'Discriminant '
                                                                                'Analysis',
                                                                                LinearDiscriminantAnalysis(covariance_estimator=None,
                                                                                                           n_components=None,
                                                                                                           priors=None,
                                                                                                           shrinkage=None,
                                                                                                           solver='svd',
                                                                                                           store_covariance=False,
                                                                                                           tol=0.0001)),
                                                                               ('...
                                                                                                       max_leaf_nodes=None,
                                                                                                       max_samples=None,
                                                                                                       min_impurity_decrease=0.0,
                                                                                                       min_samples_leaf=1,
                                                                                                       min_samples_split=2,
                                                                                                       min_weight_fraction_leaf=0.0,
                                                                                                       monotonic_cst=None,
                                                                                                       n_estimators=100,
                                                                                                       n_jobs=-1,
                                                                                                       oob_score=False,
                                                                                                       random_state=4783,
                                                                                                       verbose=0,
                                                                                                       warm_start=False))],
                                                                   flatten_transform=True,
                                                                   n_jobs=-1,
                                                                   verbose=False,
                                                                   voting='soft',
                                                                   weights=None),
                                        method='sigmoid', n_jobs=None))],
         verbose=False)
2024-06-13 14:36:11,554:INFO:create_model() successfully completed......................................
2024-06-13 14:36:11,711:INFO:_master_model_container: 22
2024-06-13 14:36:11,711:INFO:_display_container: 14
2024-06-13 14:36:11,742:INFO:Pipeline(memory=Memory(location=None),
         steps=[('placeholder', None),
                ('actual_estimator',
                 CalibratedClassifierCV(cv=5, ensemble=True,
                                        estimator=VotingClassifier(estimators=[('Linear '
                                                                                'Discriminant '
                                                                                'Analysis',
                                                                                LinearDiscriminantAnalysis(covariance_estimator=None,
                                                                                                           n_components=None,
                                                                                                           priors=None,
                                                                                                           shrinkage=None,
                                                                                                           solver='svd',
                                                                                                           store_covariance=False,
                                                                                                           tol=0.0001)),
                                                                               ('...
                                                                                                       max_leaf_nodes=None,
                                                                                                       max_samples=None,
                                                                                                       min_impurity_decrease=0.0,
                                                                                                       min_samples_leaf=1,
                                                                                                       min_samples_split=2,
                                                                                                       min_weight_fraction_leaf=0.0,
                                                                                                       monotonic_cst=None,
                                                                                                       n_estimators=100,
                                                                                                       n_jobs=-1,
                                                                                                       oob_score=False,
                                                                                                       random_state=4783,
                                                                                                       verbose=0,
                                                                                                       warm_start=False))],
                                                                   flatten_transform=True,
                                                                   n_jobs=-1,
                                                                   verbose=False,
                                                                   voting='soft',
                                                                   weights=None),
                                        method='sigmoid', n_jobs=None))],
         verbose=False)
2024-06-13 14:36:11,742:INFO:finalize_model() successfully completed......................................
2024-06-13 14:37:23,342:INFO:Initializing finalize_model()
2024-06-13 14:37:23,343:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002982933B3D0>, estimator=CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=VotingClassifier(estimators=[('Linear '
                                                               'Discriminant '
                                                               'Analysis',
                                                               LinearDiscriminantAnalysis(covariance_estimator=None,
                                                                                          n_components=None,
                                                                                          priors=None,
                                                                                          shrinkage=None,
                                                                                          solver='svd',
                                                                                          store_covariance=False,
                                                                                          tol=0.0001)),
                                                              ('Logistic '
                                                               'Regression',
                                                               LogisticRegression(C=1.0,
                                                                                  class_weight=None,
                                                                                  dual=False,
                                                                                  fit_interc...
                                                                                      max_features='sqrt',
                                                                                      max_leaf_nodes=None,
                                                                                      max_samples=None,
                                                                                      min_impurity_decrease=0.0,
                                                                                      min_samples_leaf=1,
                                                                                      min_samples_split=2,
                                                                                      min_weight_fraction_leaf=0.0,
                                                                                      monotonic_cst=None,
                                                                                      n_estimators=100,
                                                                                      n_jobs=-1,
                                                                                      oob_score=False,
                                                                                      random_state=4783,
                                                                                      verbose=0,
                                                                                      warm_start=False))],
                                                  flatten_transform=True,
                                                  n_jobs=-1, verbose=False,
                                                  voting='soft', weights=None),
                       method='sigmoid', n_jobs=None), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-06-13 14:37:23,365:INFO:Finalizing CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=VotingClassifier(estimators=[('Linear '
                                                               'Discriminant '
                                                               'Analysis',
                                                               LinearDiscriminantAnalysis(covariance_estimator=None,
                                                                                          n_components=None,
                                                                                          priors=None,
                                                                                          shrinkage=None,
                                                                                          solver='svd',
                                                                                          store_covariance=False,
                                                                                          tol=0.0001)),
                                                              ('Logistic '
                                                               'Regression',
                                                               LogisticRegression(C=1.0,
                                                                                  class_weight=None,
                                                                                  dual=False,
                                                                                  fit_interc...
                                                                                      max_features='sqrt',
                                                                                      max_leaf_nodes=None,
                                                                                      max_samples=None,
                                                                                      min_impurity_decrease=0.0,
                                                                                      min_samples_leaf=1,
                                                                                      min_samples_split=2,
                                                                                      min_weight_fraction_leaf=0.0,
                                                                                      monotonic_cst=None,
                                                                                      n_estimators=100,
                                                                                      n_jobs=-1,
                                                                                      oob_score=False,
                                                                                      random_state=4783,
                                                                                      verbose=0,
                                                                                      warm_start=False))],
                                                  flatten_transform=True,
                                                  n_jobs=-1, verbose=False,
                                                  voting='soft', weights=None),
                       method='sigmoid', n_jobs=None)
2024-06-13 14:37:23,389:INFO:Initializing create_model()
2024-06-13 14:37:23,389:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002982933B3D0>, estimator=CalibratedClassifierCV(cv=5, ensemble=True,
                       estimator=VotingClassifier(estimators=[('Linear '
                                                               'Discriminant '
                                                               'Analysis',
                                                               LinearDiscriminantAnalysis(covariance_estimator=None,
                                                                                          n_components=None,
                                                                                          priors=None,
                                                                                          shrinkage=None,
                                                                                          solver='svd',
                                                                                          store_covariance=False,
                                                                                          tol=0.0001)),
                                                              ('Logistic '
                                                               'Regression',
                                                               LogisticRegression(C=1.0,
                                                                                  class_weight=None,
                                                                                  dual=False,
                                                                                  fit_interc...
                                                                                      max_features='sqrt',
                                                                                      max_leaf_nodes=None,
                                                                                      max_samples=None,
                                                                                      min_impurity_decrease=0.0,
                                                                                      min_samples_leaf=1,
                                                                                      min_samples_split=2,
                                                                                      min_weight_fraction_leaf=0.0,
                                                                                      monotonic_cst=None,
                                                                                      n_estimators=100,
                                                                                      n_jobs=-1,
                                                                                      oob_score=False,
                                                                                      random_state=4783,
                                                                                      verbose=0,
                                                                                      warm_start=False))],
                                                  flatten_transform=True,
                                                  n_jobs=-1, verbose=False,
                                                  voting='soft', weights=None),
                       method='sigmoid', n_jobs=None), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-06-13 14:37:23,389:INFO:Checking exceptions
2024-06-13 14:37:23,392:INFO:Importing libraries
2024-06-13 14:37:23,392:INFO:Copying training dataset
2024-06-13 14:37:23,392:INFO:Defining folds
2024-06-13 14:37:23,392:INFO:Declaring metric variables
2024-06-13 14:37:23,392:INFO:Importing untrained model
2024-06-13 14:37:23,392:INFO:Declaring custom model
2024-06-13 14:37:23,396:INFO:Voting Classifier Imported successfully
2024-06-13 14:37:23,397:INFO:Cross validation set to False
2024-06-13 14:37:23,397:INFO:Fitting Model
2024-06-13 14:37:25,669:INFO:Pipeline(memory=Memory(location=None),
         steps=[('placeholder', None),
                ('actual_estimator',
                 CalibratedClassifierCV(cv=5, ensemble=True,
                                        estimator=VotingClassifier(estimators=[('Linear '
                                                                                'Discriminant '
                                                                                'Analysis',
                                                                                LinearDiscriminantAnalysis(covariance_estimator=None,
                                                                                                           n_components=None,
                                                                                                           priors=None,
                                                                                                           shrinkage=None,
                                                                                                           solver='svd',
                                                                                                           store_covariance=False,
                                                                                                           tol=0.0001)),
                                                                               ('...
                                                                                                       max_leaf_nodes=None,
                                                                                                       max_samples=None,
                                                                                                       min_impurity_decrease=0.0,
                                                                                                       min_samples_leaf=1,
                                                                                                       min_samples_split=2,
                                                                                                       min_weight_fraction_leaf=0.0,
                                                                                                       monotonic_cst=None,
                                                                                                       n_estimators=100,
                                                                                                       n_jobs=-1,
                                                                                                       oob_score=False,
                                                                                                       random_state=4783,
                                                                                                       verbose=0,
                                                                                                       warm_start=False))],
                                                                   flatten_transform=True,
                                                                   n_jobs=-1,
                                                                   verbose=False,
                                                                   voting='soft',
                                                                   weights=None),
                                        method='sigmoid', n_jobs=None))],
         verbose=False)
2024-06-13 14:37:25,669:INFO:create_model() successfully completed......................................
2024-06-13 14:37:25,924:INFO:_master_model_container: 22
2024-06-13 14:37:25,924:INFO:_display_container: 14
2024-06-13 14:37:25,984:INFO:Pipeline(memory=Memory(location=None),
         steps=[('placeholder', None),
                ('actual_estimator',
                 CalibratedClassifierCV(cv=5, ensemble=True,
                                        estimator=VotingClassifier(estimators=[('Linear '
                                                                                'Discriminant '
                                                                                'Analysis',
                                                                                LinearDiscriminantAnalysis(covariance_estimator=None,
                                                                                                           n_components=None,
                                                                                                           priors=None,
                                                                                                           shrinkage=None,
                                                                                                           solver='svd',
                                                                                                           store_covariance=False,
                                                                                                           tol=0.0001)),
                                                                               ('...
                                                                                                       max_leaf_nodes=None,
                                                                                                       max_samples=None,
                                                                                                       min_impurity_decrease=0.0,
                                                                                                       min_samples_leaf=1,
                                                                                                       min_samples_split=2,
                                                                                                       min_weight_fraction_leaf=0.0,
                                                                                                       monotonic_cst=None,
                                                                                                       n_estimators=100,
                                                                                                       n_jobs=-1,
                                                                                                       oob_score=False,
                                                                                                       random_state=4783,
                                                                                                       verbose=0,
                                                                                                       warm_start=False))],
                                                                   flatten_transform=True,
                                                                   n_jobs=-1,
                                                                   verbose=False,
                                                                   voting='soft',
                                                                   weights=None),
                                        method='sigmoid', n_jobs=None))],
         verbose=False)
2024-06-13 14:37:25,984:INFO:finalize_model() successfully completed......................................
